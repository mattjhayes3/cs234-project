{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !conda install -y gdown\n# print('hi')\n!conda install aiohttp -y\n!git clone https://github.com/mattjhayes3/cs234-project.git\n%cd /kaggle/working/cs234-project\n!git pull --rebase\n!pip install wandb\nimport wandb\n\nwandb.login(key=\"KEY\")\n# wandb.init()\n\nfrom huggingface_hub import notebook_login,login\n\n# notebook_login(\"KEY\")\nlogin(\"KEY\")\n\n# !gdown --id 1TTg8s_dj60EKl4No2unSvYmMyMopPVJ6\n# !gdown --id 1Z7HvAokBQu65jew4ou2DjOYRi23OrJdr\n!mkdir results\n!pip install datasets>=1.17.0 torch>=1.4.0 tqdm transformers accelerate peft>=0.3.0 tyro>=0.5.7\n!pip install git+https://github.com/mattjhayes3/trl.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-01T10:19:14.390434Z","iopub.execute_input":"2024-06-01T10:19:14.390702Z","iopub.status.idle":"2024-06-01T10:21:47.722494Z","shell.execute_reply.started":"2024-06-01T10:19:14.390677Z","shell.execute_reply":"2024-06-01T10:21:47.721273Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - aiohttp\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    aiohttp-3.9.5              |  py310h2372a71_0         682 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         682 KB\n\nThe following packages will be UPDATED:\n\n  aiohttp                             3.9.1-py310h2372a71_0 --> 3.9.5-py310h2372a71_0 \n\n\n\nDownloading and Extracting Packages:\n                                                                                \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nfatal: destination path 'cs234-project' already exists and is not an empty directory.\n/kaggle/working/cs234-project\nremote: Enumerating objects: 21, done.\u001b[K\nremote: Counting objects: 100% (21/21), done.\u001b[K\nremote: Compressing objects: 100% (11/11), done.\u001b[K\nremote: Total 19 (delta 9), reused 18 (delta 8), pack-reused 0\u001b[K\nUnpacking objects: 100% (19/19), 8.02 MiB | 4.48 MiB/s, done.\nFrom https://github.com/mattjhayes3/cs234-project\n   d2ea544..8cb4269  main       -> origin/main\nCould not access submodule 'trl'\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.2.2)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.3.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\nmkdir: cannot create directory 'results': File exists\nCollecting git+https://github.com/mattjhayes3/trl.git\n  Cloning https://github.com/mattjhayes3/trl.git to /tmp/pip-req-build-3_45w08t\n  Running command git clone --filter=blob:none --quiet https://github.com/mattjhayes3/trl.git /tmp/pip-req-build-3_45w08t\n  Resolved https://github.com/mattjhayes3/trl.git to commit 4c8e35e0e0a6b90b4b7c506cce7e31eb51b170b9\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (4.41.1)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (0.30.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (2.19.1)\nRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (0.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (2024.3.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.23.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (4.66.4)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (13.7.0)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (1.7.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.8.7.dev0) (5.9.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.9.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.8.7.dev0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.8.7.dev0) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.8.7.dev0) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.7.dev0) (1.16.0)\nBuilding wheels for collected packages: trl\n  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for trl: filename=trl-0.8.7.dev0-py3-none-any.whl size=209532 sha256=bc7deca9b0677b8cc10b63c3c277e6583d6a4f923a026e61bbebdaaa85f75588\n  Stored in directory: /tmp/pip-ephem-wheel-cache-wukk7tja/wheels/b5/f5/74/f982e27bdb1c23b205f8bfcaaed174cf3d2c06bd1a5f5926cc\nSuccessfully built trl\nInstalling collected packages: trl\nSuccessfully installed trl-0.8.7.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"! rm -rf */*/optimizer.pt && git pull --rebase && python dpo.py  --output_dir=dpo_6c2_div36-0_05  --beta=0.05 --dataset_name=/kaggle/working/cs234-project/pref_pairs_16_token_6_choose_2_div_36_tokenized     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128  --per_device_eval_batch_size 128     --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 50     --report_to wandb     --logging_first_step --logging_strategy='steps' --logging_steps 50  --eval_steps=50 --no_remove_unused_columns --save_total_limit=4 --evaluation_strategy='steps' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch' --num_train_epochs=19","metadata":{"execution":{"iopub.status.busy":"2024-06-01T00:25:45.100571Z","iopub.execute_input":"2024-06-01T00:25:45.100961Z","iopub.status.idle":"2024-06-01T00:57:02.203198Z","shell.execute_reply.started":"2024-06-01T00:25:45.100925Z","shell.execute_reply":"2024-06-01T00:57:02.202005Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Already up to date.\nCurrent branch main is up to date.\n2024-06-01 00:25:55.115535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-01 00:25:55.115683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-01 00:25:55.256449: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nconfig.json: 100%|█████████████████████████████| 577/577 [00:00<00:00, 3.58MB/s]\npytorch_model.bin: 100%|██████████████████████| 548M/548M [00:01<00:00, 315MB/s]\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\ntokenizer_config.json: 100%|█████████████████| 17.0/17.0 [00:00<00:00, 95.5kB/s]\nvocab.json: 100%|████████████████████████████| 899k/899k [00:00<00:00, 3.52MB/s]\nmerges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 2.46MB/s]\nspecial_tokens_map.json: 100%|████████████████| 90.0/90.0 [00:00<00:00, 544kB/s]\nds len 4149\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240601_002612-eemdkwwm\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdpo_6c2_div36-0_05\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface/runs/eemdkwwm\u001b[0m\n  0%|                                                   | 0/589 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 0.6931, 'grad_norm': 1.207987904548645, 'learning_rate': 4e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -60.114646911621094, 'logps/chosen': -60.310203552246094, 'logits/rejected': -38.24871826171875, 'logits/chosen': -36.57445526123047, 'epoch': 0.03}\n{'loss': 0.6895, 'grad_norm': 1.2010098695755005, 'learning_rate': 2e-06, 'rewards/chosen': 0.003457672195509076, 'rewards/rejected': -0.0038091838359832764, 'rewards/accuracies': 0.7744872570037842, 'rewards/margins': 0.007266854867339134, 'logps/rejected': -59.691410064697266, 'logps/chosen': -60.61823272705078, 'logits/rejected': -37.69108200073242, 'logits/chosen': -36.74053955078125, 'epoch': 1.61}\n  8%|███▌                                      | 50/589 [01:02<10:50,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6842409372329712, 'eval_runtime': 0.8963, 'eval_samples_per_second': 232.062, 'eval_steps_per_second': 2.231, 'eval_rewards/chosen': 0.008640723302960396, 'eval_rewards/rejected': -0.00911322794854641, 'eval_rewards/accuracies': 0.8218749761581421, 'eval_rewards/margins': 0.017753951251506805, 'eval_logps/rejected': -59.69798278808594, 'eval_logps/chosen': -60.0034294128418, 'eval_logits/rejected': -39.013282775878906, 'eval_logits/chosen': -38.020729064941406, 'epoch': 1.61}\n  8%|███▌                                      | 50/589 [01:03<10:50,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.6704, 'grad_norm': 1.1371697187423706, 'learning_rate': 2e-06, 'rewards/chosen': 0.01822102628648281, 'rewards/rejected': -0.028400465846061707, 'rewards/accuracies': 0.8637670278549194, 'rewards/margins': 0.04662149399518967, 'logps/rejected': -60.29573059082031, 'logps/chosen': -60.56465148925781, 'logits/rejected': -37.03486633300781, 'logits/chosen': -36.172908782958984, 'epoch': 3.23}\n 17%|██████▉                                  | 100/589 [02:07<10:22,  1.27s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6664658188819885, 'eval_runtime': 0.8957, 'eval_samples_per_second': 232.228, 'eval_steps_per_second': 2.233, 'eval_rewards/chosen': 0.01842322200536728, 'eval_rewards/rejected': -0.03629284352064133, 'eval_rewards/accuracies': 0.831250011920929, 'eval_rewards/margins': 0.054716065526008606, 'eval_logps/rejected': -60.241573333740234, 'eval_logps/chosen': -59.807777404785156, 'eval_logits/rejected': -38.18230438232422, 'eval_logits/chosen': -37.30451202392578, 'epoch': 3.23}\n 17%|██████▉                                  | 100/589 [02:08<10:22,  1.27s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.6454, 'grad_norm': 1.0444092750549316, 'learning_rate': 2e-06, 'rewards/chosen': 0.028449321165680885, 'rewards/rejected': -0.0715700164437294, 'rewards/accuracies': 0.8858941793441772, 'rewards/margins': 0.10001934319734573, 'logps/rejected': -60.97978973388672, 'logps/chosen': -60.09376907348633, 'logits/rejected': -36.311527252197266, 'logits/chosen': -35.50721740722656, 'epoch': 4.84}\n 25%|██████████▍                              | 150/589 [03:10<08:47,  1.20s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6484931111335754, 'eval_runtime': 0.8992, 'eval_samples_per_second': 231.319, 'eval_steps_per_second': 2.224, 'eval_rewards/chosen': 0.016432229429483414, 'eval_rewards/rejected': -0.07776211947202682, 'eval_rewards/accuracies': 0.8132812976837158, 'eval_rewards/margins': 0.09419434517621994, 'eval_logps/rejected': -61.070960998535156, 'eval_logps/chosen': -59.847599029541016, 'eval_logits/rejected': -37.374061584472656, 'eval_logits/chosen': -36.66398620605469, 'epoch': 4.84}\n 25%|██████████▍                              | 150/589 [03:11<08:47,  1.20s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.6187, 'grad_norm': 1.1065014600753784, 'learning_rate': 2e-06, 'rewards/chosen': 0.029228314757347107, 'rewards/rejected': -0.13083197176456451, 'rewards/accuracies': 0.8935612440109253, 'rewards/margins': 0.16006028652191162, 'logps/rejected': -62.308109283447266, 'logps/chosen': -60.28349304199219, 'logits/rejected': -35.56621551513672, 'logits/chosen': -34.801246643066406, 'epoch': 6.45}\n 34%|█████████████▉                           | 200/589 [04:15<07:50,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6296240091323853, 'eval_runtime': 0.8961, 'eval_samples_per_second': 232.129, 'eval_steps_per_second': 2.232, 'eval_rewards/chosen': 0.0017594045493751764, 'eval_rewards/rejected': -0.1363818198442459, 'eval_rewards/accuracies': 0.8132812976837158, 'eval_rewards/margins': 0.1381412148475647, 'eval_logps/rejected': -62.24335479736328, 'eval_logps/chosen': -60.14105987548828, 'eval_logits/rejected': -36.60338592529297, 'eval_logits/chosen': -36.121273040771484, 'epoch': 6.45}\n 34%|█████████████▉                           | 200/589 [04:16<07:50,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.5908, 'grad_norm': 1.1028742790222168, 'learning_rate': 2e-06, 'rewards/chosen': 0.009851098991930485, 'rewards/rejected': -0.21718858182430267, 'rewards/accuracies': 0.8921024203300476, 'rewards/margins': 0.22703967988491058, 'logps/rejected': -64.02922058105469, 'logps/chosen': -60.51311492919922, 'logits/rejected': -34.68950271606445, 'logits/chosen': -34.150367736816406, 'epoch': 8.06}\n 42%|█████████████████▍                       | 250/589 [05:20<09:13,  1.63s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6082850694656372, 'eval_runtime': 0.8971, 'eval_samples_per_second': 231.849, 'eval_steps_per_second': 2.229, 'eval_rewards/chosen': -0.030183352530002594, 'eval_rewards/rejected': -0.22181633114814758, 'eval_rewards/accuracies': 0.8132812976837158, 'eval_rewards/margins': 0.19163298606872559, 'eval_logps/rejected': -63.95204544067383, 'eval_logps/chosen': -60.779911041259766, 'eval_logits/rejected': -35.80052947998047, 'eval_logits/chosen': -35.631439208984375, 'epoch': 8.06}\n 42%|█████████████████▍                       | 250/589 [05:21<09:13,  1.63s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.5584, 'grad_norm': 1.0623018741607666, 'learning_rate': 2e-06, 'rewards/chosen': -0.0185068529099226, 'rewards/rejected': -0.3292614817619324, 'rewards/accuracies': 0.8924891948699951, 'rewards/margins': 0.31075459718704224, 'logps/rejected': -66.1121597290039, 'logps/chosen': -61.151763916015625, 'logits/rejected': -33.95956039428711, 'logits/chosen': -33.29624938964844, 'epoch': 9.68}\n 51%|████████████████████▉                    | 300/589 [06:23<05:49,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5843352675437927, 'eval_runtime': 0.8958, 'eval_samples_per_second': 232.19, 'eval_steps_per_second': 2.233, 'eval_rewards/chosen': -0.08560676872730255, 'eval_rewards/rejected': -0.34262821078300476, 'eval_rewards/accuracies': 0.8296874761581421, 'eval_rewards/margins': 0.2570214569568634, 'eval_logps/rejected': -66.3682861328125, 'eval_logps/chosen': -61.88837814331055, 'eval_logits/rejected': -34.94727325439453, 'eval_logits/chosen': -35.191123962402344, 'epoch': 9.68}\n 51%|████████████████████▉                    | 300/589 [06:24<05:49,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.5221, 'grad_norm': 1.0726829767227173, 'learning_rate': 2e-06, 'rewards/chosen': -0.08584703505039215, 'rewards/rejected': -0.49951693415641785, 'rewards/accuracies': 0.8975293636322021, 'rewards/margins': 0.4136699438095093, 'logps/rejected': -69.68408203125, 'logps/chosen': -62.38066482543945, 'logits/rejected': -33.19419479370117, 'logits/chosen': -32.89714050292969, 'epoch': 11.29}\n 59%|████████████████████████▎                | 350/589 [07:29<04:57,  1.24s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5593233108520508, 'eval_runtime': 0.894, 'eval_samples_per_second': 232.652, 'eval_steps_per_second': 2.237, 'eval_rewards/chosen': -0.1758531630039215, 'eval_rewards/rejected': -0.5121335983276367, 'eval_rewards/accuracies': 0.819531261920929, 'eval_rewards/margins': 0.3362804055213928, 'eval_logps/rejected': -69.75839233398438, 'eval_logps/chosen': -63.69331359863281, 'eval_logits/rejected': -33.98529052734375, 'eval_logits/chosen': -34.77014923095703, 'epoch': 11.29}\n 59%|████████████████████████▎                | 350/589 [07:30<04:57,  1.24s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.4816, 'grad_norm': 1.1133421659469604, 'learning_rate': 2e-06, 'rewards/chosen': -0.17328499257564545, 'rewards/rejected': -0.7161551117897034, 'rewards/accuracies': 0.9007379412651062, 'rewards/margins': 0.5428701639175415, 'logps/rejected': -74.0778579711914, 'logps/chosen': -64.3348617553711, 'logits/rejected': -32.2618293762207, 'logits/chosen': -31.966796875, 'epoch': 12.9}\n 68%|███████████████████████████▊             | 400/589 [08:32<03:47,  1.20s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5329545736312866, 'eval_runtime': 0.8961, 'eval_samples_per_second': 232.121, 'eval_steps_per_second': 2.232, 'eval_rewards/chosen': -0.30190712213516235, 'eval_rewards/rejected': -0.7382527589797974, 'eval_rewards/accuracies': 0.8296874761581421, 'eval_rewards/margins': 0.43634557723999023, 'eval_logps/rejected': -74.28076934814453, 'eval_logps/chosen': -66.21438598632812, 'eval_logits/rejected': -32.59577941894531, 'eval_logits/chosen': -33.95376968383789, 'epoch': 12.9}\n 68%|███████████████████████████▊             | 400/589 [08:33<03:47,  1.20s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.4393, 'grad_norm': 1.1953849792480469, 'learning_rate': 2e-06, 'rewards/chosen': -0.305709570646286, 'rewards/rejected': -1.0022025108337402, 'rewards/accuracies': 0.9044151902198792, 'rewards/margins': 0.6964929103851318, 'logps/rejected': -79.67247009277344, 'logps/chosen': -66.84512329101562, 'logits/rejected': -30.754901885986328, 'logits/chosen': -30.941694259643555, 'epoch': 14.52}\n 76%|███████████████████████████████▎         | 450/589 [09:37<02:47,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5076795816421509, 'eval_runtime': 0.8946, 'eval_samples_per_second': 232.494, 'eval_steps_per_second': 2.236, 'eval_rewards/chosen': -0.4821500778198242, 'eval_rewards/rejected': -1.041576623916626, 'eval_rewards/accuracies': 0.823437511920929, 'eval_rewards/margins': 0.5594265460968018, 'eval_logps/rejected': -80.34724426269531, 'eval_logps/chosen': -69.81924438476562, 'eval_logits/rejected': -30.81542205810547, 'eval_logits/chosen': -32.70686340332031, 'epoch': 14.52}\n 76%|███████████████████████████████▎         | 450/589 [09:38<02:47,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.3886, 'grad_norm': 1.3612780570983887, 'learning_rate': 2e-06, 'rewards/chosen': -0.4787351191043854, 'rewards/rejected': -1.3894047737121582, 'rewards/accuracies': 0.9175293445587158, 'rewards/margins': 0.9106696248054504, 'logps/rejected': -87.45112609863281, 'logps/chosen': -70.37078094482422, 'logits/rejected': -29.015169143676758, 'logits/chosen': -29.358076095581055, 'epoch': 16.13}\n 85%|██████████████████████████████████▊      | 500/589 [10:42<02:05,  1.41s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.4845258593559265, 'eval_runtime': 0.8982, 'eval_samples_per_second': 231.576, 'eval_steps_per_second': 2.227, 'eval_rewards/chosen': -0.7366538643836975, 'eval_rewards/rejected': -1.4602957963943481, 'eval_rewards/accuracies': 0.819531261920929, 'eval_rewards/margins': 0.7236418724060059, 'eval_logps/rejected': -88.72163391113281, 'eval_logps/chosen': -74.90933227539062, 'eval_logits/rejected': -29.086185455322266, 'eval_logits/chosen': -31.23306655883789, 'epoch': 16.13}\n 85%|██████████████████████████████████▊      | 500/589 [10:43<02:05,  1.41s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.3382, 'grad_norm': 1.4031200408935547, 'learning_rate': 2e-06, 'rewards/chosen': -0.753339946269989, 'rewards/rejected': -1.9290187358856201, 'rewards/accuracies': 0.9235302805900574, 'rewards/margins': 1.1756789684295654, 'logps/rejected': -98.27236938476562, 'logps/chosen': -75.86669158935547, 'logits/rejected': -27.966625213623047, 'logits/chosen': -28.361711502075195, 'epoch': 17.74}\n 93%|██████████████████████████████████████▎  | 550/589 [11:45<00:46,  1.20s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.45883309841156006, 'eval_runtime': 0.8954, 'eval_samples_per_second': 232.31, 'eval_steps_per_second': 2.234, 'eval_rewards/chosen': -1.0637613534927368, 'eval_rewards/rejected': -2.023406505584717, 'eval_rewards/accuracies': 0.819531261920929, 'eval_rewards/margins': 0.9596452713012695, 'eval_logps/rejected': -99.98384094238281, 'eval_logps/chosen': -81.45147705078125, 'eval_logits/rejected': -28.61951446533203, 'eval_logits/chosen': -30.629714965820312, 'epoch': 17.74}\n 93%|██████████████████████████████████████▎  | 550/589 [11:46<00:46,  1.20s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'train_runtime': 774.0656, 'train_samples_per_second': 96.735, 'train_steps_per_second': 0.761, 'train_loss': 0.5239788316101696, 'epoch': 19.0}\n100%|█████████████████████████████████████████| 589/589 [12:37<00:00,  1.29s/it]\nEvaling epochs [19, 18, 17, 16]\nLoading from dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-589\nDownloading readme: 100%|██████████████████| 7.81k/7.81k [00:00<00:00, 11.9MB/s]\nDownloading data: 100%|████████████████████| 21.0M/21.0M [00:00<00:00, 48.8MB/s]\nDownloading data: 100%|████████████████████| 20.5M/20.5M [00:00<00:00, 76.9MB/s]\nDownloading data: 100%|█████████████████████| 42.0M/42.0M [00:00<00:00, 126MB/s]\nGenerating train split: 100%|██| 25000/25000 [00:00<00:00, 105670.42 examples/s]\nGenerating test split: 100%|███| 25000/25000 [00:00<00:00, 126531.42 examples/s]\nGenerating unsupervised split: 100%|█| 50000/50000 [00:00<00:00, 121811.01 examp\nFilter: 100%|██████████████████| 25000/25000 [00:00<00:00, 165047.94 examples/s]\nMap:   0%|                                     | 0/24895 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\nMap: 100%|████████████████████████| 24895/24895 [00:32<00:00, 766.05 examples/s]\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-589\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\nconfig.json: 100%|█████████████████████████████| 687/687 [00:00<00:00, 2.29MB/s]\npytorch_model.bin: 100%|████████████████████| 1.42G/1.42G [00:06<00:00, 229MB/s]\ntokenizer_config.json: 100%|████████████████████| 256/256 [00:00<00:00, 686kB/s]\nvocab.json: 100%|████████████████████████████| 798k/798k [00:00<00:00, 3.12MB/s]\nmerges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 2.36MB/s]\nspecial_tokens_map.json: 100%|██████████████████| 150/150 [00:00<00:00, 466kB/s]\neval batch size 256\nFilter: 100%|████████████████████| 2500/2500 [00:00<00:00, 122797.02 examples/s]\nMap:   3%|▊                           | 75/2487 [00:00<00:03, 728.57 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\nMap: 100%|██████████████████████████| 2487/2487 [00:05<00:00, 494.63 examples/s]\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:40, 27.55s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:54<03:10, 27.15s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:21<02:42, 27.13s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:48<02:16, 27.20s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:15<01:48, 27.15s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:42<01:21, 27.12s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:10<00:54, 27.22s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:37<00:27, 27.19s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:04<00:00, 27.20s/it]\nmean test reward 0.8696662218084157 +/- 0.006913665586305454 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9987158179283142 from 0.00922983093187213\nmean KL 4.434547923505306 +/- 0.3950051229510039 full 25.415649870203602 +/- 0.15194129160578534\nmedian KL 7.794591665267944 full 24.72145938873291\nLoading from dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-558\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-558\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:37, 27.15s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:54<03:09, 27.08s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:21<02:42, 27.04s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:48<02:16, 27.21s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:15<01:48, 27.21s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:43<01:21, 27.21s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:10<00:54, 27.19s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:37<00:27, 27.23s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:05<00:00, 27.23s/it]\nmean test reward 0.863381361360881 +/- 0.0070600087951725 from 0.42866707400010756 +/- 0.010184844982943312\nmedian test reward 0.9986989498138428 from 0.009081022348254919\nmean KL 3.487027588662588 +/- 0.39041738983739344 full 22.544149375210207 +/- 0.13477775459136757\nmedian KL 7.502376079559326 full 22.07391357421875\nLoading from dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-527\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-527\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:26<03:35, 26.98s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:54<03:11, 27.32s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:21<02:43, 27.32s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:48<02:16, 27.25s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:16<01:49, 27.31s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:43<01:22, 27.36s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:11<00:54, 27.37s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:38<00:27, 27.32s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:05<00:00, 27.32s/it]\nmean test reward 0.8677279398248933 +/- 0.006962955737529344 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9987000226974487 from 0.00922983093187213\nmean KL 3.4348117106645883 +/- 0.337159414313619 full 19.632272987523013 +/- 0.11553961184918947\nmedian KL 6.578587532043457 full 19.121941566467285\nLoading from dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-496\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_05-2024.06.01.00.26/checkpoint-496\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:37, 27.22s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:54<03:09, 27.12s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:21<02:43, 27.18s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:48<02:16, 27.26s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:16<01:49, 27.29s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:43<01:22, 27.38s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:11<00:54, 27.34s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:38<00:27, 27.37s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:05<00:00, 27.31s/it]\nmean test reward 0.8633566346928269 +/- 0.007057235959294323 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9986914396286011 from 0.00922983093187213\nmean KL 2.9838871828202778 +/- 0.28934423615792976 full 16.546465497256982 +/- 0.09654726720657654\nmedian KL 5.834129571914673 full 16.057032585144043\ndpo_6c2_div36-0_05-2024.06.01.00.26,0.05,epoch 19,0.8696662218084157,0.006913665586305454,25.415649870203602,0.15194129160578534\ndpo_6c2_div36-0_05-2024.06.01.00.26,0.05,epoch 18,0.863381361360881,0.0070600087951725,22.544149375210207,0.13477775459136757\ndpo_6c2_div36-0_05-2024.06.01.00.26,0.05,epoch 17,0.8677279398248933,0.006962955737529344,19.632272987523013,0.11553961184918947\ndpo_6c2_div36-0_05-2024.06.01.00.26,0.05,epoch 16,0.8633566346928269,0.007057235959294323,16.546465497256982,0.09654726720657654\n","output_type":"stream"}]},{"cell_type":"code","source":"! rm -rf */*/optimizer.pt && git pull --rebase && python dpo.py  --output_dir=dpo_6c2_div36-0_1  --beta=0.1 --dataset_name=/kaggle/working/cs234-project/pref_pairs_16_token_6_choose_2_div_36_tokenized     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128  --per_device_eval_batch_size 128     --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 50     --report_to wandb     --logging_first_step --logging_strategy='steps' --logging_steps 50  --eval_steps=50 --no_remove_unused_columns --save_total_limit=4 --evaluation_strategy='steps' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch' --num_train_epochs=16","metadata":{"execution":{"iopub.status.busy":"2024-06-01T01:16:11.299695Z","iopub.execute_input":"2024-06-01T01:16:11.300183Z","iopub.status.idle":"2024-06-01T01:44:57.460737Z","shell.execute_reply.started":"2024-06-01T01:16:11.300143Z","shell.execute_reply":"2024-06-01T01:44:57.459667Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Already up to date.\nCurrent branch main is up to date.\n2024-06-01 01:16:18.616094: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-01 01:16:18.616153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-01 01:16:18.617637: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\nds len 4149\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240601_011625-o9faqae3\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdpo_6c2_div36-0_1\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface/runs/o9faqae3\u001b[0m\n  0%|                                                   | 0/496 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 0.6931, 'grad_norm': 2.41597580909729, 'learning_rate': 4e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -60.114646911621094, 'logps/chosen': -60.310203552246094, 'logits/rejected': -38.24871826171875, 'logits/chosen': -36.57445526123047, 'epoch': 0.03}\n{'loss': 0.686, 'grad_norm': 2.371826648712158, 'learning_rate': 2e-06, 'rewards/chosen': 0.006908418610692024, 'rewards/rejected': -0.007605490740388632, 'rewards/accuracies': 0.7741683721542358, 'rewards/margins': 0.014513908885419369, 'logps/rejected': -59.691280364990234, 'logps/chosen': -60.6182975769043, 'logits/rejected': -37.691558837890625, 'logits/chosen': -36.74099349975586, 'epoch': 1.61}\n 10%|████▏                                     | 50/496 [01:02<08:59,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6755723357200623, 'eval_runtime': 0.899, 'eval_samples_per_second': 231.368, 'eval_steps_per_second': 2.225, 'eval_rewards/chosen': 0.017259668558835983, 'eval_rewards/rejected': -0.01817307621240616, 'eval_rewards/accuracies': 0.8218749761581421, 'eval_rewards/margins': 0.03543274849653244, 'eval_logps/rejected': -59.697444915771484, 'eval_logps/chosen': -60.0036506652832, 'eval_logits/rejected': -39.01630401611328, 'eval_logits/chosen': -38.023406982421875, 'epoch': 1.61}\n 10%|████▏                                     | 50/496 [01:03<08:59,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.649, 'grad_norm': 2.1869001388549805, 'learning_rate': 2e-06, 'rewards/chosen': 0.036467183381319046, 'rewards/rejected': -0.0561436228454113, 'rewards/accuracies': 0.8654857873916626, 'rewards/margins': 0.09261081367731094, 'logps/rejected': -60.289154052734375, 'logps/chosen': -60.56439971923828, 'logits/rejected': -37.04914093017578, 'logits/chosen': -36.186248779296875, 'epoch': 3.23}\n 20%|████████▎                                | 100/496 [02:07<08:27,  1.28s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.641982913017273, 'eval_runtime': 0.9048, 'eval_samples_per_second': 229.874, 'eval_steps_per_second': 2.21, 'eval_rewards/chosen': 0.03721197694540024, 'eval_rewards/rejected': -0.07112899422645569, 'eval_rewards/accuracies': 0.831250011920929, 'eval_rewards/margins': 0.10834096372127533, 'eval_logps/rejected': -60.22700500488281, 'eval_logps/chosen': -59.80412292480469, 'eval_logits/rejected': -38.21501922607422, 'eval_logits/chosen': -37.33232116699219, 'epoch': 3.23}\n 20%|████████▎                                | 100/496 [02:08<08:27,  1.28s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.6032, 'grad_norm': 1.9519153833389282, 'learning_rate': 2e-06, 'rewards/chosen': 0.058214813470840454, 'rewards/rejected': -0.13853871822357178, 'rewards/accuracies': 0.8916336894035339, 'rewards/margins': 0.19675354659557343, 'logps/rejected': -60.933773040771484, 'logps/chosen': -60.08061218261719, 'logits/rejected': -36.370018005371094, 'logits/chosen': -35.56052780151367, 'epoch': 4.84}\n 30%|████████████▍                            | 150/496 [03:11<06:57,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6103217005729675, 'eval_runtime': 0.8969, 'eval_samples_per_second': 231.922, 'eval_steps_per_second': 2.23, 'eval_rewards/chosen': 0.03641805425286293, 'eval_rewards/rejected': -0.1481931507587433, 'eval_rewards/accuracies': 0.827343761920929, 'eval_rewards/margins': 0.18461120128631592, 'eval_logps/rejected': -60.99764633178711, 'eval_logps/chosen': -59.81206512451172, 'eval_logits/rejected': -37.47787857055664, 'eval_logits/chosen': -36.74671173095703, 'epoch': 4.84}\n 30%|████████████▍                            | 150/496 [03:12<06:57,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.558, 'grad_norm': 2.030489206314087, 'learning_rate': 2e-06, 'rewards/chosen': 0.0651150718331337, 'rewards/rejected': -0.24530695378780365, 'rewards/accuracies': 0.9027072787284851, 'rewards/margins': 0.31042203307151794, 'logps/rejected': -62.1445426940918, 'logps/chosen': -60.21690368652344, 'logits/rejected': -35.708412170410156, 'logits/chosen': -34.9290885925293, 'epoch': 6.45}\n 40%|████████████████▌                        | 200/496 [04:16<05:59,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5797894597053528, 'eval_runtime': 0.9015, 'eval_samples_per_second': 230.733, 'eval_steps_per_second': 2.219, 'eval_rewards/chosen': 0.017111357301473618, 'eval_rewards/rejected': -0.24964399635791779, 'eval_rewards/accuracies': 0.8171875476837158, 'eval_rewards/margins': 0.2667553424835205, 'eval_logps/rejected': -62.01215362548828, 'eval_logps/chosen': -60.005130767822266, 'eval_logits/rejected': -36.818359375, 'eval_logits/chosen': -36.27857208251953, 'epoch': 6.45}\n 40%|████████████████▌                        | 200/496 [04:17<05:59,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.5152, 'grad_norm': 1.9035615921020508, 'learning_rate': 2e-06, 'rewards/chosen': 0.041456159204244614, 'rewards/rejected': -0.3899526596069336, 'rewards/accuracies': 0.9049984812736511, 'rewards/margins': 0.4314088821411133, 'logps/rejected': -63.58498001098633, 'logps/chosen': -60.29557800292969, 'logits/rejected': -34.94895553588867, 'logits/chosen': -34.384132385253906, 'epoch': 8.06}\n 50%|████████████████████▋                    | 250/496 [05:22<06:59,  1.70s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5484131574630737, 'eval_runtime': 0.9044, 'eval_samples_per_second': 229.978, 'eval_steps_per_second': 2.211, 'eval_rewards/chosen': -0.023652581498026848, 'eval_rewards/rejected': -0.3855897784233093, 'eval_rewards/accuracies': 0.8374999761581421, 'eval_rewards/margins': 0.36193719506263733, 'eval_logps/rejected': -63.37161636352539, 'eval_logps/chosen': -60.41277313232422, 'eval_logits/rejected': -36.180633544921875, 'eval_logits/chosen': -35.878944396972656, 'epoch': 8.06}\n 50%|████████████████████▋                    | 250/496 [05:23<06:59,  1.70s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.4701, 'grad_norm': 1.7763264179229736, 'learning_rate': 2e-06, 'rewards/chosen': 0.015132435597479343, 'rewards/rejected': -0.5587894320487976, 'rewards/accuracies': 0.911593496799469, 'rewards/margins': 0.5739219188690186, 'logps/rejected': -65.11483001708984, 'logps/chosen': -60.63030242919922, 'logits/rejected': -34.39739990234375, 'logits/chosen': -33.66923904418945, 'epoch': 9.68}\n 60%|████████████████████████▊                | 300/496 [06:25<03:55,  1.20s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5168105959892273, 'eval_runtime': 0.8979, 'eval_samples_per_second': 231.641, 'eval_steps_per_second': 2.227, 'eval_rewards/chosen': -0.08812132477760315, 'eval_rewards/rejected': -0.5588417053222656, 'eval_rewards/accuracies': 0.83984375, 'eval_rewards/margins': 0.4707203209400177, 'eval_logps/rejected': -65.10413360595703, 'eval_logps/chosen': -61.057456970214844, 'eval_logits/rejected': -35.554588317871094, 'eval_logits/chosen': -35.53788757324219, 'epoch': 9.68}\n 60%|████████████████████████▊                | 300/496 [06:26<03:55,  1.20s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.4256, 'grad_norm': 1.746036410331726, 'learning_rate': 2e-06, 'rewards/chosen': -0.05942230299115181, 'rewards/rejected': -0.794375479221344, 'rewards/accuracies': 0.9199984669685364, 'rewards/margins': 0.7349531650543213, 'logps/rejected': -67.63749694824219, 'logps/chosen': -61.25794982910156, 'logits/rejected': -33.852684020996094, 'logits/chosen': -33.45843505859375, 'epoch': 11.29}\n 71%|████████████████████████████▉            | 350/496 [07:31<03:02,  1.25s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.487888365983963, 'eval_runtime': 0.8961, 'eval_samples_per_second': 232.109, 'eval_steps_per_second': 2.232, 'eval_rewards/chosen': -0.1861249804496765, 'eval_rewards/rejected': -0.7798461318016052, 'eval_rewards/accuracies': 0.8578125238418579, 'eval_rewards/margins': 0.5937211513519287, 'eval_logps/rejected': -67.31417846679688, 'eval_logps/chosen': -62.037498474121094, 'eval_logits/rejected': -34.913787841796875, 'eval_logits/chosen': -35.277427673339844, 'epoch': 11.29}\n 71%|████████████████████████████▉            | 350/496 [07:32<03:02,  1.25s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\u001b[A\n{'loss': 0.3817, 'grad_norm': 1.6424076557159424, 'learning_rate': 2e-06, 'rewards/chosen': -0.13737036287784576, 'rewards/rejected': -1.0568405389785767, 'rewards/accuracies': 0.9261757731437683, 'rewards/margins': 0.9194700717926025, 'logps/rejected': -70.32316589355469, 'logps/chosen': -62.24287033081055, 'logits/rejected': -33.276878356933594, 'logits/chosen': -32.812557220458984, 'epoch': 12.9}\n 81%|█████████████████████████████████        | 400/496 [08:35<01:55,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.459762841463089, 'eval_runtime': 0.8969, 'eval_samples_per_second': 231.921, 'eval_steps_per_second': 2.23, 'eval_rewards/chosen': -0.30221521854400635, 'eval_rewards/rejected': -1.0403447151184082, 'eval_rewards/accuracies': 0.8460937738418579, 'eval_rewards/margins': 0.7381294965744019, 'eval_logps/rejected': -69.9191665649414, 'eval_logps/chosen': -63.198394775390625, 'eval_logits/rejected': -34.096397399902344, 'eval_logits/chosen': -34.822547912597656, 'epoch': 12.9}\n 81%|█████████████████████████████████        | 400/496 [08:35<01:55,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\u001b[A\n{'loss': 0.3408, 'grad_norm': 1.6387901306152344, 'learning_rate': 2e-06, 'rewards/chosen': -0.2507602572441101, 'rewards/rejected': -1.3671108484268188, 'rewards/accuracies': 0.9370405673980713, 'rewards/margins': 1.1163506507873535, 'logps/rejected': -73.2995376586914, 'logps/chosen': -63.23854064941406, 'logits/rejected': -32.28941345214844, 'logits/chosen': -32.169090270996094, 'epoch': 14.52}\n 91%|█████████████████████████████████████▏   | 450/496 [09:40<00:55,  1.21s/it]evaluation_loop\n\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.4344642460346222, 'eval_runtime': 0.8995, 'eval_samples_per_second': 231.237, 'eval_steps_per_second': 2.223, 'eval_rewards/chosen': -0.45769864320755005, 'eval_rewards/rejected': -1.3608782291412354, 'eval_rewards/accuracies': 0.8539062738418579, 'eval_rewards/margins': 0.9031794667243958, 'eval_logps/rejected': -73.12449645996094, 'eval_logps/chosen': -64.75323486328125, 'eval_logits/rejected': -32.97685241699219, 'eval_logits/chosen': -34.122100830078125, 'epoch': 14.52}\n 91%|█████████████████████████████████████▏   | 450/496 [09:41<00:55,  1.21s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.20it/s]\u001b[A\n{'train_runtime': 657.7742, 'train_samples_per_second': 95.863, 'train_steps_per_second': 0.754, 'train_loss': 0.49441063884765873, 'epoch': 16.0}\n100%|█████████████████████████████████████████| 496/496 [10:41<00:00,  1.29s/it]\nEvaling epochs [16, 15, 14, 13]\nLoading from dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-496\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-496\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:41, 27.70s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:55<03:13, 27.69s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:23<02:46, 27.70s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:50<02:18, 27.76s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:18<01:51, 27.75s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:46<01:23, 27.79s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:14<00:55, 27.81s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:42<00:27, 27.80s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:09<00:00, 27.78s/it]\nmean test reward 0.8451534757576584 +/- 0.007423066112122984 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9986438155174255 from 0.00922983093187213\nmean KL 1.3335707726526178 +/- 0.19133828012891832 full 10.095174830406904 +/- 0.05907065663310598\nmedian KL 2.664287805557251 full 9.758732795715332\nLoading from dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-465\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-465\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:40, 27.58s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:55<03:13, 27.68s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:23<02:46, 27.73s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:50<02:18, 27.73s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:18<01:51, 27.85s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:47<01:23, 27.97s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:15<00:55, 27.96s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:43<00:27, 27.96s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:11<00:00, 27.91s/it]\nmean test reward 0.8352354859268113 +/- 0.007611316948449703 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9986165165901184 from 0.00922983093187213\nmean KL 1.1766460476792417 +/- 0.17584171624916367 full 8.792581969044274 +/- 0.05299333820822327\nmedian KL 2.493056535720825 full 8.438868522644043\nLoading from dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-434\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-434\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:41, 27.63s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:55<03:14, 27.84s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:23<02:47, 27.86s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:51<02:19, 27.89s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:19<01:51, 27.93s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:47<01:23, 27.85s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:14<00:55, 27.81s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:42<00:27, 27.86s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:10<00:00, 27.86s/it]\nmean test reward 0.8290229678945151 +/- 0.007715817552013914 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9985805749893188 from 0.00922983093187213\nmean KL 1.062667634881412 +/- 0.16165279209838002 full 7.537266090512276 +/- 0.046478149744471446\nmedian KL 2.4359641075134277 full 7.236116886138916\nLoading from dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-403\nload ref model lvwerra/gpt2-imdb\nload train model dpo_6c2_div36-0_1-2024.06.01.01.16/checkpoint-403\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:41, 27.65s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:55<03:13, 27.66s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:22<02:45, 27.66s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:50<02:18, 27.78s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:18<01:51, 27.86s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:46<01:23, 27.87s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:14<00:55, 27.91s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:42<00:27, 27.88s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:10<00:00, 27.85s/it]\nmean test reward 0.82016204739701 +/- 0.007888089727548816 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9985361099243164 from 0.00922983093187213\nmean KL 0.9443232406111848 +/- 0.14566982360605338 full 6.354444556662606 +/- 0.03956816006058312\nmedian KL 2.232743263244629 full 6.129606485366821\ndpo_6c2_div36-0_1-2024.06.01.01.16,0.1,epoch 16,0.8451534757576584,0.007423066112122984,10.095174830406904,0.05907065663310598\ndpo_6c2_div36-0_1-2024.06.01.01.16,0.1,epoch 15,0.8352354859268113,0.007611316948449703,8.792581969044274,0.05299333820822327\ndpo_6c2_div36-0_1-2024.06.01.01.16,0.1,epoch 14,0.8290229678945151,0.007715817552013914,7.537266090512276,0.046478149744471446\ndpo_6c2_div36-0_1-2024.06.01.01.16,0.1,epoch 13,0.82016204739701,0.007888089727548816,6.354444556662606,0.03956816006058312\n","output_type":"stream"}]},{"cell_type":"code","source":"! python dpo.py  --loss_type=ipo --output_dir=test_ipo_0_3_lr2e_6  --beta=0.3 --dataset_name=/kaggle/working/cs234-project/pref_pairs_16_token_tokenized_split     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128  --per_device_eval_batch_size 128     --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 150     --report_to wandb     --logging_first_step --logging_strategy='steps' --logging_steps 50  --eval_steps=500 --no_remove_unused_columns --save_total_limit=4 --evaluation_strategy='steps' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch'","metadata":{"execution":{"iopub.status.busy":"2024-06-01T01:52:21.685852Z","iopub.execute_input":"2024-06-01T01:52:21.686660Z","iopub.status.idle":"2024-06-01T03:17:30.445704Z","shell.execute_reply.started":"2024-06-01T01:52:21.686618Z","shell.execute_reply":"2024-06-01T03:17:30.444329Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"2024-06-01 01:52:28.184326: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-01 01:52:28.184384: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-01 01:52:28.185941: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\nds len 149370\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240601_015236-g3plx68r\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtest_ipo_0_3_lr2e_6\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface/runs/g3plx68r\u001b[0m\n  0%|                                                  | 0/3327 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 2.7778, 'grad_norm': 9.637479782104492, 'learning_rate': 1.3333333333333334e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -3.736757755279541, 'logps/chosen': -3.8562333583831787, 'logits/rejected': -39.777442932128906, 'logits/chosen': -37.3552131652832, 'epoch': 0.0}\n{'loss': 2.7745, 'grad_norm': 9.871687889099121, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': 0.00012629669799935073, 'rewards/rejected': -0.0001656251697568223, 'rewards/accuracies': 0.6592793464660645, 'rewards/margins': 0.000291921867756173, 'logps/rejected': -3.8712146282196045, 'logps/chosen': -3.8451051712036133, 'logits/rejected': -37.495365142822266, 'logits/chosen': -36.51926040649414, 'epoch': 0.05}\n{'loss': 2.7545, 'grad_norm': 10.659533500671387, 'learning_rate': 1.3333333333333332e-06, 'rewards/chosen': 0.0006950526731088758, 'rewards/rejected': -0.0014274977147579193, 'rewards/accuracies': 0.6909375190734863, 'rewards/margins': 0.0021225502714514732, 'logps/rejected': -3.8469631671905518, 'logps/chosen': -3.8276267051696777, 'logits/rejected': -37.162044525146484, 'logits/chosen': -36.406333923339844, 'epoch': 0.09}\n{'loss': 2.7131, 'grad_norm': 9.544535636901855, 'learning_rate': 2e-06, 'rewards/chosen': 0.0007639204850420356, 'rewards/rejected': -0.005240658298134804, 'rewards/accuracies': 0.6884375214576721, 'rewards/margins': 0.006004578899592161, 'logps/rejected': -3.8930859565734863, 'logps/chosen': -3.8176774978637695, 'logits/rejected': -36.85185623168945, 'logits/chosen': -35.93482971191406, 'epoch': 0.14}\n{'loss': 2.6544, 'grad_norm': 10.3782320022583, 'learning_rate': 2e-06, 'rewards/chosen': -0.0018497765995562077, 'rewards/rejected': -0.013666135258972645, 'rewards/accuracies': 0.6956250071525574, 'rewards/margins': 0.011816357262432575, 'logps/rejected': -3.882467031478882, 'logps/chosen': -3.840791940689087, 'logits/rejected': -36.753883361816406, 'logits/chosen': -35.927188873291016, 'epoch': 0.18}\n{'loss': 2.5948, 'grad_norm': 9.924677848815918, 'learning_rate': 2e-06, 'rewards/chosen': -0.009001817554235458, 'rewards/rejected': -0.027084901928901672, 'rewards/accuracies': 0.6935937404632568, 'rewards/margins': 0.018083084374666214, 'logps/rejected': -3.9288482666015625, 'logps/chosen': -3.8463659286499023, 'logits/rejected': -36.598114013671875, 'logits/chosen': -35.88262176513672, 'epoch': 0.23}\n{'loss': 2.5445, 'grad_norm': 10.30093002319336, 'learning_rate': 2e-06, 'rewards/chosen': -0.019554590806365013, 'rewards/rejected': -0.04367579147219658, 'rewards/accuracies': 0.6878125071525574, 'rewards/margins': 0.024121198803186417, 'logps/rejected': -4.002589225769043, 'logps/chosen': -3.885524034500122, 'logits/rejected': -36.236968994140625, 'logits/chosen': -35.8398551940918, 'epoch': 0.27}\n{'loss': 2.4808, 'grad_norm': 9.509725570678711, 'learning_rate': 2e-06, 'rewards/chosen': -0.03365463390946388, 'rewards/rejected': -0.06556036323308945, 'rewards/accuracies': 0.69140625, 'rewards/margins': 0.031905725598335266, 'logps/rejected': -4.065006256103516, 'logps/chosen': -3.9269156455993652, 'logits/rejected': -36.03829574584961, 'logits/chosen': -35.46926498413086, 'epoch': 0.32}\n{'loss': 2.4231, 'grad_norm': 8.998885154724121, 'learning_rate': 2e-06, 'rewards/chosen': -0.0512814037501812, 'rewards/rejected': -0.09102313220500946, 'rewards/accuracies': 0.6990625262260437, 'rewards/margins': 0.03974172845482826, 'logps/rejected': -4.14363431930542, 'logps/chosen': -3.9952476024627686, 'logits/rejected': -35.859527587890625, 'logits/chosen': -35.266807556152344, 'epoch': 0.36}\n{'loss': 2.3829, 'grad_norm': 11.13301944732666, 'learning_rate': 2e-06, 'rewards/chosen': -0.0724286288022995, 'rewards/rejected': -0.11936576664447784, 'rewards/accuracies': 0.6910937428474426, 'rewards/margins': 0.046937137842178345, 'logps/rejected': -4.242405891418457, 'logps/chosen': -4.065666675567627, 'logits/rejected': -35.786624908447266, 'logits/chosen': -35.336124420166016, 'epoch': 0.41}\n{'loss': 2.3296, 'grad_norm': 9.04806900024414, 'learning_rate': 2e-06, 'rewards/chosen': -0.08816096186637878, 'rewards/rejected': -0.14344657957553864, 'rewards/accuracies': 0.6996874809265137, 'rewards/margins': 0.055285610258579254, 'logps/rejected': -4.316744804382324, 'logps/chosen': -4.128403186798096, 'logits/rejected': -35.32931137084961, 'logits/chosen': -34.74541473388672, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [10:13<58:25,  1.24s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.63it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.56it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.84it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:24,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.82it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.82it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:21,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.80it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.82it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:25<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.82it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.3259024620056152, 'eval_runtime': 32.6003, 'eval_samples_per_second': 229.109, 'eval_steps_per_second': 1.81, 'eval_rewards/chosen': -0.09775860607624054, 'eval_rewards/rejected': -0.15445367991924286, 'eval_rewards/accuracies': 0.6949594020843506, 'eval_rewards/margins': 0.05669507384300232, 'eval_logps/rejected': -4.357619285583496, 'eval_logps/chosen': -4.146974563598633, 'eval_logits/rejected': -35.2765007019043, 'eval_logits/chosen': -34.841880798339844, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [10:46<58:25,  1.24s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 2.3026, 'grad_norm': 8.866583824157715, 'learning_rate': 2e-06, 'rewards/chosen': -0.10450273752212524, 'rewards/rejected': -0.16485637426376343, 'rewards/accuracies': 0.7035937309265137, 'rewards/margins': 0.06035362556576729, 'logps/rejected': -4.402736663818359, 'logps/chosen': -4.187499523162842, 'logits/rejected': -35.21079635620117, 'logits/chosen': -34.79197311401367, 'epoch': 0.5}\n{'loss': 2.2585, 'grad_norm': 9.762731552124023, 'learning_rate': 2e-06, 'rewards/chosen': -0.12300025671720505, 'rewards/rejected': -0.19113145768642426, 'rewards/accuracies': 0.6993749737739563, 'rewards/margins': 0.06813120096921921, 'logps/rejected': -4.499264240264893, 'logps/chosen': -4.236473560333252, 'logits/rejected': -34.888912200927734, 'logits/chosen': -34.27997970581055, 'epoch': 0.54}\n{'loss': 2.264, 'grad_norm': 8.809305191040039, 'learning_rate': 2e-06, 'rewards/chosen': -0.13695330917835236, 'rewards/rejected': -0.20736517012119293, 'rewards/accuracies': 0.6965625286102295, 'rewards/margins': 0.07041186094284058, 'logps/rejected': -4.561252117156982, 'logps/chosen': -4.276440620422363, 'logits/rejected': -34.61540985107422, 'logits/chosen': -34.29369354248047, 'epoch': 0.59}\n{'loss': 2.2298, 'grad_norm': 9.431971549987793, 'learning_rate': 2e-06, 'rewards/chosen': -0.1508701741695404, 'rewards/rejected': -0.2284325212240219, 'rewards/accuracies': 0.6971874833106995, 'rewards/margins': 0.07756232470273972, 'logps/rejected': -4.59922981262207, 'logps/chosen': -4.340275287628174, 'logits/rejected': -34.415321350097656, 'logits/chosen': -34.087642669677734, 'epoch': 0.63}\n{'loss': 2.2204, 'grad_norm': 10.47300910949707, 'learning_rate': 2e-06, 'rewards/chosen': -0.15679660439491272, 'rewards/rejected': -0.23685726523399353, 'rewards/accuracies': 0.6982812285423279, 'rewards/margins': 0.08006063103675842, 'logps/rejected': -4.61113166809082, 'logps/chosen': -4.357213020324707, 'logits/rejected': -34.30779266357422, 'logits/chosen': -33.953792572021484, 'epoch': 0.68}\n{'loss': 2.2196, 'grad_norm': 9.965638160705566, 'learning_rate': 2e-06, 'rewards/chosen': -0.16191257536411285, 'rewards/rejected': -0.2424757033586502, 'rewards/accuracies': 0.7028124928474426, 'rewards/margins': 0.08056313544511795, 'logps/rejected': -4.644721031188965, 'logps/chosen': -4.3557963371276855, 'logits/rejected': -34.38227844238281, 'logits/chosen': -34.129661560058594, 'epoch': 0.72}\n{'loss': 2.1593, 'grad_norm': 8.531286239624023, 'learning_rate': 2e-06, 'rewards/chosen': -0.1706572026014328, 'rewards/rejected': -0.25982901453971863, 'rewards/accuracies': 0.7139062285423279, 'rewards/margins': 0.08917184919118881, 'logps/rejected': -4.721078395843506, 'logps/chosen': -4.406505584716797, 'logits/rejected': -34.1179313659668, 'logits/chosen': -33.793601989746094, 'epoch': 0.77}\n{'loss': 2.1982, 'grad_norm': 9.158125877380371, 'learning_rate': 2e-06, 'rewards/chosen': -0.18366692960262299, 'rewards/rejected': -0.2714393436908722, 'rewards/accuracies': 0.7049999833106995, 'rewards/margins': 0.0877724289894104, 'logps/rejected': -4.748573303222656, 'logps/chosen': -4.451866626739502, 'logits/rejected': -34.044124603271484, 'logits/chosen': -33.65607833862305, 'epoch': 0.81}\n{'loss': 2.1732, 'grad_norm': 9.68702220916748, 'learning_rate': 2e-06, 'rewards/chosen': -0.18799006938934326, 'rewards/rejected': -0.2811199426651001, 'rewards/accuracies': 0.7051562666893005, 'rewards/margins': 0.09312987327575684, 'logps/rejected': -4.77590799331665, 'logps/chosen': -4.439661026000977, 'logits/rejected': -33.7318229675293, 'logits/chosen': -33.56086349487305, 'epoch': 0.86}\n{'loss': 2.1318, 'grad_norm': 9.570418357849121, 'learning_rate': 2e-06, 'rewards/chosen': -0.19203457236289978, 'rewards/rejected': -0.2896517813205719, 'rewards/accuracies': 0.71484375, 'rewards/margins': 0.09761721640825272, 'logps/rejected': -4.806123733520508, 'logps/chosen': -4.45314884185791, 'logits/rejected': -33.52870178222656, 'logits/chosen': -33.3570442199707, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [21:05<47:47,  1.23s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.59it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:22,  2.54it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.16it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.95it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.90it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.87it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:27,  1.84it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:05<00:26,  1.83it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.82it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.82it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.82it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.81it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.1318020820617676, 'eval_runtime': 32.615, 'eval_samples_per_second': 229.005, 'eval_steps_per_second': 1.809, 'eval_rewards/chosen': -0.19770948588848114, 'eval_rewards/rejected': -0.29608359932899475, 'eval_rewards/accuracies': 0.7122645974159241, 'eval_rewards/margins': 0.09837412089109421, 'eval_logps/rejected': -4.829719066619873, 'eval_logps/chosen': -4.480144500732422, 'eval_logits/rejected': -33.399871826171875, 'eval_logits/chosen': -33.19938278198242, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [21:38<47:47,  1.23s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 2.1293, 'grad_norm': 8.692316055297852, 'learning_rate': 2e-06, 'rewards/chosen': -0.19793559610843658, 'rewards/rejected': -0.2972927391529083, 'rewards/accuracies': 0.7151562571525574, 'rewards/margins': 0.09935712069272995, 'logps/rejected': -4.855541229248047, 'logps/chosen': -4.480777740478516, 'logits/rejected': -33.540218353271484, 'logits/chosen': -33.28354263305664, 'epoch': 0.95}\n{'loss': 2.0921, 'grad_norm': 9.5712890625, 'learning_rate': 2e-06, 'rewards/chosen': -0.2032194286584854, 'rewards/rejected': -0.30928659439086914, 'rewards/accuracies': 0.7235937714576721, 'rewards/margins': 0.10606720298528671, 'logps/rejected': -4.875179767608643, 'logps/chosen': -4.514461517333984, 'logits/rejected': -33.2236328125, 'logits/chosen': -33.077693939208984, 'epoch': 0.99}\n{'loss': 2.0891, 'grad_norm': 8.722036361694336, 'learning_rate': 2e-06, 'rewards/chosen': -0.20500196516513824, 'rewards/rejected': -0.3123559057712555, 'rewards/accuracies': 0.7278814911842346, 'rewards/margins': 0.10735393315553665, 'logps/rejected': -4.867324352264404, 'logps/chosen': -4.4768757820129395, 'logits/rejected': -33.09759521484375, 'logits/chosen': -32.76628494262695, 'epoch': 1.04}\n{'loss': 2.0179, 'grad_norm': 9.756139755249023, 'learning_rate': 2e-06, 'rewards/chosen': -0.20704655349254608, 'rewards/rejected': -0.32306140661239624, 'rewards/accuracies': 0.7403125166893005, 'rewards/margins': 0.11601489037275314, 'logps/rejected': -4.937026500701904, 'logps/chosen': -4.5174760818481445, 'logits/rejected': -32.87044906616211, 'logits/chosen': -32.60398864746094, 'epoch': 1.08}\n{'loss': 2.0383, 'grad_norm': 8.875890731811523, 'learning_rate': 2e-06, 'rewards/chosen': -0.21564631164073944, 'rewards/rejected': -0.3310922384262085, 'rewards/accuracies': 0.739062488079071, 'rewards/margins': 0.11544589698314667, 'logps/rejected': -4.934377670288086, 'logps/chosen': -4.5380024909973145, 'logits/rejected': -33.327945709228516, 'logits/chosen': -33.132930755615234, 'epoch': 1.13}\n{'loss': 1.9935, 'grad_norm': 8.488285064697266, 'learning_rate': 2e-06, 'rewards/chosen': -0.21758070588111877, 'rewards/rejected': -0.33783969283103943, 'rewards/accuracies': 0.7407812476158142, 'rewards/margins': 0.12025902420282364, 'logps/rejected': -4.967657089233398, 'logps/chosen': -4.5479044914245605, 'logits/rejected': -33.09341049194336, 'logits/chosen': -32.82760238647461, 'epoch': 1.17}\n{'loss': 1.9965, 'grad_norm': 9.213492393493652, 'learning_rate': 2e-06, 'rewards/chosen': -0.22514158487319946, 'rewards/rejected': -0.348245233297348, 'rewards/accuracies': 0.7440624833106995, 'rewards/margins': 0.12310364097356796, 'logps/rejected': -5.030068874359131, 'logps/chosen': -4.570101261138916, 'logits/rejected': -32.4244384765625, 'logits/chosen': -32.584957122802734, 'epoch': 1.22}\n{'loss': 2.0158, 'grad_norm': 8.984728813171387, 'learning_rate': 2e-06, 'rewards/chosen': -0.2354661524295807, 'rewards/rejected': -0.35621047019958496, 'rewards/accuracies': 0.7385937571525574, 'rewards/margins': 0.12074430286884308, 'logps/rejected': -5.044552803039551, 'logps/chosen': -4.634166717529297, 'logits/rejected': -32.53825378417969, 'logits/chosen': -32.4353141784668, 'epoch': 1.26}\n{'loss': 2.032, 'grad_norm': 9.381531715393066, 'learning_rate': 2e-06, 'rewards/chosen': -0.2291741818189621, 'rewards/rejected': -0.35100382566452026, 'rewards/accuracies': 0.7353125214576721, 'rewards/margins': 0.12182968109846115, 'logps/rejected': -5.019258499145508, 'logps/chosen': -4.581435203552246, 'logits/rejected': -32.574546813964844, 'logits/chosen': -32.48637771606445, 'epoch': 1.31}\n{'loss': 2.0582, 'grad_norm': 9.22081470489502, 'learning_rate': 2e-06, 'rewards/chosen': -0.23433448374271393, 'rewards/rejected': -0.34862610697746277, 'rewards/accuracies': 0.7253124713897705, 'rewards/margins': 0.11429166793823242, 'logps/rejected': -5.004870414733887, 'logps/chosen': -4.612256050109863, 'logits/rejected': -32.28533935546875, 'logits/chosen': -32.19997024536133, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [32:00<37:18,  1.23s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.58it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:26,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.92it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.89it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.87it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:24,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.82it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.82it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:21,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.82it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.81it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:25<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 2.043449640274048, 'eval_runtime': 32.5449, 'eval_samples_per_second': 229.498, 'eval_steps_per_second': 1.813, 'eval_rewards/chosen': -0.23237203061580658, 'eval_rewards/rejected': -0.34995236992836, 'eval_rewards/accuracies': 0.7312706112861633, 'eval_rewards/margins': 0.11758039146661758, 'eval_logps/rejected': -5.009282112121582, 'eval_logps/chosen': -4.595685958862305, 'eval_logits/rejected': -32.46738815307617, 'eval_logits/chosen': -32.39274597167969, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [32:33<37:18,  1.23s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 1.9928, 'grad_norm': 10.364508628845215, 'learning_rate': 2e-06, 'rewards/chosen': -0.2312249392271042, 'rewards/rejected': -0.3546530604362488, 'rewards/accuracies': 0.7440624833106995, 'rewards/margins': 0.12342808395624161, 'logps/rejected': -5.012974739074707, 'logps/chosen': -4.592971324920654, 'logits/rejected': -32.78140640258789, 'logits/chosen': -32.55863952636719, 'epoch': 1.4}\n{'loss': 1.9644, 'grad_norm': 8.882752418518066, 'learning_rate': 2e-06, 'rewards/chosen': -0.23522216081619263, 'rewards/rejected': -0.36427611112594604, 'rewards/accuracies': 0.7450000047683716, 'rewards/margins': 0.12905395030975342, 'logps/rejected': -5.061664581298828, 'logps/chosen': -4.591058731079102, 'logits/rejected': -33.23746109008789, 'logits/chosen': -33.0404167175293, 'epoch': 1.44}\n{'loss': 1.9618, 'grad_norm': 8.623370170593262, 'learning_rate': 2e-06, 'rewards/chosen': -0.23930318653583527, 'rewards/rejected': -0.3695114552974701, 'rewards/accuracies': 0.7445312738418579, 'rewards/margins': 0.13020829856395721, 'logps/rejected': -5.0785441398620605, 'logps/chosen': -4.624356746673584, 'logits/rejected': -32.965415954589844, 'logits/chosen': -32.79548263549805, 'epoch': 1.49}\n{'loss': 2.0155, 'grad_norm': 8.878945350646973, 'learning_rate': 2e-06, 'rewards/chosen': -0.2379549741744995, 'rewards/rejected': -0.3628098964691162, 'rewards/accuracies': 0.7367187738418579, 'rewards/margins': 0.12485494464635849, 'logps/rejected': -5.052811622619629, 'logps/chosen': -4.60207986831665, 'logits/rejected': -32.78230667114258, 'logits/chosen': -32.85554122924805, 'epoch': 1.53}\n{'loss': 1.9456, 'grad_norm': 9.513871192932129, 'learning_rate': 2e-06, 'rewards/chosen': -0.23872607946395874, 'rewards/rejected': -0.36959898471832275, 'rewards/accuracies': 0.7581250071525574, 'rewards/margins': 0.1308729201555252, 'logps/rejected': -5.082091331481934, 'logps/chosen': -4.625504493713379, 'logits/rejected': -32.626739501953125, 'logits/chosen': -32.60647964477539, 'epoch': 1.58}\n{'loss': 1.9877, 'grad_norm': 8.88181209564209, 'learning_rate': 2e-06, 'rewards/chosen': -0.24645841121673584, 'rewards/rejected': -0.3760394752025604, 'rewards/accuracies': 0.7357812523841858, 'rewards/margins': 0.12958106398582458, 'logps/rejected': -5.099145412445068, 'logps/chosen': -4.666964530944824, 'logits/rejected': -32.478111267089844, 'logits/chosen': -32.47116470336914, 'epoch': 1.62}\n{'loss': 1.9814, 'grad_norm': 9.569737434387207, 'learning_rate': 2e-06, 'rewards/chosen': -0.24363498389720917, 'rewards/rejected': -0.3740663230419159, 'rewards/accuracies': 0.7443749904632568, 'rewards/margins': 0.13043132424354553, 'logps/rejected': -5.1073713302612305, 'logps/chosen': -4.628997802734375, 'logits/rejected': -32.24254608154297, 'logits/chosen': -32.206260681152344, 'epoch': 1.67}\n{'loss': 1.9844, 'grad_norm': 9.613801002502441, 'learning_rate': 2e-06, 'rewards/chosen': -0.24669960141181946, 'rewards/rejected': -0.37595874071121216, 'rewards/accuracies': 0.7440624833106995, 'rewards/margins': 0.1292591243982315, 'logps/rejected': -5.102334499359131, 'logps/chosen': -4.662456035614014, 'logits/rejected': -32.69061279296875, 'logits/chosen': -32.73568344116211, 'epoch': 1.71}\n{'loss': 1.9958, 'grad_norm': 8.383513450622559, 'learning_rate': 2e-06, 'rewards/chosen': -0.24234561622142792, 'rewards/rejected': -0.37024986743927, 'rewards/accuracies': 0.7421875, 'rewards/margins': 0.12790422141551971, 'logps/rejected': -5.080732822418213, 'logps/chosen': -4.641356468200684, 'logits/rejected': -32.75825500488281, 'logits/chosen': -33.022972106933594, 'epoch': 1.76}\n{'loss': 1.964, 'grad_norm': 9.61351203918457, 'learning_rate': 2e-06, 'rewards/chosen': -0.24095067381858826, 'rewards/rejected': -0.3718457818031311, 'rewards/accuracies': 0.7471874952316284, 'rewards/margins': 0.13089509308338165, 'logps/rejected': -5.1111931800842285, 'logps/chosen': -4.625885963439941, 'logits/rejected': -32.932735443115234, 'logits/chosen': -32.763404846191406, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [42:50<27:22,  1.24s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.84it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:24,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.82it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.82it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:21,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:10,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.82it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:25<00:08,  1.53it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:07,  1.61it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.64it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.69it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.73it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.75it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.77it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:29<00:03,  1.79it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.77it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:30<00:02,  1.76it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.75it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.76it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.9913408756256104, 'eval_runtime': 32.9205, 'eval_samples_per_second': 226.88, 'eval_steps_per_second': 1.792, 'eval_rewards/chosen': -0.2491917908191681, 'eval_rewards/rejected': -0.37734708189964294, 'eval_rewards/accuracies': 0.7392361164093018, 'eval_rewards/margins': 0.12815529108047485, 'eval_logps/rejected': -5.100597858428955, 'eval_logps/chosen': -4.65175199508667, 'eval_logits/rejected': -32.857181549072266, 'eval_logits/chosen': -32.90809631347656, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [43:23<27:22,  1.24s/it]\n100%|███████████████████████████████████████████| 59/59 [00:32<00:00,  2.19it/s]\u001b[A\n{'loss': 1.94, 'grad_norm': 10.513936996459961, 'learning_rate': 2e-06, 'rewards/chosen': -0.24754253029823303, 'rewards/rejected': -0.38359978795051575, 'rewards/accuracies': 0.7521874904632568, 'rewards/margins': 0.13605721294879913, 'logps/rejected': -5.105106353759766, 'logps/chosen': -4.647428035736084, 'logits/rejected': -33.14690017700195, 'logits/chosen': -33.097679138183594, 'epoch': 1.85}\n{'loss': 1.9212, 'grad_norm': 9.52083683013916, 'learning_rate': 2e-06, 'rewards/chosen': -0.24864313006401062, 'rewards/rejected': -0.3862111568450928, 'rewards/accuracies': 0.7496874928474426, 'rewards/margins': 0.13756804168224335, 'logps/rejected': -5.147360324859619, 'logps/chosen': -4.6631178855896, 'logits/rejected': -33.01424789428711, 'logits/chosen': -33.074710845947266, 'epoch': 1.89}\n{'loss': 1.9487, 'grad_norm': 9.488874435424805, 'learning_rate': 2e-06, 'rewards/chosen': -0.25437214970588684, 'rewards/rejected': -0.38902682065963745, 'rewards/accuracies': 0.7479687333106995, 'rewards/margins': 0.13465473055839539, 'logps/rejected': -5.143701076507568, 'logps/chosen': -4.688302040100098, 'logits/rejected': -32.83165740966797, 'logits/chosen': -32.89464569091797, 'epoch': 1.94}\n{'loss': 1.8272, 'grad_norm': 9.559123992919922, 'learning_rate': 2e-06, 'rewards/chosen': -0.27857476472854614, 'rewards/rejected': -0.4355241656303406, 'rewards/accuracies': 0.7709375023841858, 'rewards/margins': 0.15694940090179443, 'logps/rejected': -5.2904839515686035, 'logps/chosen': -4.74272346496582, 'logits/rejected': -34.55848693847656, 'logits/chosen': -34.740455627441406, 'epoch': 2.48}\n{'loss': 1.8182, 'grad_norm': 10.739920616149902, 'learning_rate': 2e-06, 'rewards/chosen': -0.2818479537963867, 'rewards/rejected': -0.43933963775634766, 'rewards/accuracies': 0.7774999737739563, 'rewards/margins': 0.15749168395996094, 'logps/rejected': -5.317718505859375, 'logps/chosen': -4.768738746643066, 'logits/rejected': -35.22868347167969, 'logits/chosen': -35.231964111328125, 'epoch': 2.66}\n{'loss': 1.7786, 'grad_norm': 10.26533317565918, 'learning_rate': 2e-06, 'rewards/chosen': -0.28797295689582825, 'rewards/rejected': -0.4493238031864166, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.16135086119174957, 'logps/rejected': -5.358458042144775, 'logps/chosen': -4.77802848815918, 'logits/rejected': -35.22822189331055, 'logits/chosen': -35.46159744262695, 'epoch': 2.71}\n 90%|█████████████████████████████████▎   | 3000/3327 [1:04:28<06:37,  1.22s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.87it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.84it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:24,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:21,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.80it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.82it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:10,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.80it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.82it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.81it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:25<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.81it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.82it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.76it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.919816017150879, 'eval_runtime': 32.5978, 'eval_samples_per_second': 229.126, 'eval_steps_per_second': 1.81, 'eval_rewards/chosen': -0.2958502471446991, 'eval_rewards/rejected': -0.443645179271698, 'eval_rewards/accuracies': 0.753363311290741, 'eval_rewards/margins': 0.1477949172258377, 'eval_logps/rejected': -5.321590900421143, 'eval_logps/chosen': -4.80728006362915, 'eval_logits/rejected': -35.10792922973633, 'eval_logits/chosen': -35.3287467956543, 'epoch': 2.71}\n 90%|█████████████████████████████████▎   | 3000/3327 [1:05:00<06:37,  1.22s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 1.824, 'grad_norm': 9.835877418518066, 'learning_rate': 2e-06, 'rewards/chosen': -0.28828758001327515, 'rewards/rejected': -0.446137011051178, 'rewards/accuracies': 0.7770312428474426, 'rewards/margins': 0.15784940123558044, 'logps/rejected': -5.332718372344971, 'logps/chosen': -4.770918369293213, 'logits/rejected': -35.407440185546875, 'logits/chosen': -35.665401458740234, 'epoch': 2.75}\n{'loss': 1.7879, 'grad_norm': 9.955257415771484, 'learning_rate': 2e-06, 'rewards/chosen': -0.2840077877044678, 'rewards/rejected': -0.44578051567077637, 'rewards/accuracies': 0.7784374952316284, 'rewards/margins': 0.1617727279663086, 'logps/rejected': -5.3307366371154785, 'logps/chosen': -4.776209831237793, 'logits/rejected': -35.08035659790039, 'logits/chosen': -35.141414642333984, 'epoch': 2.8}\n{'loss': 1.804, 'grad_norm': 9.509867668151855, 'learning_rate': 2e-06, 'rewards/chosen': -0.2886415123939514, 'rewards/rejected': -0.44987374544143677, 'rewards/accuracies': 0.7731249928474426, 'rewards/margins': 0.16123221814632416, 'logps/rejected': -5.359441757202148, 'logps/chosen': -4.801230430603027, 'logits/rejected': -35.530738830566406, 'logits/chosen': -35.601524353027344, 'epoch': 2.84}\n{'loss': 1.7894, 'grad_norm': 9.482096672058105, 'learning_rate': 2e-06, 'rewards/chosen': -0.2882741689682007, 'rewards/rejected': -0.4507315158843994, 'rewards/accuracies': 0.7723437547683716, 'rewards/margins': 0.16245734691619873, 'logps/rejected': -5.339534759521484, 'logps/chosen': -4.799912452697754, 'logits/rejected': -35.16728591918945, 'logits/chosen': -35.207862854003906, 'epoch': 2.89}\n{'loss': 1.8194, 'grad_norm': 10.278144836425781, 'learning_rate': 2e-06, 'rewards/chosen': -0.2896638810634613, 'rewards/rejected': -0.4510643780231476, 'rewards/accuracies': 0.7729687690734863, 'rewards/margins': 0.16140049695968628, 'logps/rejected': -5.325873851776123, 'logps/chosen': -4.791955471038818, 'logits/rejected': -35.26246643066406, 'logits/chosen': -35.40253829956055, 'epoch': 2.93}\n{'loss': 1.7918, 'grad_norm': 9.636144638061523, 'learning_rate': 2e-06, 'rewards/chosen': -0.28871628642082214, 'rewards/rejected': -0.4507402181625366, 'rewards/accuracies': 0.7728124856948853, 'rewards/margins': 0.1620238870382309, 'logps/rejected': -5.358895778656006, 'logps/chosen': -4.789324760437012, 'logits/rejected': -35.895782470703125, 'logits/chosen': -36.105377197265625, 'epoch': 2.98}\n{'train_runtime': 4319.2344, 'train_samples_per_second': 98.56, 'train_steps_per_second': 0.77, 'train_loss': 2.05857369818772, 'epoch': 3.0}\n100%|█████████████████████████████████████| 3327/3327 [1:11:42<00:00,  1.29s/it]\nEvaling epochs [3, 2, 1, 0]\nLoading from test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-3327\nload ref model lvwerra/gpt2-imdb\nload train model test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-3327\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:26<03:33, 26.70s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:53<03:07, 26.82s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:20<02:41, 26.89s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:47<02:15, 27.01s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:14<01:48, 27.04s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:41<01:20, 26.99s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:08<00:53, 27.00s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:35<00:27, 27.05s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:03<00:00, 27.01s/it]\nmean test reward 0.9408321871299753 +/- 0.004835286387837727 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9988682866096497 from 0.00922983093187213\nmean KL 2.61016442735369 +/- 0.17139681842378904 full 15.219295924529433 +/- 0.07486400273196978\nmedian KL 3.4345818758010864 full 14.781717777252197\nLoading from test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-2218\nload ref model lvwerra/gpt2-imdb\nload train model test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-2218\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:26<03:34, 26.82s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:53<03:07, 26.76s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:20<02:41, 26.95s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:47<02:15, 27.01s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:14<01:48, 27.07s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:42<01:21, 27.23s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:11<00:55, 27.67s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:39<00:27, 27.81s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:07<00:00, 27.48s/it]\nmean test reward 0.9307536026451797 +/- 0.005199401131896607 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9988582134246826 from 0.00922983093187213\nmean KL 3.4100911499828928 +/- 0.15517621873428086 full 13.032778362433115 +/- 0.06736996002107026\nmedian KL 4.373143672943115 full 12.543567657470703\nLoading from test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-1109\nload ref model lvwerra/gpt2-imdb\nload train model test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-1109\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 11%|█████                                        | 1/9 [00:27<03:40, 27.56s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 22%|██████████                                   | 2/9 [00:54<03:11, 27.30s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 33%|███████████████                              | 3/9 [01:21<02:43, 27.27s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 44%|████████████████████                         | 4/9 [01:49<02:16, 27.27s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 56%|█████████████████████████                    | 5/9 [02:16<01:48, 27.24s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 67%|██████████████████████████████               | 6/9 [02:43<01:21, 27.24s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 78%|███████████████████████████████████          | 7/9 [03:10<00:54, 27.29s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n 89%|████████████████████████████████████████     | 8/9 [03:38<00:27, 27.22s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nFor input shapes ftorch.Size([256, 22, 50257]), computed KL shape torch.Size([256, 22, 50257])\nKL approx for shape ftorch.Size([256, 22])\n100%|█████████████████████████████████████████████| 9/9 [04:05<00:00, 27.27s/it]\nmean test reward 0.9143362521855225 +/- 0.00574468352810565 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9988431930541992 from 0.00922983093187213\nmean KL 4.61247394205485 +/- 0.1365105131714086 full 11.005112130194902 +/- 0.064267653588367\nmedian KL 5.350022792816162 full 10.551557064056396\nLoading from test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-0\nload ref model lvwerra/gpt2-imdb\nload train model test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-0\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n    response.raise_for_status()\n  File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-0/resolve/main/config.json\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 399, in cached_file\n    resolved_file = hf_hub_download(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n    raise head_call_error\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n    r = _request_wrapper(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n    response = _request_wrapper(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n    hf_raise_for_status(response)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n    raise RepositoryNotFoundError(message, response) from e\nhuggingface_hub.utils._errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-665a92c8-152ca74d4d2ffcbc120ca148;267046b3-77f9-4af4-b918-51916788549b)\n\nRepository Not Found for url: https://huggingface.co/test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-0/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/cs234-project/dpo.py\", line 207, in <module>\n    r, r_sem, kl, kl_sem = ppo.eval(checkpoint, f\"epoch {epoch}\")\n  File \"/kaggle/working/cs234-project/ppo.py\", line 267, in eval\n    return run(PPOConfig(exp_name=\"eval\", eval_model=model), args=ScriptArguments(), full_name=f'{model}_{notes}')\n  File \"/kaggle/working/cs234-project/ppo.py\", line 120, in run\n    model = trl_model_class.from_pretrained(\n  File \"/opt/conda/lib/python3.10/site-packages/trl/models/modeling_base.py\", line 219, in from_pretrained\n    pretrained_model = cls.transformers_parent_class.from_pretrained(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 484, in from_pretrained\n    resolved_config_file = cached_file(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 422, in cached_file\n    raise EnvironmentError(\nOSError: test_ipo_0_3_lr2e_6-2024.06.01.01.52/checkpoint-0 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf */optimizer.pt && python dpo.py --output_dir=dpo_filtered_2c2_0_3-0_2 --beta=0.2 --dataset_name=/kaggle/working/cs234-project/pref_pairs_16_token_2_choose_2_filtered_0_3_tokenized     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128  --per_device_eval_batch_size 128     --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 100     --report_to wandb     --logging_first_step --logging_strategy='steps' --logging_steps 50  --eval_steps=250 --no_remove_unused_columns --save_total_limit=4 --evaluation_strategy='steps' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch' --num_train_epochs=6","metadata":{"execution":{"iopub.status.busy":"2024-06-01T10:23:55.533632Z","iopub.execute_input":"2024-06-01T10:23:55.534709Z","iopub.status.idle":"2024-06-01T10:24:24.011344Z","shell.execute_reply.started":"2024-06-01T10:23:55.534668Z","shell.execute_reply":"2024-06-01T10:24:24.010187Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2024-06-01 10:24:05.499679: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-01 10:24:05.499799: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-01 10:24:05.635505: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nconfig.json: 100%|█████████████████████████████| 577/577 [00:00<00:00, 3.87MB/s]\npytorch_model.bin: 100%|██████████████████████| 548M/548M [00:01<00:00, 299MB/s]\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\ntokenizer_config.json: 100%|██████████████████| 17.0/17.0 [00:00<00:00, 104kB/s]\nvocab.json: 100%|████████████████████████████| 899k/899k [00:00<00:00, 5.09MB/s]\nmerges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 22.0MB/s]\nspecial_tokens_map.json: 100%|████████████████| 90.0/90.0 [00:00<00:00, 629kB/s]\nTraceback (most recent call last):\n  File \"/kaggle/working/cs234-project/dpo.py\", line 152, in <module>\n    ds = load_from_disk(args.dataset_name) if not args.tokenize else load_dataset(args.dataset_name)\n  File \"/opt/conda/lib/python3.10/site-packages/datasets/load.py\", line 2689, in load_from_disk\n    raise FileNotFoundError(f\"Directory {dataset_path} not found\")\nFileNotFoundError: Directory /kaggle/working/cs234-project/pref_pairs_16_token_2_choose_2_filtered_0_3_tokenized not found\n","output_type":"stream"}]}]}