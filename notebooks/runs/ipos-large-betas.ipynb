{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !conda install -y gdown\n# print('hi')\n!git clone https://github.com/mattjhayes3/cs234-project.git\n%cd /kaggle/working/cs234-project\n!pip install wandb\nimport wandb\n\nwandb.login(key=\"KEY\")\n# wandb.init()\n\nfrom huggingface_hub import notebook_login,login\n\n# notebook_login(\"KEY\")\nlogin(\"KEY\")\n\n# !gdown --id 1TTg8s_dj60EKl4No2unSvYmMyMopPVJ6\n# !gdown --id 1Z7HvAokBQu65jew4ou2DjOYRi23OrJdr\n!mkdir results\n!pip install datasets>=1.17.0 torch>=1.4.0 tqdm transformers accelerate peft>=0.3.0 tyro>=0.5.7\n!pip install git+https://github.com/mattjhayes3/trl.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-25T23:36:22.675261Z","iopub.execute_input":"2024-05-25T23:36:22.675895Z","iopub.status.idle":"2024-05-25T23:37:26.032434Z","shell.execute_reply.started":"2024-05-25T23:36:22.675862Z","shell.execute_reply":"2024-05-25T23:37:26.031324Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'cs234-project'...\nremote: Enumerating objects: 111, done.\u001b[K\nremote: Counting objects: 100% (111/111), done.\u001b[K\nremote: Compressing objects: 100% (69/69), done.\u001b[K\nremote: Total 111 (delta 37), reused 98 (delta 27), pack-reused 0\u001b[K\nReceiving objects: 100% (111/111), 23.60 MiB | 19.38 MiB/s, done.\nResolving deltas: 100% (37/37), done.\nUpdating files: 100% (46/46), done.\nEncountered 2 file(s) that should have been pointers, but weren't:\n\tpref_pairs_16_token_tokenized_split/data-00000-of-00002.arrow\n\tpref_pairs_16_token_tokenized_split/data-00001-of-00002.arrow\n/kaggle/working/cs234-project\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\nCollecting git+https://github.com/mattjhayes3/trl.git\n  Cloning https://github.com/mattjhayes3/trl.git to /tmp/pip-req-build-u0vtbi_1\n  Running command git clone --filter=blob:none --quiet https://github.com/mattjhayes3/trl.git /tmp/pip-req-build-u0vtbi_1\n  Resolved https://github.com/mattjhayes3/trl.git to commit 0f327a2feb6a1bba0c9494205875bea5c868ed75\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (4.39.3)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (0.29.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (2.18.0)\nRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (0.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (4.66.1)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (13.7.0)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (1.7.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.8.7.dev0) (5.9.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.8.7.dev0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.8.7.dev0) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.8.7.dev0) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.7.dev0) (1.16.0)\nBuilding wheels for collected packages: trl\n  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for trl: filename=trl-0.8.7.dev0-py3-none-any.whl size=209518 sha256=627cde4425e76a696624f02b03d949b933b202d35d3e2e157a454000f2fca2a1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-n9i0wsdx/wheels/b5/f5/74/f982e27bdb1c23b205f8bfcaaed174cf3d2c06bd1a5f5926cc\nSuccessfully built trl\nInstalling collected packages: trl\nSuccessfully installed trl-0.8.7.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"! python dpo.py  --loss_type=ipo --output_dir=test_ipo_0_6_lr2e_6  --beta=0.6 --dataset_name=/kaggle/working/cs234-project/pref_pairs_16_token_tokenized_split     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128  --per_device_eval_batch_size 128     --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 150     --report_to wandb     --logging_first_step --logging_strategy='steps' --logging_steps 50  --eval_steps=500 --no_remove_unused_columns --save_total_limit=4 --evaluation_strategy='steps' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch'","metadata":{"execution":{"iopub.status.busy":"2024-05-25T23:37:26.034776Z","iopub.execute_input":"2024-05-25T23:37:26.035422Z","iopub.status.idle":"2024-05-26T00:41:20.027565Z","shell.execute_reply.started":"2024-05-25T23:37:26.035392Z","shell.execute_reply":"2024-05-26T00:41:20.026548Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2024-05-25 23:37:36.295150: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-25 23:37:36.295284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-25 23:37:36.425239: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nconfig.json: 100%|█████████████████████████████| 577/577 [00:00<00:00, 3.60MB/s]\npytorch_model.bin: 100%|██████████████████████| 548M/548M [00:01<00:00, 385MB/s]\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\ntokenizer_config.json: 100%|██████████████████| 17.0/17.0 [00:00<00:00, 103kB/s]\nvocab.json: 100%|████████████████████████████| 899k/899k [00:00<00:00, 2.74MB/s]\nmerges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 1.86MB/s]\nspecial_tokens_map.json: 100%|████████████████| 90.0/90.0 [00:00<00:00, 541kB/s]\nds len 149370\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240525_233753-atp77hil\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtest_ipo_0_6_lr2e_6\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface/runs/atp77hil\u001b[0m\n  0%|                                                  | 0/3327 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 0.6944, 'grad_norm': 4.818739891052246, 'learning_rate': 1.3333333333333334e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -3.736757755279541, 'logps/chosen': -3.8562333583831787, 'logits/rejected': -39.777442932128906, 'logits/chosen': -37.3552131652832, 'epoch': 0.0}\n{'loss': 0.6928, 'grad_norm': 4.928776741027832, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': 0.0002524137089494616, 'rewards/rejected': -0.00033071075449697673, 'rewards/accuracies': 0.6592793464660645, 'rewards/margins': 0.0005831244052387774, 'logps/rejected': -3.871213436126709, 'logps/chosen': -3.8451058864593506, 'logits/rejected': -37.49539566040039, 'logits/chosen': -36.519283294677734, 'epoch': 0.05}\n{'loss': 0.683, 'grad_norm': 5.304897308349609, 'learning_rate': 1.3333333333333332e-06, 'rewards/chosen': 0.0013924927916377783, 'rewards/rejected': -0.002822190523147583, 'rewards/accuracies': 0.6907812356948853, 'rewards/margins': 0.004214683547616005, 'logps/rejected': -3.8469083309173584, 'logps/chosen': -3.827622413635254, 'logits/rejected': -37.163909912109375, 'logits/chosen': -36.40814971923828, 'epoch': 0.09}\n{'loss': 0.6637, 'grad_norm': 4.691040515899658, 'learning_rate': 2e-06, 'rewards/chosen': 0.001666734111495316, 'rewards/rejected': -0.010115358047187328, 'rewards/accuracies': 0.6907812356948853, 'rewards/margins': 0.011782092042267323, 'logps/rejected': -3.8924758434295654, 'logps/chosen': -3.817446231842041, 'logits/rejected': -36.866554260253906, 'logits/chosen': -35.94826126098633, 'epoch': 0.14}\n{'loss': 0.6387, 'grad_norm': 5.144408702850342, 'learning_rate': 2e-06, 'rewards/chosen': -0.002668266650289297, 'rewards/rejected': -0.0253025833517313, 'rewards/accuracies': 0.6971874833106995, 'rewards/margins': 0.022634319961071014, 'logps/rejected': -3.8790838718414307, 'logps/chosen': -3.8390729427337646, 'logits/rejected': -36.788658142089844, 'logits/chosen': -35.956668853759766, 'epoch': 0.18}\n{'loss': 0.6163, 'grad_norm': 4.863109588623047, 'learning_rate': 2e-06, 'rewards/chosen': -0.013662610203027725, 'rewards/rejected': -0.04717983305454254, 'rewards/accuracies': 0.6968749761581421, 'rewards/margins': 0.03351721912622452, 'logps/rejected': -3.917198419570923, 'logps/chosen': -3.8391311168670654, 'logits/rejected': -36.648681640625, 'logits/chosen': -35.91880416870117, 'epoch': 0.23}\n{'loss': 0.602, 'grad_norm': 5.148665428161621, 'learning_rate': 2e-06, 'rewards/chosen': -0.027439149096608162, 'rewards/rejected': -0.07011056691408157, 'rewards/accuracies': 0.692187488079071, 'rewards/margins': 0.04267142340540886, 'logps/rejected': -3.973853826522827, 'logps/chosen': -3.8660738468170166, 'logits/rejected': -36.28841018676758, 'logits/chosen': -35.859619140625, 'epoch': 0.27}\n{'loss': 0.5839, 'grad_norm': 4.580087184906006, 'learning_rate': 2e-06, 'rewards/chosen': -0.04285963624715805, 'rewards/rejected': -0.09639488160610199, 'rewards/accuracies': 0.6981250047683716, 'rewards/margins': 0.05353524163365364, 'logps/rejected': -4.0071306228637695, 'logps/chosen': -3.8861663341522217, 'logits/rejected': -36.088356018066406, 'logits/chosen': -35.4651985168457, 'epoch': 0.32}\n{'loss': 0.5686, 'grad_norm': 4.237202167510986, 'learning_rate': 2e-06, 'rewards/chosen': -0.05910452827811241, 'rewards/rejected': -0.12295123189687729, 'rewards/accuracies': 0.7067187428474426, 'rewards/margins': 0.06384669244289398, 'logps/rejected': -4.045142650604248, 'logps/chosen': -3.922816753387451, 'logits/rejected': -35.882904052734375, 'logits/chosen': -35.22517013549805, 'epoch': 0.36}\n{'loss': 0.5631, 'grad_norm': 5.211945533752441, 'learning_rate': 2e-06, 'rewards/chosen': -0.07602296769618988, 'rewards/rejected': -0.14743588864803314, 'rewards/accuracies': 0.6996874809265137, 'rewards/margins': 0.07141293585300446, 'logps/rejected': -4.090246677398682, 'logps/chosen': -3.9509429931640625, 'logits/rejected': -35.756874084472656, 'logits/chosen': -35.2288703918457, 'epoch': 0.41}\n{'loss': 0.5483, 'grad_norm': 4.24124002456665, 'learning_rate': 2e-06, 'rewards/chosen': -0.08390919864177704, 'rewards/rejected': -0.16525641083717346, 'rewards/accuracies': 0.7154687643051147, 'rewards/margins': 0.08134721964597702, 'logps/rejected': -4.114017009735107, 'logps/chosen': -3.974381923675537, 'logits/rejected': -35.31268310546875, 'logits/chosen': -34.630088806152344, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [08:59<50:50,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.66it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.58it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:26,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.80it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.81it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.79it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5496914982795715, 'eval_runtime': 32.4143, 'eval_samples_per_second': 230.423, 'eval_steps_per_second': 1.82, 'eval_rewards/chosen': -0.0898890495300293, 'eval_rewards/rejected': -0.17154651880264282, 'eval_rewards/accuracies': 0.707580029964447, 'eval_rewards/margins': 0.08165747672319412, 'eval_logps/rejected': -4.1286845207214355, 'eval_logps/chosen': -3.970928192138672, 'eval_logits/rejected': -35.244232177734375, 'eval_logits/chosen': -34.6979866027832, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [09:32<50:50,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.5462, 'grad_norm': 4.28519868850708, 'learning_rate': 2e-06, 'rewards/chosen': -0.09245497733354568, 'rewards/rejected': -0.1767738312482834, 'rewards/accuracies': 0.714062511920929, 'rewards/margins': 0.0843188539147377, 'logps/rejected': -4.147838115692139, 'logps/chosen': -3.99324893951416, 'logits/rejected': -35.1457633972168, 'logits/chosen': -34.61500549316406, 'epoch': 0.5}\n{'loss': 0.5346, 'grad_norm': 4.740942478179932, 'learning_rate': 2e-06, 'rewards/chosen': -0.10216117650270462, 'rewards/rejected': -0.19474369287490845, 'rewards/accuracies': 0.7154687643051147, 'rewards/margins': 0.09258250892162323, 'logps/rejected': -4.186731815338135, 'logps/chosen': -3.9967410564422607, 'logits/rejected': -34.804840087890625, 'logits/chosen': -34.12089920043945, 'epoch': 0.54}\n{'loss': 0.5383, 'grad_norm': 3.986872673034668, 'learning_rate': 2e-06, 'rewards/chosen': -0.10793037712574005, 'rewards/rejected': -0.20085710287094116, 'rewards/accuracies': 0.7120312452316284, 'rewards/margins': 0.0929267480969429, 'logps/rejected': -4.20479679107666, 'logps/chosen': -3.9998135566711426, 'logits/rejected': -34.5796012878418, 'logits/chosen': -34.12492370605469, 'epoch': 0.59}\n{'loss': 0.5305, 'grad_norm': 4.4371490478515625, 'learning_rate': 2e-06, 'rewards/chosen': -0.11519905924797058, 'rewards/rejected': -0.21470887959003448, 'rewards/accuracies': 0.7178124785423279, 'rewards/margins': 0.09950980544090271, 'logps/rejected': -4.19563627243042, 'logps/chosen': -4.029373645782471, 'logits/rejected': -34.422157287597656, 'logits/chosen': -33.96776580810547, 'epoch': 0.63}\n{'loss': 0.5288, 'grad_norm': 4.938240051269531, 'learning_rate': 2e-06, 'rewards/chosen': -0.11597061902284622, 'rewards/rejected': -0.2162962406873703, 'rewards/accuracies': 0.7189062237739563, 'rewards/margins': 0.10032561421394348, 'logps/rejected': -4.182101249694824, 'logps/chosen': -4.027841567993164, 'logits/rejected': -34.38374328613281, 'logits/chosen': -33.90497970581055, 'epoch': 0.68}\n{'loss': 0.5296, 'grad_norm': 4.538466930389404, 'learning_rate': 2e-06, 'rewards/chosen': -0.11773990839719772, 'rewards/rejected': -0.2184399664402008, 'rewards/accuracies': 0.7192187309265137, 'rewards/margins': 0.10070003569126129, 'logps/rejected': -4.200535297393799, 'logps/chosen': -4.0123209953308105, 'logits/rejected': -34.47895050048828, 'logits/chosen': -34.03461837768555, 'epoch': 0.72}\n{'loss': 0.5186, 'grad_norm': 3.9082794189453125, 'learning_rate': 2e-06, 'rewards/chosen': -0.12157025188207626, 'rewards/rejected': -0.22936587035655975, 'rewards/accuracies': 0.7246875166893005, 'rewards/margins': 0.10779561847448349, 'logps/rejected': -4.237258434295654, 'logps/chosen': -4.040265083312988, 'logits/rejected': -34.12648391723633, 'logits/chosen': -33.631744384765625, 'epoch': 0.77}\n{'loss': 0.5285, 'grad_norm': 4.211853504180908, 'learning_rate': 2e-06, 'rewards/chosen': -0.12776516377925873, 'rewards/rejected': -0.23193691670894623, 'rewards/accuracies': 0.7251562476158142, 'rewards/margins': 0.1041717454791069, 'logps/rejected': -4.230337142944336, 'logps/chosen': -4.052585601806641, 'logits/rejected': -34.11482238769531, 'logits/chosen': -33.561866760253906, 'epoch': 0.81}\n{'loss': 0.5252, 'grad_norm': 4.585885524749756, 'learning_rate': 2e-06, 'rewards/chosen': -0.12858381867408752, 'rewards/rejected': -0.23734931647777557, 'rewards/accuracies': 0.7260937690734863, 'rewards/margins': 0.10876547545194626, 'logps/rejected': -4.234423637390137, 'logps/chosen': -4.027334213256836, 'logits/rejected': -33.90074157714844, 'logits/chosen': -33.53132247924805, 'epoch': 0.86}\n{'loss': 0.5126, 'grad_norm': 4.297885417938232, 'learning_rate': 2e-06, 'rewards/chosen': -0.1266442835330963, 'rewards/rejected': -0.23986592888832092, 'rewards/accuracies': 0.7332812547683716, 'rewards/margins': 0.1132216528058052, 'logps/rejected': -4.240394115447998, 'logps/chosen': -4.024107456207275, 'logits/rejected': -33.869441986083984, 'logits/chosen': -33.46165466308594, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [18:31<41:36,  1.07s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.66it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.81it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5124269127845764, 'eval_runtime': 32.4232, 'eval_samples_per_second': 230.36, 'eval_steps_per_second': 1.82, 'eval_rewards/chosen': -0.1303194761276245, 'eval_rewards/rejected': -0.24387511610984802, 'eval_rewards/accuracies': 0.7304055094718933, 'eval_rewards/margins': 0.11355562508106232, 'eval_logps/rejected': -4.249232292175293, 'eval_logps/chosen': -4.03831148147583, 'eval_logits/rejected': -33.694297790527344, 'eval_logits/chosen': -33.2646484375, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [19:03<41:36,  1.07s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.5123, 'grad_norm': 3.9627835750579834, 'learning_rate': 2e-06, 'rewards/chosen': -0.13025285303592682, 'rewards/rejected': -0.24353809654712677, 'rewards/accuracies': 0.7378125190734863, 'rewards/margins': 0.11328525841236115, 'logps/rejected': -4.270462512969971, 'logps/chosen': -4.038080215454102, 'logits/rejected': -33.84913635253906, 'logits/chosen': -33.442588806152344, 'epoch': 0.95}\n{'loss': 0.5052, 'grad_norm': 4.333914756774902, 'learning_rate': 2e-06, 'rewards/chosen': -0.1339452713727951, 'rewards/rejected': -0.2534443140029907, 'rewards/accuracies': 0.73828125, 'rewards/margins': 0.11949899792671204, 'logps/rejected': -4.266631603240967, 'logps/chosen': -4.060306072235107, 'logits/rejected': -33.66764831542969, 'logits/chosen': -33.256961822509766, 'epoch': 0.99}\n{'loss': 0.496, 'grad_norm': 3.939002752304077, 'learning_rate': 2e-06, 'rewards/chosen': -0.13218243420124054, 'rewards/rejected': -0.2560824453830719, 'rewards/accuracies': 0.7514732480049133, 'rewards/margins': 0.12389999628067017, 'logps/rejected': -4.252942085266113, 'logps/chosen': -4.0138397216796875, 'logits/rejected': -33.73411560058594, 'logits/chosen': -33.1700325012207, 'epoch': 1.04}\n{'loss': 0.4786, 'grad_norm': 4.354557037353516, 'learning_rate': 2e-06, 'rewards/chosen': -0.1319027841091156, 'rewards/rejected': -0.26412975788116455, 'rewards/accuracies': 0.7549999952316284, 'rewards/margins': 0.13222698867321014, 'logps/rejected': -4.300371170043945, 'logps/chosen': -4.047159194946289, 'logits/rejected': -33.46717834472656, 'logits/chosen': -33.0034065246582, 'epoch': 1.08}\n{'loss': 0.4838, 'grad_norm': 3.930236339569092, 'learning_rate': 2e-06, 'rewards/chosen': -0.1373356431722641, 'rewards/rejected': -0.26783204078674316, 'rewards/accuracies': 0.757031261920929, 'rewards/margins': 0.13049638271331787, 'logps/rejected': -4.277123928070068, 'logps/chosen': -4.048074245452881, 'logits/rejected': -33.902976989746094, 'logits/chosen': -33.49161911010742, 'epoch': 1.13}\n{'loss': 0.4738, 'grad_norm': 3.7665653228759766, 'learning_rate': 2e-06, 'rewards/chosen': -0.13579250872135162, 'rewards/rejected': -0.270359605550766, 'rewards/accuracies': 0.7640625238418579, 'rewards/margins': 0.13456712663173676, 'logps/rejected': -4.292124271392822, 'logps/chosen': -4.048956394195557, 'logits/rejected': -33.71794891357422, 'logits/chosen': -33.223873138427734, 'epoch': 1.17}\n{'loss': 0.4755, 'grad_norm': 4.0086140632629395, 'learning_rate': 2e-06, 'rewards/chosen': -0.14061444997787476, 'rewards/rejected': -0.27789783477783203, 'rewards/accuracies': 0.764843761920929, 'rewards/margins': 0.13728338479995728, 'logps/rejected': -4.332414150238037, 'logps/chosen': -4.0539870262146, 'logits/rejected': -33.053802490234375, 'logits/chosen': -32.89442825317383, 'epoch': 1.22}\n{'loss': 0.4793, 'grad_norm': 4.096275329589844, 'learning_rate': 2e-06, 'rewards/chosen': -0.15007250010967255, 'rewards/rejected': -0.2850169837474823, 'rewards/accuracies': 0.7639062404632568, 'rewards/margins': 0.13494448363780975, 'logps/rejected': -4.332212448120117, 'logps/chosen': -4.099400520324707, 'logits/rejected': -33.364322662353516, 'logits/chosen': -32.934349060058594, 'epoch': 1.26}\n{'loss': 0.4834, 'grad_norm': 4.246674060821533, 'learning_rate': 2e-06, 'rewards/chosen': -0.14430637657642365, 'rewards/rejected': -0.2803301215171814, 'rewards/accuracies': 0.7545312643051147, 'rewards/margins': 0.13602371513843536, 'logps/rejected': -4.316462516784668, 'logps/chosen': -4.0580315589904785, 'logits/rejected': -33.4179801940918, 'logits/chosen': -33.04131317138672, 'epoch': 1.31}\n{'loss': 0.4884, 'grad_norm': 3.9809370040893555, 'learning_rate': 2e-06, 'rewards/chosen': -0.14901497960090637, 'rewards/rejected': -0.27779316902160645, 'rewards/accuracies': 0.7493749856948853, 'rewards/margins': 0.12877817451953888, 'logps/rejected': -4.305771350860596, 'logps/chosen': -4.0794997215271, 'logits/rejected': -33.274322509765625, 'logits/chosen': -32.922183990478516, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [28:04<32:43,  1.07s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.79it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.80it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.49378839135169983, 'eval_runtime': 32.4386, 'eval_samples_per_second': 230.25, 'eval_steps_per_second': 1.819, 'eval_rewards/chosen': -0.14904610812664032, 'eval_rewards/rejected': -0.2782348692417145, 'eval_rewards/accuracies': 0.7418844103813171, 'eval_rewards/margins': 0.12918874621391296, 'eval_logps/rejected': -4.3064985275268555, 'eval_logps/chosen': -4.069522857666016, 'eval_logits/rejected': -33.333133697509766, 'eval_logits/chosen': -32.95839309692383, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [28:36<32:43,  1.07s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.4732, 'grad_norm': 4.693009853363037, 'learning_rate': 2e-06, 'rewards/chosen': -0.14655928313732147, 'rewards/rejected': -0.2845715582370758, 'rewards/accuracies': 0.7639062404632568, 'rewards/margins': 0.13801231980323792, 'logps/rejected': -4.305084228515625, 'logps/chosen': -4.066486835479736, 'logits/rejected': -33.48954391479492, 'logits/chosen': -33.01785659790039, 'epoch': 1.4}\n{'loss': 0.4675, 'grad_norm': 4.048703670501709, 'learning_rate': 2e-06, 'rewards/chosen': -0.14894622564315796, 'rewards/rejected': -0.2912023067474365, 'rewards/accuracies': 0.7629687786102295, 'rewards/margins': 0.14225606620311737, 'logps/rejected': -4.332747936248779, 'logps/chosen': -4.0552287101745605, 'logits/rejected': -33.91851806640625, 'logits/chosen': -33.421051025390625, 'epoch': 1.44}\n{'loss': 0.466, 'grad_norm': 3.896409749984741, 'learning_rate': 2e-06, 'rewards/chosen': -0.15310817956924438, 'rewards/rejected': -0.29812106490135193, 'rewards/accuracies': 0.7682812213897705, 'rewards/margins': 0.14501287043094635, 'logps/rejected': -4.343708038330078, 'logps/chosen': -4.081859588623047, 'logits/rejected': -33.66130447387695, 'logits/chosen': -33.25608444213867, 'epoch': 1.49}\n{'loss': 0.4794, 'grad_norm': 3.9373366832733154, 'learning_rate': 2e-06, 'rewards/chosen': -0.15085738897323608, 'rewards/rejected': -0.28957024216651917, 'rewards/accuracies': 0.7543749809265137, 'rewards/margins': 0.1387128382921219, 'logps/rejected': -4.326062202453613, 'logps/chosen': -4.060326099395752, 'logits/rejected': -33.6800537109375, 'logits/chosen': -33.413368225097656, 'epoch': 1.53}\n{'loss': 0.4625, 'grad_norm': 4.1664137840271, 'learning_rate': 2e-06, 'rewards/chosen': -0.15099391341209412, 'rewards/rejected': -0.2957494854927063, 'rewards/accuracies': 0.7721874713897705, 'rewards/margins': 0.14475557208061218, 'logps/rejected': -4.343010425567627, 'logps/chosen': -4.081407070159912, 'logits/rejected': -33.681766510009766, 'logits/chosen': -33.292293548583984, 'epoch': 1.58}\n{'loss': 0.474, 'grad_norm': 3.860778331756592, 'learning_rate': 2e-06, 'rewards/chosen': -0.15610434114933014, 'rewards/rejected': -0.2983575165271759, 'rewards/accuracies': 0.7574999928474426, 'rewards/margins': 0.14225313067436218, 'logps/rejected': -4.34294319152832, 'logps/chosen': -4.105610370635986, 'logits/rejected': -33.63595199584961, 'logits/chosen': -33.27075958251953, 'epoch': 1.62}\n{'loss': 0.4728, 'grad_norm': 4.23886251449585, 'learning_rate': 2e-06, 'rewards/chosen': -0.15256528556346893, 'rewards/rejected': -0.2947692573070526, 'rewards/accuracies': 0.76171875, 'rewards/margins': 0.1422039270401001, 'logps/rejected': -4.3517656326293945, 'logps/chosen': -4.0711565017700195, 'logits/rejected': -33.566715240478516, 'logits/chosen': -33.133602142333984, 'epoch': 1.67}\n{'loss': 0.4714, 'grad_norm': 4.272594928741455, 'learning_rate': 2e-06, 'rewards/chosen': -0.15437345206737518, 'rewards/rejected': -0.2967422604560852, 'rewards/accuracies': 0.7645312547683716, 'rewards/margins': 0.1423688381910324, 'logps/rejected': -4.3437089920043945, 'logps/chosen': -4.097413063049316, 'logits/rejected': -33.84858703613281, 'logits/chosen': -33.59255599975586, 'epoch': 1.71}\n{'loss': 0.4764, 'grad_norm': 3.6080684661865234, 'learning_rate': 2e-06, 'rewards/chosen': -0.15234029293060303, 'rewards/rejected': -0.29279690980911255, 'rewards/accuracies': 0.7581250071525574, 'rewards/margins': 0.14045658707618713, 'logps/rejected': -4.334561824798584, 'logps/chosen': -4.087438583374023, 'logits/rejected': -33.933467864990234, 'logits/chosen': -33.790096282958984, 'epoch': 1.76}\n{'loss': 0.4668, 'grad_norm': 4.133065700531006, 'learning_rate': 2e-06, 'rewards/chosen': -0.1510714590549469, 'rewards/rejected': -0.29456639289855957, 'rewards/accuracies': 0.7728124856948853, 'rewards/margins': 0.14349490404129028, 'logps/rejected': -4.362651348114014, 'logps/chosen': -4.074502468109131, 'logits/rejected': -34.08494567871094, 'logits/chosen': -33.618804931640625, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [37:36<25:13,  1.14s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.66it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:26,  1.97it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.92it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.89it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.87it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.84it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:24,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.80it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:25<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.48235154151916504, 'eval_runtime': 32.4102, 'eval_samples_per_second': 230.452, 'eval_steps_per_second': 1.82, 'eval_rewards/chosen': -0.16065002977848053, 'eval_rewards/rejected': -0.2993142306804657, 'eval_rewards/accuracies': 0.7568267583847046, 'eval_rewards/margins': 0.13866423070430756, 'eval_logps/rejected': -4.341630935668945, 'eval_logps/chosen': -4.088862895965576, 'eval_logits/rejected': -34.094810485839844, 'eval_logits/chosen': -33.76909637451172, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [38:08<25:13,  1.14s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.4615, 'grad_norm': 4.450954914093018, 'learning_rate': 2e-06, 'rewards/chosen': -0.15622077882289886, 'rewards/rejected': -0.3057270646095276, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.14950627088546753, 'logps/rejected': -4.33598518371582, 'logps/chosen': -4.082653999328613, 'logits/rejected': -34.45854949951172, 'logits/chosen': -34.06703186035156, 'epoch': 1.85}\n{'loss': 0.4595, 'grad_norm': 4.1477274894714355, 'learning_rate': 2e-06, 'rewards/chosen': -0.15423741936683655, 'rewards/rejected': -0.303987592458725, 'rewards/accuracies': 0.7679687738418579, 'rewards/margins': 0.14975017309188843, 'logps/rejected': -4.366635799407959, 'logps/chosen': -4.091369152069092, 'logits/rejected': -34.18123245239258, 'logits/chosen': -33.934608459472656, 'epoch': 1.89}\n{'loss': 0.4646, 'grad_norm': 4.19016695022583, 'learning_rate': 2e-06, 'rewards/chosen': -0.16103290021419525, 'rewards/rejected': -0.3071843981742859, 'rewards/accuracies': 0.7682812213897705, 'rewards/margins': 0.14615151286125183, 'logps/rejected': -4.358919143676758, 'logps/chosen': -4.108782768249512, 'logits/rejected': -34.179420471191406, 'logits/chosen': -33.883331298828125, 'epoch': 1.94}\n{'loss': 0.4555, 'grad_norm': 4.033609390258789, 'learning_rate': 2e-06, 'rewards/chosen': -0.16120494902133942, 'rewards/rejected': -0.315735787153244, 'rewards/accuracies': 0.7714062333106995, 'rewards/margins': 0.15453088283538818, 'logps/rejected': -4.366848468780518, 'logps/chosen': -4.103577136993408, 'logits/rejected': -34.20258712768555, 'logits/chosen': -33.823631286621094, 'epoch': 1.98}\n{'loss': 0.4497, 'grad_norm': 3.851367473602295, 'learning_rate': 2e-06, 'rewards/chosen': -0.1533295214176178, 'rewards/rejected': -0.30953261256217957, 'rewards/accuracies': 0.7816781401634216, 'rewards/margins': 0.15620310604572296, 'logps/rejected': -4.361111640930176, 'logps/chosen': -4.090385437011719, 'logits/rejected': -34.29422378540039, 'logits/chosen': -34.02693176269531, 'epoch': 2.03}\n{'loss': 0.4393, 'grad_norm': 3.67289662361145, 'learning_rate': 2e-06, 'rewards/chosen': -0.15246066451072693, 'rewards/rejected': -0.31098365783691406, 'rewards/accuracies': 0.7884374856948853, 'rewards/margins': 0.15852300822734833, 'logps/rejected': -4.346550464630127, 'logps/chosen': -4.098140239715576, 'logits/rejected': -34.6123161315918, 'logits/chosen': -33.99284744262695, 'epoch': 2.07}\n{'loss': 0.4369, 'grad_norm': 4.255429267883301, 'learning_rate': 2e-06, 'rewards/chosen': -0.1524115949869156, 'rewards/rejected': -0.3125971555709839, 'rewards/accuracies': 0.7915624976158142, 'rewards/margins': 0.1601855605840683, 'logps/rejected': -4.359755992889404, 'logps/chosen': -4.086495399475098, 'logits/rejected': -34.27506637573242, 'logits/chosen': -34.04007339477539, 'epoch': 2.12}\n{'loss': 0.4382, 'grad_norm': 3.7437973022460938, 'learning_rate': 2e-06, 'rewards/chosen': -0.1538950353860855, 'rewards/rejected': -0.3125889301300049, 'rewards/accuracies': 0.7915624976158142, 'rewards/margins': 0.1586938500404358, 'logps/rejected': -4.367956638336182, 'logps/chosen': -4.090217590332031, 'logits/rejected': -34.228553771972656, 'logits/chosen': -34.184837341308594, 'epoch': 2.16}\n{'loss': 0.4397, 'grad_norm': 4.212091445922852, 'learning_rate': 2e-06, 'rewards/chosen': -0.16109202802181244, 'rewards/rejected': -0.320963978767395, 'rewards/accuracies': 0.7890625, 'rewards/margins': 0.1598719358444214, 'logps/rejected': -4.392160892486572, 'logps/chosen': -4.088414192199707, 'logits/rejected': -34.65420150756836, 'logits/chosen': -34.52748107910156, 'epoch': 2.21}\n{'loss': 0.4234, 'grad_norm': 3.8874146938323975, 'learning_rate': 2e-06, 'rewards/chosen': -0.16045492887496948, 'rewards/rejected': -0.32574158906936646, 'rewards/accuracies': 0.7979687452316284, 'rewards/margins': 0.16528668999671936, 'logps/rejected': -4.414301872253418, 'logps/chosen': -4.108987331390381, 'logits/rejected': -34.84302520751953, 'logits/chosen': -34.45608901977539, 'epoch': 2.25}\n 75%|█████████████████████████████▎         | 2500/3327 [47:09<14:51,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.80it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.80it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.47289136052131653, 'eval_runtime': 32.4753, 'eval_samples_per_second': 229.99, 'eval_steps_per_second': 1.817, 'eval_rewards/chosen': -0.17299315333366394, 'eval_rewards/rejected': -0.3208279013633728, 'eval_rewards/accuracies': 0.7619909644126892, 'eval_rewards/margins': 0.14783473312854767, 'eval_logps/rejected': -4.377486705780029, 'eval_logps/chosen': -4.109434604644775, 'eval_logits/rejected': -34.75807189941406, 'eval_logits/chosen': -34.47361373901367, 'epoch': 2.25}\n 75%|█████████████████████████████▎         | 2500/3327 [47:41<14:51,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.4249, 'grad_norm': 3.9118762016296387, 'learning_rate': 2e-06, 'rewards/chosen': -0.16663576662540436, 'rewards/rejected': -0.3376629650592804, 'rewards/accuracies': 0.7995312213897705, 'rewards/margins': 0.17102718353271484, 'logps/rejected': -4.405993461608887, 'logps/chosen': -4.115174293518066, 'logits/rejected': -34.940242767333984, 'logits/chosen': -34.441497802734375, 'epoch': 2.3}\n{'loss': 0.4255, 'grad_norm': 4.10105562210083, 'learning_rate': 2e-06, 'rewards/chosen': -0.1607956439256668, 'rewards/rejected': -0.33074870705604553, 'rewards/accuracies': 0.7953125238418579, 'rewards/margins': 0.16995306313037872, 'logps/rejected': -4.416210174560547, 'logps/chosen': -4.088380813598633, 'logits/rejected': -34.879547119140625, 'logits/chosen': -34.58515167236328, 'epoch': 2.34}\n{'loss': 0.4312, 'grad_norm': 3.8615429401397705, 'learning_rate': 2e-06, 'rewards/chosen': -0.1681516468524933, 'rewards/rejected': -0.3353407382965088, 'rewards/accuracies': 0.7978125214576721, 'rewards/margins': 0.16718906164169312, 'logps/rejected': -4.425899505615234, 'logps/chosen': -4.1068501472473145, 'logits/rejected': -34.84062194824219, 'logits/chosen': -34.574554443359375, 'epoch': 2.39}\n{'loss': 0.431, 'grad_norm': 4.4233527183532715, 'learning_rate': 2e-06, 'rewards/chosen': -0.1695670634508133, 'rewards/rejected': -0.33808040618896484, 'rewards/accuracies': 0.7920312285423279, 'rewards/margins': 0.16851334273815155, 'logps/rejected': -4.3954596519470215, 'logps/chosen': -4.088849067687988, 'logits/rejected': -35.133644104003906, 'logits/chosen': -34.868614196777344, 'epoch': 2.43}\n{'loss': 0.428, 'grad_norm': 3.996284246444702, 'learning_rate': 2e-06, 'rewards/chosen': -0.16861313581466675, 'rewards/rejected': -0.33864808082580566, 'rewards/accuracies': 0.7979687452316284, 'rewards/margins': 0.1700349599123001, 'logps/rejected': -4.403149604797363, 'logps/chosen': -4.095162868499756, 'logits/rejected': -35.53974914550781, 'logits/chosen': -35.23667907714844, 'epoch': 2.48}\n{'loss': 0.4346, 'grad_norm': 4.077830791473389, 'learning_rate': 2e-06, 'rewards/chosen': -0.17478080093860626, 'rewards/rejected': -0.3385966420173645, 'rewards/accuracies': 0.7893750071525574, 'rewards/margins': 0.16381584107875824, 'logps/rejected': -4.408022880554199, 'logps/chosen': -4.126315116882324, 'logits/rejected': -35.6261100769043, 'logits/chosen': -35.388065338134766, 'epoch': 2.52}\n{'loss': 0.4359, 'grad_norm': 4.300407886505127, 'learning_rate': 2e-06, 'rewards/chosen': -0.16808338463306427, 'rewards/rejected': -0.33206072449684143, 'rewards/accuracies': 0.7906249761581421, 'rewards/margins': 0.16397733986377716, 'logps/rejected': -4.406920433044434, 'logps/chosen': -4.106245517730713, 'logits/rejected': -35.74187469482422, 'logits/chosen': -35.60026931762695, 'epoch': 2.57}\n{'loss': 0.4187, 'grad_norm': 4.531728267669678, 'learning_rate': 2e-06, 'rewards/chosen': -0.16779100894927979, 'rewards/rejected': -0.34091052412986755, 'rewards/accuracies': 0.8034374713897705, 'rewards/margins': 0.17311948537826538, 'logps/rejected': -4.404487133026123, 'logps/chosen': -4.101922988891602, 'logits/rejected': -35.87343215942383, 'logits/chosen': -35.455955505371094, 'epoch': 2.61}\n{'loss': 0.4254, 'grad_norm': 4.4685235023498535, 'learning_rate': 2e-06, 'rewards/chosen': -0.17068713903427124, 'rewards/rejected': -0.3398324251174927, 'rewards/accuracies': 0.7984374761581421, 'rewards/margins': 0.16914530098438263, 'logps/rejected': -4.419640064239502, 'logps/chosen': -4.113724231719971, 'logits/rejected': -35.87919616699219, 'logits/chosen': -35.474029541015625, 'epoch': 2.66}\n{'loss': 0.4185, 'grad_norm': 4.263434410095215, 'learning_rate': 2e-06, 'rewards/chosen': -0.17587973177433014, 'rewards/rejected': -0.3492010235786438, 'rewards/accuracies': 0.803906261920929, 'rewards/margins': 0.17332130670547485, 'logps/rejected': -4.442713737487793, 'logps/chosen': -4.111251354217529, 'logits/rejected': -35.785369873046875, 'logits/chosen': -35.58097839355469, 'epoch': 2.71}\n 90%|███████████████████████████████████▏   | 3000/3327 [56:40<05:51,  1.07s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:26,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.76it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.46551162004470825, 'eval_runtime': 32.4489, 'eval_samples_per_second': 230.177, 'eval_steps_per_second': 1.818, 'eval_rewards/chosen': -0.18573404848575592, 'eval_rewards/rejected': -0.34106945991516113, 'eval_rewards/accuracies': 0.7644861936569214, 'eval_rewards/margins': 0.1553354412317276, 'eval_logps/rejected': -4.411223411560059, 'eval_logps/chosen': -4.130669593811035, 'eval_logits/rejected': -35.602210998535156, 'eval_logits/chosen': -35.351898193359375, 'epoch': 2.71}\n 90%|███████████████████████████████████▏   | 3000/3327 [57:13<05:51,  1.07s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.4268, 'grad_norm': 4.155933380126953, 'learning_rate': 2e-06, 'rewards/chosen': -0.1759113371372223, 'rewards/rejected': -0.34679076075553894, 'rewards/accuracies': 0.8048437237739563, 'rewards/margins': 0.17087943851947784, 'logps/rejected': -4.423580646514893, 'logps/chosen': -4.103145122528076, 'logits/rejected': -35.847564697265625, 'logits/chosen': -35.58134841918945, 'epoch': 2.75}\n{'loss': 0.4199, 'grad_norm': 4.193503379821777, 'learning_rate': 2e-06, 'rewards/chosen': -0.1722746342420578, 'rewards/rejected': -0.3462337553501129, 'rewards/accuracies': 0.8003125190734863, 'rewards/margins': 0.1739591658115387, 'logps/rejected': -4.421857833862305, 'logps/chosen': -4.116641044616699, 'logits/rejected': -35.64445877075195, 'logits/chosen': -35.30574035644531, 'epoch': 2.8}\n{'loss': 0.4255, 'grad_norm': 4.006418228149414, 'learning_rate': 2e-06, 'rewards/chosen': -0.17482462525367737, 'rewards/rejected': -0.34753987193107605, 'rewards/accuracies': 0.7939062714576721, 'rewards/margins': 0.17271527647972107, 'logps/rejected': -4.439095497131348, 'logps/chosen': -4.130466461181641, 'logits/rejected': -35.945213317871094, 'logits/chosen': -35.56417465209961, 'epoch': 2.84}\n{'loss': 0.4193, 'grad_norm': 4.03008508682251, 'learning_rate': 2e-06, 'rewards/chosen': -0.17200182378292084, 'rewards/rejected': -0.3467123508453369, 'rewards/accuracies': 0.7982812523841858, 'rewards/margins': 0.17471054196357727, 'logps/rejected': -4.414949893951416, 'logps/chosen': -4.125668525695801, 'logits/rejected': -35.751251220703125, 'logits/chosen': -35.382965087890625, 'epoch': 2.89}\n{'loss': 0.4264, 'grad_norm': 4.1303606033325195, 'learning_rate': 2e-06, 'rewards/chosen': -0.17197710275650024, 'rewards/rejected': -0.3445385992527008, 'rewards/accuracies': 0.7946875095367432, 'rewards/margins': 0.17256149649620056, 'logps/rejected': -4.396557331085205, 'logps/chosen': -4.113037586212158, 'logits/rejected': -35.80250549316406, 'logits/chosen': -35.50323486328125, 'epoch': 2.93}\n{'loss': 0.421, 'grad_norm': 4.081119537353516, 'learning_rate': 2e-06, 'rewards/chosen': -0.1729375272989273, 'rewards/rejected': -0.34606292843818665, 'rewards/accuracies': 0.7950000166893005, 'rewards/margins': 0.17312540113925934, 'logps/rejected': -4.433199882507324, 'logps/chosen': -4.115166187286377, 'logits/rejected': -36.24292755126953, 'logits/chosen': -36.014747619628906, 'epoch': 2.98}\n{'train_runtime': 3804.0353, 'train_samples_per_second': 111.908, 'train_steps_per_second': 0.875, 'train_loss': 0.4891882460863339, 'epoch': 3.0}\n100%|█████████████████████████████████████| 3327/3327 [1:03:07<00:00,  1.14s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python ppo.py --exp_name=eval --log_with=wandb --eval_model=./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-3327\n!python ppo.py --exp_name=eval --log_with=wandb --eval_model=./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-2218\n!python ppo.py --exp_name=eval --log_with=wandb --eval_model=./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-1109","metadata":{"execution":{"iopub.status.busy":"2024-05-26T00:42:39.116875Z","iopub.execute_input":"2024-05-26T00:42:39.117251Z","iopub.status.idle":"2024-05-26T00:57:44.588271Z","shell.execute_reply.started":"2024-05-26T00:42:39.117219Z","shell.execute_reply":"2024-05-26T00:57:44.587083Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"2024-05-26 00:42:45.644077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 00:42:45.644133: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 00:42:45.645511: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-3327', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.00.42'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nMap:   0%|                                     | 0/24895 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\nMap: 100%|████████████████████████| 24895/24895 [00:29<00:00, 851.28 examples/s]\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-3327\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_004328-9kzydcjw\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.00.42\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/9kzydcjw\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\nconfig.json: 100%|█████████████████████████████| 687/687 [00:00<00:00, 1.78MB/s]\npytorch_model.bin: 100%|████████████████████| 1.42G/1.42G [00:03<00:00, 381MB/s]\ntokenizer_config.json: 100%|████████████████████| 256/256 [00:00<00:00, 765kB/s]\nvocab.json: 100%|████████████████████████████| 798k/798k [00:00<00:00, 2.42MB/s]\nmerges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 1.89MB/s]\nspecial_tokens_map.json: 100%|██████████████████| 150/150 [00:00<00:00, 377kB/s]\neval batch size 256\nFilter: 100%|██████████████████████| 2500/2500 [00:01<00:00, 1476.01 examples/s]\nMap:   3%|▊                           | 70/2487 [00:00<00:03, 675.74 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\nMap: 100%|██████████████████████████| 2487/2487 [00:02<00:00, 837.46 examples/s]\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:28<03:46, 28.28s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:54<03:10, 27.20s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:21<02:40, 26.82s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:47<02:13, 26.65s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:13<01:46, 26.60s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:40<01:19, 26.59s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:07<00:53, 26.63s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:33<00:26, 26.58s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [04:00<00:00, 26.72s/it]\nmean test reward 0.9003152412610942 +/- 0.006152539077516477 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9988107085227966 from 0.00922983093187213\nmean KL 0.4347361763809911 +/- 0.10065946890885791 full 6.185308412027855 +/- 0.03678759502781658\nmedian KL 1.0872238874435425 full 5.887624263763428\n2024-05-26 00:48:13.863310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 00:48:13.863370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 00:48:13.864800: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-2218', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.00.48'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-2218\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_004827-5yv9uxt5\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.00.48\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/5yv9uxt5\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:27<03:39, 27.42s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:54<03:08, 26.97s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:21<02:43, 27.30s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:49<02:16, 27.28s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:15<01:48, 27.13s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:42<01:20, 26.90s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:09<00:53, 26.87s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:35<00:26, 26.85s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [04:02<00:00, 26.96s/it]\nmean test reward 0.8884296324977691 +/- 0.006474517776337073 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9987878203392029 from 0.00922983093187213\nmean KL 1.1237349489044088 +/- 0.0894744816708944 full 5.46009443110476 +/- 0.03622158097623488\nmedian KL 1.7330951690673828 full 5.146851539611816\n2024-05-26 00:53:03.551614: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 00:53:03.551690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 00:53:03.553098: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-1109', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.00.53'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_0_6_lr2e_6-2024.05.25.23.37/checkpoint-1109\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_005317-iylbv522\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.00.53\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/iylbv522\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:26<03:33, 26.69s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:53<03:05, 26.49s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:19<02:39, 26.60s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:46<02:13, 26.62s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:12<01:46, 26.58s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:40<01:20, 26.76s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:06<00:53, 26.69s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:33<00:26, 26.69s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [04:00<00:00, 26.68s/it]\nmean test reward 0.8642827241798917 +/- 0.007039118245396259 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9987470507621765 from 0.00922983093187213\nmean KL 1.8959066446275554 +/- 0.07902109466370062 full 4.729932612066881 +/- 0.035638953930087494\nmedian KL 2.3858357667922974 full 4.4542882442474365\n","output_type":"stream"}]},{"cell_type":"code","source":"! python dpo.py  --loss_type=ipo --output_dir=test_ipo_1_0_lr2e_6  --beta=1.0 --dataset_name=/kaggle/working/cs234-project/pref_pairs_16_token_tokenized_split     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128  --per_device_eval_batch_size 128     --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 150     --report_to wandb     --logging_first_step --logging_strategy='steps' --logging_steps 50  --eval_steps=500 --no_remove_unused_columns --save_total_limit=4 --evaluation_strategy='steps' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch'","metadata":{"execution":{"iopub.status.busy":"2024-05-26T00:58:20.387931Z","iopub.execute_input":"2024-05-26T00:58:20.388316Z","iopub.status.idle":"2024-05-26T02:02:03.519993Z","shell.execute_reply.started":"2024-05-26T00:58:20.388286Z","shell.execute_reply":"2024-05-26T02:02:03.518999Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"2024-05-26 00:58:26.429222: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 00:58:26.429285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 00:58:26.430642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\nds len 149370\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_005832-c5ls84si\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtest_ipo_1_0_lr2e_6\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface/runs/c5ls84si\u001b[0m\n  0%|                                                  | 0/3327 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 0.25, 'grad_norm': 2.8912436962127686, 'learning_rate': 1.3333333333333334e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -3.736757755279541, 'logps/chosen': -3.8562333583831787, 'logits/rejected': -39.777442932128906, 'logits/chosen': -37.3552131652832, 'epoch': 0.0}\n{'loss': 0.249, 'grad_norm': 2.9517288208007812, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': 0.00042040165862999856, 'rewards/rejected': -0.0005499625694938004, 'rewards/accuracies': 0.6592793464660645, 'rewards/margins': 0.0009703641990199685, 'logps/rejected': -3.8712120056152344, 'logps/chosen': -3.8451061248779297, 'logits/rejected': -37.49543380737305, 'logits/chosen': -36.519317626953125, 'epoch': 0.05}\n{'loss': 0.2433, 'grad_norm': 3.1649885177612305, 'learning_rate': 1.3333333333333332e-06, 'rewards/chosen': 0.0023246516939252615, 'rewards/rejected': -0.004632347729057074, 'rewards/accuracies': 0.6909375190734863, 'rewards/margins': 0.0069569991901516914, 'logps/rejected': -3.846837043762207, 'logps/chosen': -3.8276190757751465, 'logits/rejected': -37.16633224487305, 'logits/chosen': -36.41049575805664, 'epoch': 0.09}\n{'loss': 0.2327, 'grad_norm': 2.757660150527954, 'learning_rate': 2e-06, 'rewards/chosen': 0.003044223180040717, 'rewards/rejected': -0.016085071489214897, 'rewards/accuracies': 0.6928125023841858, 'rewards/margins': 0.019129294902086258, 'logps/rejected': -3.8917019367218018, 'logps/chosen': -3.8171799182891846, 'logits/rejected': -36.884742736816406, 'logits/chosen': -35.96474075317383, 'epoch': 0.14}\n{'loss': 0.2205, 'grad_norm': 3.0840704441070557, 'learning_rate': 2e-06, 'rewards/chosen': -0.002519834553822875, 'rewards/rejected': -0.038117870688438416, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.0355980321764946, 'logps/rejected': -3.875030517578125, 'logps/chosen': -3.8371458053588867, 'logits/rejected': -36.83112716674805, 'logits/chosen': -35.992332458496094, 'epoch': 0.18}\n{'loss': 0.2113, 'grad_norm': 2.8966469764709473, 'learning_rate': 2e-06, 'rewards/chosen': -0.015315447933971882, 'rewards/rejected': -0.06588128954172134, 'rewards/accuracies': 0.6993749737739563, 'rewards/margins': 0.05056585371494293, 'logps/rejected': -3.9044463634490967, 'logps/chosen': -3.8316755294799805, 'logits/rejected': -36.71363830566406, 'logits/chosen': -35.96705627441406, 'epoch': 0.23}\n{'loss': 0.2073, 'grad_norm': 3.122093439102173, 'learning_rate': 2e-06, 'rewards/chosen': -0.028211141005158424, 'rewards/rejected': -0.08930043876171112, 'rewards/accuracies': 0.6995312571525574, 'rewards/margins': 0.061089299619197845, 'logps/rejected': -3.946303367614746, 'logps/chosen': -3.84855318069458, 'logits/rejected': -36.360774993896484, 'logits/chosen': -35.897342681884766, 'epoch': 0.27}\n{'loss': 0.2011, 'grad_norm': 2.6939356327056885, 'learning_rate': 2e-06, 'rewards/chosen': -0.04026028513908386, 'rewards/rejected': -0.11304224282503128, 'rewards/accuracies': 0.7082812786102295, 'rewards/margins': 0.07278195023536682, 'logps/rejected': -3.9595141410827637, 'logps/chosen': -3.8549938201904297, 'logits/rejected': -36.18486785888672, 'logits/chosen': -35.507171630859375, 'epoch': 0.32}\n{'loss': 0.1956, 'grad_norm': 2.4583795070648193, 'learning_rate': 2e-06, 'rewards/chosen': -0.05093633010983467, 'rewards/rejected': -0.13469380140304565, 'rewards/accuracies': 0.7185937762260437, 'rewards/margins': 0.08375746011734009, 'logps/rejected': -3.9749178886413574, 'logps/chosen': -3.875246047973633, 'logits/rejected': -35.99583053588867, 'logits/chosen': -35.277435302734375, 'epoch': 0.36}\n{'loss': 0.1958, 'grad_norm': 3.084841728210449, 'learning_rate': 2e-06, 'rewards/chosen': -0.06113598495721817, 'rewards/rejected': -0.15076304972171783, 'rewards/accuracies': 0.7103124856948853, 'rewards/margins': 0.08962706476449966, 'logps/rejected': -3.995283603668213, 'logps/chosen': -3.885374069213867, 'logits/rejected': -35.88663864135742, 'logits/chosen': -35.28311538696289, 'epoch': 0.41}\n{'loss': 0.1897, 'grad_norm': 2.456190824508667, 'learning_rate': 2e-06, 'rewards/chosen': -0.06264391541481018, 'rewards/rejected': -0.16214820742607117, 'rewards/accuracies': 0.7276562452316284, 'rewards/margins': 0.09950429946184158, 'logps/rejected': -4.000738143920898, 'logps/chosen': -3.897177219390869, 'logits/rejected': -35.49872589111328, 'logits/chosen': -34.73213195800781, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [08:59<50:55,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.63it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.56it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.95it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.90it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.87it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.85it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.84it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.82it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.80it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:16,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.81it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.80it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.78it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.79it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.80it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.80it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.79it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.79it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.80it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.77it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.79it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.80it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.80it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.78it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:30<00:02,  1.76it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.75it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.74it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.76it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.19030679762363434, 'eval_runtime': 32.5598, 'eval_samples_per_second': 229.394, 'eval_steps_per_second': 1.812, 'eval_rewards/chosen': -0.06620783358812332, 'eval_rewards/rejected': -0.16536419093608856, 'eval_rewards/accuracies': 0.7180202007293701, 'eval_rewards/margins': 0.09915634989738464, 'eval_logps/rejected': -4.008138179779053, 'eval_logps/chosen': -3.8873205184936523, 'eval_logits/rejected': -35.44729995727539, 'eval_logits/chosen': -34.796634674072266, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [09:32<50:55,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.19it/s]\u001b[A\n{'loss': 0.1901, 'grad_norm': 2.5586764812469482, 'learning_rate': 2e-06, 'rewards/chosen': -0.06631389260292053, 'rewards/rejected': -0.16675205528736115, 'rewards/accuracies': 0.7254687547683716, 'rewards/margins': 0.10043815523386002, 'logps/rejected': -4.019967555999756, 'logps/chosen': -3.9054715633392334, 'logits/rejected': -35.34354019165039, 'logits/chosen': -34.71409225463867, 'epoch': 0.5}\n{'loss': 0.1861, 'grad_norm': 2.81911563873291, 'learning_rate': 2e-06, 'rewards/chosen': -0.07158336043357849, 'rewards/rejected': -0.1806313842535019, 'rewards/accuracies': 0.7315624952316284, 'rewards/margins': 0.1090480238199234, 'logps/rejected': -4.042790412902832, 'logps/chosen': -3.8980557918548584, 'logits/rejected': -35.089210510253906, 'logits/chosen': -34.32768249511719, 'epoch': 0.54}\n{'loss': 0.1869, 'grad_norm': 2.295300245285034, 'learning_rate': 2e-06, 'rewards/chosen': -0.0744437649846077, 'rewards/rejected': -0.18317602574825287, 'rewards/accuracies': 0.7235937714576721, 'rewards/margins': 0.10873224586248398, 'logps/rejected': -4.053211212158203, 'logps/chosen': -3.8943731784820557, 'logits/rejected': -34.952266693115234, 'logits/chosen': -34.39366149902344, 'epoch': 0.59}\n{'loss': 0.1844, 'grad_norm': 2.56321382522583, 'learning_rate': 2e-06, 'rewards/chosen': -0.08022470772266388, 'rewards/rejected': -0.19531787931919098, 'rewards/accuracies': 0.7285937666893005, 'rewards/margins': 0.11509314179420471, 'logps/rejected': -4.033105850219727, 'logps/chosen': -3.917599678039551, 'logits/rejected': -34.87732696533203, 'logits/chosen': -34.317745208740234, 'epoch': 0.63}\n{'loss': 0.1836, 'grad_norm': 2.95293927192688, 'learning_rate': 2e-06, 'rewards/chosen': -0.07984745502471924, 'rewards/rejected': -0.19473448395729065, 'rewards/accuracies': 0.7329687476158142, 'rewards/margins': 0.11488702148199081, 'logps/rejected': -4.016342639923096, 'logps/chosen': -3.914405107498169, 'logits/rejected': -34.90470886230469, 'logits/chosen': -34.333648681640625, 'epoch': 0.68}\n{'loss': 0.1845, 'grad_norm': 2.6591734886169434, 'learning_rate': 2e-06, 'rewards/chosen': -0.08037521690130234, 'rewards/rejected': -0.19571447372436523, 'rewards/accuracies': 0.7359374761581421, 'rewards/margins': 0.11533927917480469, 'logps/rejected': -4.0321831703186035, 'logps/chosen': -3.896462917327881, 'logits/rejected': -35.04557800292969, 'logits/chosen': -34.476078033447266, 'epoch': 0.72}\n{'loss': 0.1813, 'grad_norm': 2.257791757583618, 'learning_rate': 2e-06, 'rewards/chosen': -0.08199965208768845, 'rewards/rejected': -0.20410817861557007, 'rewards/accuracies': 0.7393749952316284, 'rewards/margins': 0.12210853397846222, 'logps/rejected': -4.0590901374816895, 'logps/chosen': -3.9196479320526123, 'logits/rejected': -34.698604583740234, 'logits/chosen': -34.09353256225586, 'epoch': 0.77}\n{'loss': 0.1843, 'grad_norm': 2.445220470428467, 'learning_rate': 2e-06, 'rewards/chosen': -0.086065873503685, 'rewards/rejected': -0.2034158855676651, 'rewards/accuracies': 0.7370312213897705, 'rewards/margins': 0.1173500269651413, 'logps/rejected': -4.047191619873047, 'logps/chosen': -3.9257097244262695, 'logits/rejected': -34.762142181396484, 'logits/chosen': -34.08852767944336, 'epoch': 0.81}\n{'loss': 0.1839, 'grad_norm': 2.729949712753296, 'learning_rate': 2e-06, 'rewards/chosen': -0.0859038233757019, 'rewards/rejected': -0.2075413316488266, 'rewards/accuracies': 0.7364062666893005, 'rewards/margins': 0.1216375082731247, 'logps/rejected': -4.046382904052734, 'logps/chosen': -3.8989312648773193, 'logits/rejected': -34.604122161865234, 'logits/chosen': -34.110321044921875, 'epoch': 0.86}\n{'loss': 0.1788, 'grad_norm': 2.5127646923065186, 'learning_rate': 2e-06, 'rewards/chosen': -0.08238598704338074, 'rewards/rejected': -0.20892463624477386, 'rewards/accuracies': 0.7448437213897705, 'rewards/margins': 0.12653866410255432, 'logps/rejected': -4.049542427062988, 'logps/chosen': -3.8954198360443115, 'logits/rejected': -34.692474365234375, 'logits/chosen': -34.141197204589844, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [18:32<41:51,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.84it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.82it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.79it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.80it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.80it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.81it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:16,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.81it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.81it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.79it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.80it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.80it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.80it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.78it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.79it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.80it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.77it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.78it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.79it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.80it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.78it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:30<00:02,  1.76it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.75it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.74it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.76it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.17872855067253113, 'eval_runtime': 32.5574, 'eval_samples_per_second': 229.41, 'eval_steps_per_second': 1.812, 'eval_rewards/chosen': -0.08529618382453918, 'eval_rewards/rejected': -0.2117488831281662, 'eval_rewards/accuracies': 0.7415077686309814, 'eval_rewards/margins': 0.12645268440246582, 'eval_logps/rejected': -4.05452299118042, 'eval_logps/chosen': -3.9064090251922607, 'eval_logits/rejected': -34.53011703491211, 'eval_logits/chosen': -33.943477630615234, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [19:04<41:51,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.19it/s]\u001b[A\n{'loss': 0.1785, 'grad_norm': 2.3185858726501465, 'learning_rate': 2e-06, 'rewards/chosen': -0.08541259914636612, 'rewards/rejected': -0.21080590784549713, 'rewards/accuracies': 0.7482812404632568, 'rewards/margins': 0.1253933161497116, 'logps/rejected': -4.075371265411377, 'logps/chosen': -3.906404972076416, 'logits/rejected': -34.68027114868164, 'logits/chosen': -34.165000915527344, 'epoch': 0.95}\n{'loss': 0.1767, 'grad_norm': 2.51749849319458, 'learning_rate': 2e-06, 'rewards/chosen': -0.08854691684246063, 'rewards/rejected': -0.2206191122531891, 'rewards/accuracies': 0.7510937452316284, 'rewards/margins': 0.13207216560840607, 'logps/rejected': -4.064843654632568, 'logps/chosen': -3.925610303878784, 'logits/rejected': -34.55939865112305, 'logits/chosen': -33.98744583129883, 'epoch': 0.99}\n{'loss': 0.1692, 'grad_norm': 2.262892723083496, 'learning_rate': 2e-06, 'rewards/chosen': -0.08363214135169983, 'rewards/rejected': -0.22391140460968018, 'rewards/accuracies': 0.7748072147369385, 'rewards/margins': 0.14027924835681915, 'logps/rejected': -4.050049304962158, 'logps/chosen': -3.8771677017211914, 'logits/rejected': -34.71031951904297, 'logits/chosen': -33.999454498291016, 'epoch': 1.04}\n{'loss': 0.1636, 'grad_norm': 2.5179126262664795, 'learning_rate': 2e-06, 'rewards/chosen': -0.08250390738248825, 'rewards/rejected': -0.23036131262779236, 'rewards/accuracies': 0.7740625143051147, 'rewards/margins': 0.1478574126958847, 'logps/rejected': -4.090516567230225, 'logps/chosen': -3.909825325012207, 'logits/rejected': -34.451629638671875, 'logits/chosen': -33.861907958984375, 'epoch': 1.08}\n{'loss': 0.1644, 'grad_norm': 2.235267400741577, 'learning_rate': 2e-06, 'rewards/chosen': -0.08548558503389359, 'rewards/rejected': -0.23176583647727966, 'rewards/accuracies': 0.7729687690734863, 'rewards/margins': 0.14628024399280548, 'logps/rejected': -4.062502861022949, 'logps/chosen': -3.904667377471924, 'logits/rejected': -34.89403533935547, 'logits/chosen': -34.3427848815918, 'epoch': 1.13}\n{'loss': 0.1613, 'grad_norm': 2.140763998031616, 'learning_rate': 2e-06, 'rewards/chosen': -0.08254802972078323, 'rewards/rejected': -0.23242676258087158, 'rewards/accuracies': 0.7806249856948853, 'rewards/margins': 0.14987874031066895, 'logps/rejected': -4.073951244354248, 'logps/chosen': -3.905183792114258, 'logits/rejected': -34.752418518066406, 'logits/chosen': -34.11312484741211, 'epoch': 1.17}\n{'loss': 0.1625, 'grad_norm': 2.2727339267730713, 'learning_rate': 2e-06, 'rewards/chosen': -0.08619263023138046, 'rewards/rejected': -0.23858152329921722, 'rewards/accuracies': 0.7796875238418579, 'rewards/margins': 0.15238890051841736, 'logps/rejected': -4.107832431793213, 'logps/chosen': -3.9058218002319336, 'logits/rejected': -34.11894989013672, 'logits/chosen': -33.76914978027344, 'epoch': 1.22}\n{'loss': 0.1636, 'grad_norm': 2.308379650115967, 'learning_rate': 2e-06, 'rewards/chosen': -0.09435378760099411, 'rewards/rejected': -0.24413619935512543, 'rewards/accuracies': 0.7862499952316284, 'rewards/margins': 0.14978240430355072, 'logps/rejected': -4.101320743560791, 'logps/chosen': -3.943634033203125, 'logits/rejected': -34.534732818603516, 'logits/chosen': -33.920921325683594, 'epoch': 1.26}\n{'loss': 0.165, 'grad_norm': 2.4348483085632324, 'learning_rate': 2e-06, 'rewards/chosen': -0.08857807517051697, 'rewards/rejected': -0.23927342891693115, 'rewards/accuracies': 0.7734375, 'rewards/margins': 0.150695338845253, 'logps/rejected': -4.088519096374512, 'logps/chosen': -3.9060988426208496, 'logits/rejected': -34.60272979736328, 'logits/chosen': -34.06966781616211, 'epoch': 1.31}\n{'loss': 0.167, 'grad_norm': 2.2853212356567383, 'learning_rate': 2e-06, 'rewards/chosen': -0.09333926439285278, 'rewards/rejected': -0.23640882968902588, 'rewards/accuracies': 0.7715625166893005, 'rewards/margins': 0.1430695652961731, 'logps/rejected': -4.0791916847229, 'logps/chosen': -3.924480676651001, 'logits/rejected': -34.537994384765625, 'logits/chosen': -34.0160026550293, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [28:06<32:41,  1.07s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.62it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.56it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.95it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.90it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.87it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:27,  1.85it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:05<00:26,  1.84it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.82it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.82it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.78it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.79it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.79it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.80it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.80it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:10<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.80it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:21,  1.80it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:20,  1.80it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.80it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.80it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:15<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:16,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.81it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.81it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:14,  1.77it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.78it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.79it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:20<00:12,  1.79it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.80it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.79it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.77it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.78it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.79it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.80it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.80it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:25<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.79it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.77it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.78it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.79it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.79it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.80it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.80it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.78it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:30<00:02,  1.76it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.75it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.74it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.76it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.17225949466228485, 'eval_runtime': 32.6588, 'eval_samples_per_second': 228.698, 'eval_steps_per_second': 1.807, 'eval_rewards/chosen': -0.09472032636404037, 'eval_rewards/rejected': -0.23447422683238983, 'eval_rewards/accuracies': 0.7562971115112305, 'eval_rewards/margins': 0.13975390791893005, 'eval_logps/rejected': -4.0772480964660645, 'eval_logps/chosen': -3.915832996368408, 'eval_logits/rejected': -34.62209701538086, 'eval_logits/chosen': -34.05485534667969, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [28:38<32:41,  1.07s/it]\n100%|███████████████████████████████████████████| 59/59 [00:32<00:00,  2.19it/s]\u001b[A\n{'loss': 0.1619, 'grad_norm': 2.6946558952331543, 'learning_rate': 2e-06, 'rewards/chosen': -0.09064489603042603, 'rewards/rejected': -0.24267597496509552, 'rewards/accuracies': 0.785937488079071, 'rewards/margins': 0.1520310938358307, 'logps/rejected': -4.073473930358887, 'logps/chosen': -3.9128661155700684, 'logits/rejected': -34.72728729248047, 'logits/chosen': -34.087791442871094, 'epoch': 1.4}\n{'loss': 0.1601, 'grad_norm': 2.343165636062622, 'learning_rate': 2e-06, 'rewards/chosen': -0.09275418519973755, 'rewards/rejected': -0.24872137606143951, 'rewards/accuracies': 0.7856249809265137, 'rewards/margins': 0.15596717596054077, 'logps/rejected': -4.096132278442383, 'logps/chosen': -3.8997392654418945, 'logits/rejected': -35.13920593261719, 'logits/chosen': -34.47434997558594, 'epoch': 1.44}\n{'loss': 0.1588, 'grad_norm': 2.2889251708984375, 'learning_rate': 2e-06, 'rewards/chosen': -0.09660472720861435, 'rewards/rejected': -0.25701266527175903, 'rewards/accuracies': 0.7854687571525574, 'rewards/margins': 0.16040796041488647, 'logps/rejected': -4.103851795196533, 'logps/chosen': -3.923283576965332, 'logits/rejected': -34.88810729980469, 'logits/chosen': -34.33070755004883, 'epoch': 1.49}\n{'loss': 0.1639, 'grad_norm': 2.2933506965637207, 'learning_rate': 2e-06, 'rewards/chosen': -0.09362657368183136, 'rewards/rejected': -0.2460555136203766, 'rewards/accuracies': 0.7774999737739563, 'rewards/margins': 0.15242896974086761, 'logps/rejected': -4.08950138092041, 'logps/chosen': -3.9025232791900635, 'logits/rejected': -34.96514129638672, 'logits/chosen': -34.51816177368164, 'epoch': 1.53}\n{'loss': 0.1582, 'grad_norm': 2.411190986633301, 'learning_rate': 2e-06, 'rewards/chosen': -0.09333760291337967, 'rewards/rejected': -0.25201931595802307, 'rewards/accuracies': 0.7862499952316284, 'rewards/margins': 0.1586817055940628, 'logps/rejected': -4.102113723754883, 'logps/chosen': -3.9230880737304688, 'logits/rejected': -35.030548095703125, 'logits/chosen': -34.44824981689453, 'epoch': 1.58}\n{'loss': 0.1615, 'grad_norm': 2.2154860496520996, 'learning_rate': 2e-06, 'rewards/chosen': -0.09797900915145874, 'rewards/rejected': -0.25452330708503723, 'rewards/accuracies': 0.7782812714576721, 'rewards/margins': 0.1565442681312561, 'logps/rejected': -4.100203990936279, 'logps/chosen': -3.943415641784668, 'logits/rejected': -35.02532196044922, 'logits/chosen': -34.474632263183594, 'epoch': 1.62}\n{'loss': 0.1617, 'grad_norm': 2.4960169792175293, 'learning_rate': 2e-06, 'rewards/chosen': -0.09457537531852722, 'rewards/rejected': -0.2503114640712738, 'rewards/accuracies': 0.7815625071525574, 'rewards/margins': 0.15573610365390778, 'logps/rejected': -4.110795497894287, 'logps/chosen': -3.91145658493042, 'logits/rejected': -34.991058349609375, 'logits/chosen': -34.371822357177734, 'epoch': 1.67}\n{'loss': 0.1603, 'grad_norm': 2.4514193534851074, 'learning_rate': 2e-06, 'rewards/chosen': -0.09487888216972351, 'rewards/rejected': -0.2520955204963684, 'rewards/accuracies': 0.784375011920929, 'rewards/margins': 0.1572166383266449, 'logps/rejected': -4.101234436035156, 'logps/chosen': -3.9350028038024902, 'logits/rejected': -35.21684265136719, 'logits/chosen': -34.78190994262695, 'epoch': 1.71}\n{'loss': 0.1627, 'grad_norm': 2.0496160984039307, 'learning_rate': 2e-06, 'rewards/chosen': -0.09422272443771362, 'rewards/rejected': -0.24868690967559814, 'rewards/accuracies': 0.7771875262260437, 'rewards/margins': 0.15446418523788452, 'logps/rejected': -4.0952534675598145, 'logps/chosen': -3.927760601043701, 'logits/rejected': -35.2386589050293, 'logits/chosen': -34.88345718383789, 'epoch': 1.76}\n{'loss': 0.1589, 'grad_norm': 2.3356196880340576, 'learning_rate': 2e-06, 'rewards/chosen': -0.09251609444618225, 'rewards/rejected': -0.25041663646698, 'rewards/accuracies': 0.7890625, 'rewards/margins': 0.15790052711963654, 'logps/rejected': -4.122124195098877, 'logps/chosen': -3.9152328968048096, 'logits/rejected': -35.376251220703125, 'logits/chosen': -34.74866485595703, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [37:39<24:00,  1.09s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.63it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.56it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.95it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.90it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.87it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:31,  1.61it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:05<00:29,  1.67it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:28,  1.71it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:27,  1.74it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:26,  1.76it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.75it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:08<00:24,  1.77it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:24,  1.78it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:09<00:23,  1.79it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.80it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:10<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:13<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.81it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:14<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:15<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.81it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.79it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:19<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:20<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.79it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.80it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:24<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:25<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.79it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:28<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.80it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:29<00:03,  1.80it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.78it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:30<00:02,  1.76it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.75it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.74it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.76it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.1681637316942215, 'eval_runtime': 32.7962, 'eval_samples_per_second': 227.739, 'eval_steps_per_second': 1.799, 'eval_rewards/chosen': -0.10353033244609833, 'eval_rewards/rejected': -0.25296512246131897, 'eval_rewards/accuracies': 0.7635592818260193, 'eval_rewards/margins': 0.14943480491638184, 'eval_logps/rejected': -4.095738887786865, 'eval_logps/chosen': -3.924643039703369, 'eval_logits/rejected': -35.4334831237793, 'eval_logits/chosen': -34.89548110961914, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [38:11<24:00,  1.09s/it]\n100%|███████████████████████████████████████████| 59/59 [00:32<00:00,  2.19it/s]\u001b[A\n{'loss': 0.1574, 'grad_norm': 2.5183796882629395, 'learning_rate': 2e-06, 'rewards/chosen': -0.09581334888935089, 'rewards/rejected': -0.25966233015060425, 'rewards/accuracies': 0.7901562452316284, 'rewards/margins': 0.16384895145893097, 'logps/rejected': -4.086102485656738, 'logps/chosen': -3.9180994033813477, 'logits/rejected': -35.82475662231445, 'logits/chosen': -35.24325180053711, 'epoch': 1.85}\n{'loss': 0.1575, 'grad_norm': 2.38411021232605, 'learning_rate': 2e-06, 'rewards/chosen': -0.0930052101612091, 'rewards/rejected': -0.2557058036327362, 'rewards/accuracies': 0.7871875166893005, 'rewards/margins': 0.1627005785703659, 'logps/rejected': -4.115695953369141, 'logps/chosen': -3.927311897277832, 'logits/rejected': -35.5052604675293, 'logits/chosen': -35.096885681152344, 'epoch': 1.89}\n{'loss': 0.1589, 'grad_norm': 2.3966596126556396, 'learning_rate': 2e-06, 'rewards/chosen': -0.09883785247802734, 'rewards/rejected': -0.2576795816421509, 'rewards/accuracies': 0.7842187285423279, 'rewards/margins': 0.15884169936180115, 'logps/rejected': -4.1046247482299805, 'logps/chosen': -3.93923282623291, 'logits/rejected': -35.562782287597656, 'logits/chosen': -35.072208404541016, 'epoch': 1.94}\n{'loss': 0.1554, 'grad_norm': 2.3230197429656982, 'learning_rate': 2e-06, 'rewards/chosen': -0.09880620986223221, 'rewards/rejected': -0.2663330137729645, 'rewards/accuracies': 0.7892187237739563, 'rewards/margins': 0.16752678155899048, 'logps/rejected': -4.106955528259277, 'logps/chosen': -3.9337081909179688, 'logits/rejected': -35.563438415527344, 'logits/chosen': -34.994476318359375, 'epoch': 1.98}\n{'loss': 0.1507, 'grad_norm': 2.2173454761505127, 'learning_rate': 2e-06, 'rewards/chosen': -0.09006847441196442, 'rewards/rejected': -0.26240602135658264, 'rewards/accuracies': 0.8065218925476074, 'rewards/margins': 0.17233753204345703, 'logps/rejected': -4.107629776000977, 'logps/chosen': -3.9249045848846436, 'logits/rejected': -35.611873626708984, 'logits/chosen': -35.133384704589844, 'epoch': 2.03}\n{'loss': 0.1461, 'grad_norm': 2.031576633453369, 'learning_rate': 2e-06, 'rewards/chosen': -0.087925985455513, 'rewards/rejected': -0.26390960812568665, 'rewards/accuracies': 0.8126562237739563, 'rewards/margins': 0.17598360776901245, 'logps/rejected': -4.092154502868652, 'logps/chosen': -3.9319651126861572, 'logits/rejected': -35.931766510009766, 'logits/chosen': -35.12023162841797, 'epoch': 2.07}\n{'loss': 0.1448, 'grad_norm': 2.3628010749816895, 'learning_rate': 2e-06, 'rewards/chosen': -0.08782579749822617, 'rewards/rejected': -0.2653660774230957, 'rewards/accuracies': 0.8198437690734863, 'rewards/margins': 0.17754030227661133, 'logps/rejected': -4.104126453399658, 'logps/chosen': -3.920302152633667, 'logits/rejected': -35.65934371948242, 'logits/chosen': -35.19595718383789, 'epoch': 2.12}\n{'loss': 0.1452, 'grad_norm': 2.1046924591064453, 'learning_rate': 2e-06, 'rewards/chosen': -0.0896386057138443, 'rewards/rejected': -0.26610681414604187, 'rewards/accuracies': 0.82421875, 'rewards/margins': 0.17646822333335876, 'logps/rejected': -4.113081455230713, 'logps/chosen': -3.9233646392822266, 'logits/rejected': -35.53104019165039, 'logits/chosen': -35.2968864440918, 'epoch': 2.16}\n{'loss': 0.1464, 'grad_norm': 2.36904239654541, 'learning_rate': 2e-06, 'rewards/chosen': -0.09719695150852203, 'rewards/rejected': -0.2741001844406128, 'rewards/accuracies': 0.8149999976158142, 'rewards/margins': 0.17690320312976837, 'logps/rejected': -4.131321907043457, 'logps/chosen': -3.9171247482299805, 'logits/rejected': -35.97814178466797, 'logits/chosen': -35.629600524902344, 'epoch': 2.21}\n{'loss': 0.1412, 'grad_norm': 2.211703062057495, 'learning_rate': 2e-06, 'rewards/chosen': -0.09387125074863434, 'rewards/rejected': -0.2757517695426941, 'rewards/accuracies': 0.8279687762260437, 'rewards/margins': 0.18188048899173737, 'logps/rejected': -4.147150993347168, 'logps/chosen': -3.935433864593506, 'logits/rejected': -36.18053436279297, 'logits/chosen': -35.57260513305664, 'epoch': 2.25}\n 75%|█████████████████████████████▎         | 2500/3327 [47:13<14:51,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.63it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.56it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.95it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.84it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.79it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.80it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:21,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.81it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.78it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.79it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.80it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.78it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.79it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.80it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.80it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.78it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:30<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.16458289325237274, 'eval_runtime': 32.5224, 'eval_samples_per_second': 229.657, 'eval_steps_per_second': 1.814, 'eval_rewards/chosen': -0.10944020748138428, 'eval_rewards/rejected': -0.26713526248931885, 'eval_rewards/accuracies': 0.7685911059379578, 'eval_rewards/margins': 0.15769505500793457, 'eval_logps/rejected': -4.109909534454346, 'eval_logps/chosen': -3.9305531978607178, 'eval_logits/rejected': -36.11642074584961, 'eval_logits/chosen': -35.59843444824219, 'epoch': 2.25}\n 75%|█████████████████████████████▎         | 2500/3327 [47:45<14:51,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.1417, 'grad_norm': 2.2018985748291016, 'learning_rate': 2e-06, 'rewards/chosen': -0.09869888424873352, 'rewards/rejected': -0.2856849431991577, 'rewards/accuracies': 0.8253124952316284, 'rewards/margins': 0.1869860291481018, 'logps/rejected': -4.128906726837158, 'logps/chosen': -3.9361464977264404, 'logits/rejected': -36.262428283691406, 'logits/chosen': -35.56597137451172, 'epoch': 2.3}\n{'loss': 0.1416, 'grad_norm': 2.3047051429748535, 'learning_rate': 2e-06, 'rewards/chosen': -0.09099452942609787, 'rewards/rejected': -0.27638888359069824, 'rewards/accuracies': 0.8168749809265137, 'rewards/margins': 0.18539434671401978, 'logps/rejected': -4.141351222991943, 'logps/chosen': -3.9113826751708984, 'logits/rejected': -36.2109489440918, 'logits/chosen': -35.70439529418945, 'epoch': 2.34}\n{'loss': 0.1434, 'grad_norm': 2.12469482421875, 'learning_rate': 2e-06, 'rewards/chosen': -0.09842059761285782, 'rewards/rejected': -0.2820906937122345, 'rewards/accuracies': 0.8223437666893005, 'rewards/margins': 0.18367010354995728, 'logps/rejected': -4.1490888595581055, 'logps/chosen': -3.925018072128296, 'logits/rejected': -36.161354064941406, 'logits/chosen': -35.703407287597656, 'epoch': 2.39}\n{'loss': 0.1446, 'grad_norm': 2.4810378551483154, 'learning_rate': 2e-06, 'rewards/chosen': -0.09920726716518402, 'rewards/rejected': -0.28310179710388184, 'rewards/accuracies': 0.8179687261581421, 'rewards/margins': 0.18389450013637543, 'logps/rejected': -4.115094184875488, 'logps/chosen': -3.905444383621216, 'logits/rejected': -36.44297790527344, 'logits/chosen': -35.97117614746094, 'epoch': 2.43}\n{'loss': 0.1432, 'grad_norm': 2.2889564037323, 'learning_rate': 2e-06, 'rewards/chosen': -0.09806286543607712, 'rewards/rejected': -0.28353944420814514, 'rewards/accuracies': 0.8168749809265137, 'rewards/margins': 0.18547658622264862, 'logps/rejected': -4.122276306152344, 'logps/chosen': -3.912203788757324, 'logits/rejected': -36.76993942260742, 'logits/chosen': -36.23222351074219, 'epoch': 2.48}\n{'loss': 0.145, 'grad_norm': 2.3141329288482666, 'learning_rate': 2e-06, 'rewards/chosen': -0.10496936738491058, 'rewards/rejected': -0.2851879298686981, 'rewards/accuracies': 0.8181250095367432, 'rewards/margins': 0.18021856248378754, 'logps/rejected': -4.1288838386535645, 'logps/chosen': -3.9399831295013428, 'logits/rejected': -36.766136169433594, 'logits/chosen': -36.326438903808594, 'epoch': 2.52}\n{'loss': 0.1451, 'grad_norm': 2.4024674892425537, 'learning_rate': 2e-06, 'rewards/chosen': -0.09727568924427032, 'rewards/rejected': -0.27740761637687683, 'rewards/accuracies': 0.8151562213897705, 'rewards/margins': 0.1801319122314453, 'logps/rejected': -4.130893707275391, 'logps/chosen': -3.923382520675659, 'logits/rejected': -36.777523040771484, 'logits/chosen': -36.4157829284668, 'epoch': 2.57}\n{'loss': 0.139, 'grad_norm': 2.535959005355835, 'learning_rate': 2e-06, 'rewards/chosen': -0.09679576009511948, 'rewards/rejected': -0.28676846623420715, 'rewards/accuracies': 0.8318750262260437, 'rewards/margins': 0.18997272849082947, 'logps/rejected': -4.123071193695068, 'logps/chosen': -3.919067144393921, 'logits/rejected': -36.87550735473633, 'logits/chosen': -36.25920867919922, 'epoch': 2.61}\n{'loss': 0.1414, 'grad_norm': 2.4600303173065186, 'learning_rate': 2e-06, 'rewards/chosen': -0.09935025125741959, 'rewards/rejected': -0.2845882177352905, 'rewards/accuracies': 0.8207812309265137, 'rewards/margins': 0.18523800373077393, 'logps/rejected': -4.13784122467041, 'logps/chosen': -3.928596258163452, 'logits/rejected': -36.89154052734375, 'logits/chosen': -36.28272247314453, 'epoch': 2.66}\n{'loss': 0.1397, 'grad_norm': 2.3828208446502686, 'learning_rate': 2e-06, 'rewards/chosen': -0.10402972251176834, 'rewards/rejected': -0.29354846477508545, 'rewards/accuracies': 0.8310937285423279, 'rewards/margins': 0.1895187348127365, 'logps/rejected': -4.154260635375977, 'logps/chosen': -3.9221484661102295, 'logits/rejected': -36.82725524902344, 'logits/chosen': -36.40426254272461, 'epoch': 2.71}\n 90%|███████████████████████████████████▏   | 3000/3327 [56:45<05:51,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.64it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.82it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.79it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.80it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.81it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.80it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.78it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.79it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.80it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.78it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.76it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.75it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.76it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.1616898477077484, 'eval_runtime': 32.5118, 'eval_samples_per_second': 229.732, 'eval_steps_per_second': 1.815, 'eval_rewards/chosen': -0.1164620965719223, 'eval_rewards/rejected': -0.2817018926143646, 'eval_rewards/accuracies': 0.7734904289245605, 'eval_rewards/margins': 0.16523979604244232, 'eval_logps/rejected': -4.124475955963135, 'eval_logps/chosen': -3.937574625015259, 'eval_logits/rejected': -36.65472412109375, 'eval_logits/chosen': -36.154022216796875, 'epoch': 2.71}\n 90%|███████████████████████████████████▏   | 3000/3327 [57:17<05:51,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.19it/s]\u001b[A\n{'loss': 0.1421, 'grad_norm': 2.3303170204162598, 'learning_rate': 2e-06, 'rewards/chosen': -0.10263238102197647, 'rewards/rejected': -0.2894769608974457, 'rewards/accuracies': 0.828906238079071, 'rewards/margins': 0.186844602227211, 'logps/rejected': -4.135072708129883, 'logps/chosen': -3.9125919342041016, 'logits/rejected': -36.8740234375, 'logits/chosen': -36.35078430175781, 'epoch': 2.75}\n{'loss': 0.1397, 'grad_norm': 2.370539903640747, 'learning_rate': 2e-06, 'rewards/chosen': -0.09958984702825546, 'rewards/rejected': -0.2895607650279999, 'rewards/accuracies': 0.8301562666893005, 'rewards/margins': 0.1899709552526474, 'logps/rejected': -4.13436222076416, 'logps/chosen': -3.9291067123413086, 'logits/rejected': -36.70480728149414, 'logits/chosen': -36.16616439819336, 'epoch': 2.8}\n{'loss': 0.1415, 'grad_norm': 2.258518695831299, 'learning_rate': 2e-06, 'rewards/chosen': -0.10097379982471466, 'rewards/rejected': -0.2902180552482605, 'rewards/accuracies': 0.8223437666893005, 'rewards/margins': 0.18924427032470703, 'logps/rejected': -4.150080680847168, 'logps/chosen': -3.940066337585449, 'logits/rejected': -36.95111846923828, 'logits/chosen': -36.33482360839844, 'epoch': 2.84}\n{'loss': 0.1393, 'grad_norm': 2.246769666671753, 'learning_rate': 2e-06, 'rewards/chosen': -0.09866629540920258, 'rewards/rejected': -0.28964146971702576, 'rewards/accuracies': 0.8260937333106995, 'rewards/margins': 0.1909751445055008, 'logps/rejected': -4.126737594604492, 'logps/chosen': -3.937664747238159, 'logits/rejected': -36.827423095703125, 'logits/chosen': -36.22774887084961, 'epoch': 2.89}\n{'loss': 0.142, 'grad_norm': 2.2996466159820557, 'learning_rate': 2e-06, 'rewards/chosen': -0.09891469031572342, 'rewards/rejected': -0.28674229979515076, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 0.18782758712768555, 'logps/rejected': -4.109068393707275, 'logps/chosen': -3.925323724746704, 'logits/rejected': -36.872215270996094, 'logits/chosen': -36.35319137573242, 'epoch': 2.93}\n{'loss': 0.1402, 'grad_norm': 2.3249197006225586, 'learning_rate': 2e-06, 'rewards/chosen': -0.09959162771701813, 'rewards/rejected': -0.2883461117744446, 'rewards/accuracies': 0.8243749737739563, 'rewards/margins': 0.18875449895858765, 'logps/rejected': -4.144773960113525, 'logps/chosen': -3.9265286922454834, 'logits/rejected': -37.184242248535156, 'logits/chosen': -36.75415802001953, 'epoch': 2.98}\n{'train_runtime': 3808.6168, 'train_samples_per_second': 111.774, 'train_steps_per_second': 0.874, 'train_loss': 0.16710453252732163, 'epoch': 3.0}\n100%|█████████████████████████████████████| 3327/3327 [1:03:11<00:00,  1.14s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python ppo.py --exp_name=eval --log_with=wandb --eval_model=./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-3327\n!python ppo.py --exp_name=eval --log_with=wandb --eval_model=./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-2218\n!python ppo.py --exp_name=eval --log_with=wandb --eval_model=./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-1109","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:08:20.425575Z","iopub.execute_input":"2024-05-26T02:08:20.426309Z","iopub.status.idle":"2024-05-26T02:22:46.958657Z","shell.execute_reply.started":"2024-05-26T02:08:20.426274Z","shell.execute_reply":"2024-05-26T02:22:46.957443Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"2024-05-26 02:08:27.196172: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 02:08:27.196239: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 02:08:27.197850: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-3327', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.02.08'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-3327\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_020844-bbsmlpma\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.02.08\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/bbsmlpma\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:26<03:34, 26.83s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:53<03:06, 26.61s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:19<02:39, 26.62s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:46<02:13, 26.65s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:13<01:46, 26.65s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:39<01:19, 26.64s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:06<00:53, 26.64s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:33<00:26, 26.62s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [03:59<00:00, 26.65s/it]\nmean test reward 0.8438052224468416 +/- 0.00745899723425938 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9986588954925537 from 0.00922983093187213\nmean KL -0.14403468398247948 +/- 0.0655904952778155 full 3.1792551460675895 +/- 0.02269436460290995\nmedian KL 0.2520570755004883 full 2.975912094116211\n2024-05-26 02:13:18.522645: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 02:13:18.522714: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 02:13:18.524152: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-2218', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.02.13'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-2218\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_021332-gv4h09a7\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.02.13\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/gv4h09a7\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:26<03:35, 26.90s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:53<03:06, 26.62s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:19<02:39, 26.58s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:46<02:13, 26.61s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:12<01:46, 26.56s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:39<01:19, 26.54s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:06<00:53, 26.55s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:32<00:26, 26.55s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [03:59<00:00, 26.59s/it]\nmean test reward 0.8401381700773274 +/- 0.007535686547229095 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9986059665679932 from 0.00922983093187213\nmean KL 0.2811283413385455 +/- 0.05678357292554059 full 2.8075261599280767 +/- 0.022273558545105144\nmedian KL 0.6321814656257629 full 2.5922363996505737\n2024-05-26 02:18:05.145633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 02:18:05.145699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 02:18:05.147056: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-1109', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.02.18'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_1_0_lr2e_6-2024.05.26.00.58/checkpoint-1109\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_021818-3nv27fwr\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.02.18\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/3nv27fwr\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:27<03:36, 27.09s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:53<03:07, 26.80s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:20<02:40, 26.72s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:46<02:13, 26.68s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:13<01:47, 26.76s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:40<01:20, 26.71s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:07<00:53, 26.73s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:33<00:26, 26.68s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [04:00<00:00, 26.71s/it]\nmean test reward 0.8103125500199566 +/- 0.00806261335318418 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9985139966011047 from 0.00922983093187213\nmean KL 0.8624516283873365 +/- 0.05058033061962911 full 2.4575935094876007 +/- 0.021985834698342064\nmedian KL 1.1082514524459839 full 2.272499442100525\n","output_type":"stream"}]},{"cell_type":"code","source":"! python dpo.py  --loss_type=ipo --output_dir=test_ipo_1_6_lr2e_6  --beta=1.6 --dataset_name=/kaggle/working/cs234-project/pref_pairs_16_token_tokenized_split     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128  --per_device_eval_batch_size 128     --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 150     --report_to wandb     --logging_first_step --logging_strategy='steps' --logging_steps 50  --eval_steps=500 --no_remove_unused_columns --save_total_limit=4 --evaluation_strategy='steps' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch'","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:27:01.303731Z","iopub.execute_input":"2024-05-26T02:27:01.304157Z","iopub.status.idle":"2024-05-26T03:30:40.638713Z","shell.execute_reply.started":"2024-05-26T02:27:01.304116Z","shell.execute_reply":"2024-05-26T03:30:40.637555Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"2024-05-26 02:27:07.227252: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 02:27:07.227308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 02:27:07.228798: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\nds len 149370\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_022713-fzap2crd\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtest_ipo_1_6_lr2e_6\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface/runs/fzap2crd\u001b[0m\n  0%|                                                  | 0/3327 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 0.0977, 'grad_norm': 1.8070273399353027, 'learning_rate': 1.3333333333333334e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -3.736757755279541, 'logps/chosen': -3.8562333583831787, 'logits/rejected': -39.777442932128906, 'logits/chosen': -37.3552131652832, 'epoch': 0.0}\n{'loss': 0.0971, 'grad_norm': 1.8397761583328247, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': 0.0006718907970935106, 'rewards/rejected': -0.0008770999847911298, 'rewards/accuracies': 0.6600765585899353, 'rewards/margins': 0.0015489907236769795, 'logps/rejected': -3.8712100982666016, 'logps/chosen': -3.845106363296509, 'logits/rejected': -37.4954833984375, 'logits/chosen': -36.51937484741211, 'epoch': 0.05}\n{'loss': 0.0937, 'grad_norm': 1.963533639907837, 'learning_rate': 1.3333333333333332e-06, 'rewards/chosen': 0.0037238984368741512, 'rewards/rejected': -0.007245006039738655, 'rewards/accuracies': 0.6917187571525574, 'rewards/margins': 0.010968904942274094, 'logps/rejected': -3.8467328548431396, 'logps/chosen': -3.8276162147521973, 'logits/rejected': -37.16984939575195, 'logits/chosen': -36.413883209228516, 'epoch': 0.09}\n{'loss': 0.0878, 'grad_norm': 1.6796958446502686, 'learning_rate': 2e-06, 'rewards/chosen': 0.005383769050240517, 'rewards/rejected': -0.024007363244891167, 'rewards/accuracies': 0.696093738079071, 'rewards/margins': 0.029391132295131683, 'logps/rejected': -3.8906216621398926, 'logps/chosen': -3.816859245300293, 'logits/rejected': -36.909400939941406, 'logits/chosen': -35.98683166503906, 'epoch': 0.14}\n{'loss': 0.0822, 'grad_norm': 1.9375779628753662, 'learning_rate': 2e-06, 'rewards/chosen': -0.000444927834905684, 'rewards/rejected': -0.05266577750444412, 'rewards/accuracies': 0.7026562690734863, 'rewards/margins': 0.052220843732357025, 'logps/rejected': -3.869828701019287, 'logps/chosen': -3.834904193878174, 'logits/rejected': -36.888511657714844, 'logits/chosen': -36.04035949707031, 'epoch': 0.18}\n{'loss': 0.0788, 'grad_norm': 1.8257110118865967, 'learning_rate': 2e-06, 'rewards/chosen': -0.01227033231407404, 'rewards/rejected': -0.08239449560642242, 'rewards/accuracies': 0.7037500143051147, 'rewards/margins': 0.07012417167425156, 'logps/rejected': -3.8900623321533203, 'logps/chosen': -3.824028968811035, 'logits/rejected': -36.801353454589844, 'logits/chosen': -36.034278869628906, 'epoch': 0.23}\n{'loss': 0.0781, 'grad_norm': 1.9915480613708496, 'learning_rate': 2e-06, 'rewards/chosen': -0.020838318392634392, 'rewards/rejected': -0.10066325217485428, 'rewards/accuracies': 0.7073437571525574, 'rewards/margins': 0.07982493191957474, 'logps/rejected': -3.9199182987213135, 'logps/chosen': -3.8333661556243896, 'logits/rejected': -36.46018981933594, 'logits/chosen': -35.957313537597656, 'epoch': 0.27}\n{'loss': 0.0757, 'grad_norm': 1.6712610721588135, 'learning_rate': 2e-06, 'rewards/chosen': -0.027927381917834282, 'rewards/rejected': -0.11862283945083618, 'rewards/accuracies': 0.7151562571525574, 'rewards/margins': 0.09069544076919556, 'logps/rejected': -3.9206113815307617, 'logps/chosen': -3.832188129425049, 'logits/rejected': -36.323429107666016, 'logits/chosen': -35.59195327758789, 'epoch': 0.32}\n{'loss': 0.0735, 'grad_norm': 1.5145223140716553, 'learning_rate': 2e-06, 'rewards/chosen': -0.03285873308777809, 'rewards/rejected': -0.13444490730762482, 'rewards/accuracies': 0.7282812595367432, 'rewards/margins': 0.10158616304397583, 'logps/rejected': -3.9242522716522217, 'logps/chosen': -3.844846248626709, 'logits/rejected': -36.167091369628906, 'logits/chosen': -35.390480041503906, 'epoch': 0.36}\n{'loss': 0.0742, 'grad_norm': 1.9674794673919678, 'learning_rate': 2e-06, 'rewards/chosen': -0.03805941715836525, 'rewards/rejected': -0.14350846409797668, 'rewards/accuracies': 0.7209374904632568, 'rewards/margins': 0.10544905066490173, 'logps/rejected': -3.934213161468506, 'logps/chosen': -3.848025321960449, 'logits/rejected': -36.101295471191406, 'logits/chosen': -35.426883697509766, 'epoch': 0.41}\n{'loss': 0.0716, 'grad_norm': 1.4953793287277222, 'learning_rate': 2e-06, 'rewards/chosen': -0.03612474724650383, 'rewards/rejected': -0.15078508853912354, 'rewards/accuracies': 0.7376562356948853, 'rewards/margins': 0.1146603524684906, 'logps/rejected': -3.932830572128296, 'logps/chosen': -3.8571109771728516, 'logits/rejected': -35.788753509521484, 'logits/chosen': -34.94389343261719, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [08:59<50:52,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.94it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.90it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.87it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.83it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.07188049703836441, 'eval_runtime': 32.4512, 'eval_samples_per_second': 230.161, 'eval_steps_per_second': 1.818, 'eval_rewards/chosen': -0.03839755058288574, 'eval_rewards/rejected': -0.15196478366851807, 'eval_rewards/accuracies': 0.7308439612388611, 'eval_rewards/margins': 0.11356725543737411, 'eval_logps/rejected': -3.9377520084381104, 'eval_logps/chosen': -3.8451108932495117, 'eval_logits/rejected': -35.768646240234375, 'eval_logits/chosen': -35.024742126464844, 'epoch': 0.45}\n 15%|██████                                  | 500/3327 [09:31<50:52,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.0721, 'grad_norm': 1.6112372875213623, 'learning_rate': 2e-06, 'rewards/chosen': -0.0374462828040123, 'rewards/rejected': -0.15156732499599457, 'rewards/accuracies': 0.7354687452316284, 'rewards/margins': 0.11412105709314346, 'logps/rejected': -3.9479446411132812, 'logps/chosen': -3.8625612258911133, 'logits/rejected': -35.675071716308594, 'logits/chosen': -34.958187103271484, 'epoch': 0.5}\n{'loss': 0.0708, 'grad_norm': 1.7467293739318848, 'learning_rate': 2e-06, 'rewards/chosen': -0.04035944119095802, 'rewards/rejected': -0.16264024376869202, 'rewards/accuracies': 0.7426562309265137, 'rewards/margins': 0.12228080630302429, 'logps/rejected': -3.9638092517852783, 'logps/chosen': -3.8516969680786133, 'logits/rejected': -35.517189025878906, 'logits/chosen': -34.679141998291016, 'epoch': 0.54}\n{'loss': 0.0708, 'grad_norm': 1.4022647142410278, 'learning_rate': 2e-06, 'rewards/chosen': -0.04176219925284386, 'rewards/rejected': -0.16373804211616516, 'rewards/accuracies': 0.7373437285423279, 'rewards/margins': 0.12197583168745041, 'logps/rejected': -3.9723715782165527, 'logps/chosen': -3.8460309505462646, 'logits/rejected': -35.44643020629883, 'logits/chosen': -34.79594802856445, 'epoch': 0.59}\n{'loss': 0.07, 'grad_norm': 1.5399590730667114, 'learning_rate': 2e-06, 'rewards/chosen': -0.04677054286003113, 'rewards/rejected': -0.1747138947248459, 'rewards/accuracies': 0.7403125166893005, 'rewards/margins': 0.12794336676597595, 'logps/rejected': -3.94698429107666, 'logps/chosen': -3.8666069507598877, 'logits/rejected': -35.441104888916016, 'logits/chosen': -34.788169860839844, 'epoch': 0.63}\n{'loss': 0.0694, 'grad_norm': 1.85854172706604, 'learning_rate': 2e-06, 'rewards/chosen': -0.04568920284509659, 'rewards/rejected': -0.17289870977401733, 'rewards/accuracies': 0.7457812428474426, 'rewards/margins': 0.12720951437950134, 'logps/rejected': -3.92966890335083, 'logps/chosen': -3.8631131649017334, 'logits/rejected': -35.52617645263672, 'logits/chosen': -34.872108459472656, 'epoch': 0.68}\n{'loss': 0.07, 'grad_norm': 1.6580193042755127, 'learning_rate': 2e-06, 'rewards/chosen': -0.04543435946106911, 'rewards/rejected': -0.17326892912387848, 'rewards/accuracies': 0.7510937452316284, 'rewards/margins': 0.12783455848693848, 'logps/rejected': -3.9447617530822754, 'logps/chosen': -3.8444838523864746, 'logits/rejected': -35.70765686035156, 'logits/chosen': -35.033966064453125, 'epoch': 0.72}\n{'loss': 0.0691, 'grad_norm': 1.3828397989273071, 'learning_rate': 2e-06, 'rewards/chosen': -0.04518214240670204, 'rewards/rejected': -0.17924529314041138, 'rewards/accuracies': 0.75, 'rewards/margins': 0.13406315445899963, 'logps/rejected': -3.9670097827911377, 'logps/chosen': -3.865886926651001, 'logits/rejected': -35.370521545410156, 'logits/chosen': -34.67290496826172, 'epoch': 0.77}\n{'loss': 0.0698, 'grad_norm': 1.494152307510376, 'learning_rate': 2e-06, 'rewards/chosen': -0.0490574948489666, 'rewards/rejected': -0.1779099851846695, 'rewards/accuracies': 0.7456250190734863, 'rewards/margins': 0.1288524866104126, 'logps/rejected': -3.9549691677093506, 'logps/chosen': -3.870304822921753, 'logits/rejected': -35.482154846191406, 'logits/chosen': -34.711090087890625, 'epoch': 0.81}\n{'loss': 0.07, 'grad_norm': 1.69675874710083, 'learning_rate': 2e-06, 'rewards/chosen': -0.04899849742650986, 'rewards/rejected': -0.18198320269584656, 'rewards/accuracies': 0.7473437786102295, 'rewards/margins': 0.1329846978187561, 'logps/rejected': -3.9525811672210693, 'logps/chosen': -3.843651533126831, 'logits/rejected': -35.34395217895508, 'logits/chosen': -34.752159118652344, 'epoch': 0.86}\n{'loss': 0.0677, 'grad_norm': 1.5559459924697876, 'learning_rate': 2e-06, 'rewards/chosen': -0.044555921107530594, 'rewards/rejected': -0.1833389401435852, 'rewards/accuracies': 0.7520312666893005, 'rewards/margins': 0.1387830227613449, 'logps/rejected': -3.955204486846924, 'logps/chosen': -3.840881586074829, 'logits/rejected': -35.48201370239258, 'logits/chosen': -34.82188415527344, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [18:30<41:40,  1.07s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:22,  2.52it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.15it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.02it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.95it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.84it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:21,  1.80it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:16,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.81it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.81it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:04,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.78it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.73it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.75it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.06765463203191757, 'eval_runtime': 32.5099, 'eval_samples_per_second': 229.746, 'eval_steps_per_second': 1.815, 'eval_rewards/chosen': -0.046820588409900665, 'eval_rewards/rejected': -0.1848476082086563, 'eval_rewards/accuracies': 0.7560528516769409, 'eval_rewards/margins': 0.13802701234817505, 'eval_logps/rejected': -3.958303689956665, 'eval_logps/chosen': -3.8503754138946533, 'eval_logits/rejected': -35.3359260559082, 'eval_logits/chosen': -34.62904739379883, 'epoch': 0.9}\n 30%|███████████▋                           | 1000/3327 [19:03<41:40,  1.07s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.18it/s]\u001b[A\n{'loss': 0.0677, 'grad_norm': 1.4374321699142456, 'learning_rate': 2e-06, 'rewards/chosen': -0.047512784600257874, 'rewards/rejected': -0.1840711236000061, 'rewards/accuracies': 0.7559375166893005, 'rewards/margins': 0.13655833899974823, 'logps/rejected': -3.979609966278076, 'logps/chosen': -3.8506879806518555, 'logits/rejected': -35.47706604003906, 'logits/chosen': -34.868446350097656, 'epoch': 0.95}\n{'loss': 0.067, 'grad_norm': 1.5208635330200195, 'learning_rate': 2e-06, 'rewards/chosen': -0.04941873997449875, 'rewards/rejected': -0.19329766929149628, 'rewards/accuracies': 0.7604687213897705, 'rewards/margins': 0.14387893676757812, 'logps/rejected': -3.9650354385375977, 'logps/chosen': -3.867950201034546, 'logits/rejected': -35.392250061035156, 'logits/chosen': -34.699527740478516, 'epoch': 0.99}\n{'loss': 0.0621, 'grad_norm': 1.3613450527191162, 'learning_rate': 2e-06, 'rewards/chosen': -0.04092474281787872, 'rewards/rejected': -0.19844482839107513, 'rewards/accuracies': 0.7970982193946838, 'rewards/margins': 0.1575201004743576, 'logps/rejected': -3.9501659870147705, 'logps/chosen': -3.819113254547119, 'logits/rejected': -35.56356430053711, 'logits/chosen': -34.742347717285156, 'epoch': 1.04}\n{'loss': 0.06, 'grad_norm': 1.539085865020752, 'learning_rate': 2e-06, 'rewards/chosen': -0.03915068134665489, 'rewards/rejected': -0.20365844666957855, 'rewards/accuracies': 0.7928125262260437, 'rewards/margins': 0.16450777649879456, 'logps/rejected': -3.9874417781829834, 'logps/chosen': -3.851790189743042, 'logits/rejected': -35.30992126464844, 'logits/chosen': -34.6230583190918, 'epoch': 1.08}\n{'loss': 0.0599, 'grad_norm': 1.3466334342956543, 'learning_rate': 2e-06, 'rewards/chosen': -0.040138129144907, 'rewards/rejected': -0.203837051987648, 'rewards/accuracies': 0.797656238079071, 'rewards/margins': 0.1636989265680313, 'logps/rejected': -3.958134651184082, 'logps/chosen': -3.8442678451538086, 'logits/rejected': -35.75482940673828, 'logits/chosen': -35.09492492675781, 'epoch': 1.13}\n{'loss': 0.0589, 'grad_norm': 1.2844879627227783, 'learning_rate': 2e-06, 'rewards/chosen': -0.03727230429649353, 'rewards/rejected': -0.20452629029750824, 'rewards/accuracies': 0.8051562309265137, 'rewards/margins': 0.1672539860010147, 'logps/rejected': -3.969353675842285, 'logps/chosen': -3.845930814743042, 'logits/rejected': -35.635623931884766, 'logits/chosen': -34.88957595825195, 'epoch': 1.17}\n{'loss': 0.0595, 'grad_norm': 1.366991400718689, 'learning_rate': 2e-06, 'rewards/chosen': -0.04049040004611015, 'rewards/rejected': -0.21105094254016876, 'rewards/accuracies': 0.8023437261581421, 'rewards/margins': 0.1705605387687683, 'logps/rejected': -4.001157760620117, 'logps/chosen': -3.844935655593872, 'logits/rejected': -35.00996780395508, 'logits/chosen': -34.53099060058594, 'epoch': 1.22}\n{'loss': 0.06, 'grad_norm': 1.36131751537323, 'learning_rate': 2e-06, 'rewards/chosen': -0.0474361851811409, 'rewards/rejected': -0.21423865854740143, 'rewards/accuracies': 0.8075000047683716, 'rewards/margins': 0.16680248081684113, 'logps/rejected': -3.991084098815918, 'logps/chosen': -3.878927707672119, 'logits/rejected': -35.487388610839844, 'logits/chosen': -34.75218963623047, 'epoch': 1.26}\n{'loss': 0.0604, 'grad_norm': 1.4484694004058838, 'learning_rate': 2e-06, 'rewards/chosen': -0.0410839319229126, 'rewards/rejected': -0.2083778977394104, 'rewards/accuracies': 0.7978125214576721, 'rewards/margins': 0.1672939658164978, 'logps/rejected': -3.9794816970825195, 'logps/chosen': -3.843198537826538, 'logits/rejected': -35.55595397949219, 'logits/chosen': -34.91611862182617, 'epoch': 1.31}\n{'loss': 0.0611, 'grad_norm': 1.401158094406128, 'learning_rate': 2e-06, 'rewards/chosen': -0.04604373872280121, 'rewards/rejected': -0.20521919429302216, 'rewards/accuracies': 0.7957812547683716, 'rewards/margins': 0.15917542576789856, 'logps/rejected': -3.9710452556610107, 'logps/chosen': -3.8599188327789307, 'logits/rejected': -35.557735443115234, 'logits/chosen': -34.91331100463867, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [28:04<32:42,  1.07s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.66it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.80it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:20<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.80it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.79it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.06503205746412277, 'eval_runtime': 32.4568, 'eval_samples_per_second': 230.121, 'eval_steps_per_second': 1.818, 'eval_rewards/chosen': -0.04975238814949989, 'eval_rewards/rejected': -0.20001958310604095, 'eval_rewards/accuracies': 0.7684586644172668, 'eval_rewards/margins': 0.15026719868183136, 'eval_logps/rejected': -3.9677860736846924, 'eval_logps/chosen': -3.852207660675049, 'eval_logits/rejected': -35.6789665222168, 'eval_logits/chosen': -34.978614807128906, 'epoch': 1.35}\n 45%|█████████████████▌                     | 1500/3327 [28:36<32:42,  1.07s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.0595, 'grad_norm': 1.6179512739181519, 'learning_rate': 2e-06, 'rewards/chosen': -0.043284930288791656, 'rewards/rejected': -0.21020212769508362, 'rewards/accuracies': 0.8023437261581421, 'rewards/margins': 0.16691718995571136, 'logps/rejected': -3.962174654006958, 'logps/chosen': -3.8492746353149414, 'logits/rejected': -35.74693298339844, 'logits/chosen': -34.98487854003906, 'epoch': 1.4}\n{'loss': 0.0589, 'grad_norm': 1.4198938608169556, 'learning_rate': 2e-06, 'rewards/chosen': -0.0444728322327137, 'rewards/rejected': -0.2158592790365219, 'rewards/accuracies': 0.8096874952316284, 'rewards/margins': 0.1713864505290985, 'logps/rejected': -3.9823226928710938, 'logps/chosen': -3.834780693054199, 'logits/rejected': -36.11117172241211, 'logits/chosen': -35.33816909790039, 'epoch': 1.44}\n{'loss': 0.058, 'grad_norm': 1.416983723640442, 'learning_rate': 2e-06, 'rewards/chosen': -0.04786067083477974, 'rewards/rejected': -0.22527354955673218, 'rewards/accuracies': 0.8082812428474426, 'rewards/margins': 0.17741286754608154, 'logps/rejected': -3.987635612487793, 'logps/chosen': -3.8565921783447266, 'logits/rejected': -35.84079360961914, 'logits/chosen': -35.17389678955078, 'epoch': 1.49}\n{'loss': 0.0601, 'grad_norm': 1.4211933612823486, 'learning_rate': 2e-06, 'rewards/chosen': -0.04466400295495987, 'rewards/rejected': -0.2123541384935379, 'rewards/accuracies': 0.7975000143051147, 'rewards/margins': 0.16769014298915863, 'logps/rejected': -3.9761669635772705, 'logps/chosen': -3.8368115425109863, 'logits/rejected': -35.933841705322266, 'logits/chosen': -35.36683654785156, 'epoch': 1.53}\n{'loss': 0.0581, 'grad_norm': 1.4773558378219604, 'learning_rate': 2e-06, 'rewards/chosen': -0.044465240091085434, 'rewards/rejected': -0.21928821504116058, 'rewards/accuracies': 0.8034374713897705, 'rewards/margins': 0.17482295632362366, 'logps/rejected': -3.987149715423584, 'logps/chosen': -3.857541561126709, 'logits/rejected': -36.006866455078125, 'logits/chosen': -35.30914306640625, 'epoch': 1.58}\n{'loss': 0.0589, 'grad_norm': 1.3454506397247314, 'learning_rate': 2e-06, 'rewards/chosen': -0.04785976558923721, 'rewards/rejected': -0.22037506103515625, 'rewards/accuracies': 0.801562488079071, 'rewards/margins': 0.17251530289649963, 'logps/rejected': -3.9834156036376953, 'logps/chosen': -3.8753488063812256, 'logits/rejected': -36.009307861328125, 'logits/chosen': -35.33525085449219, 'epoch': 1.62}\n{'loss': 0.0592, 'grad_norm': 1.5248383283615112, 'learning_rate': 2e-06, 'rewards/chosen': -0.04519215598702431, 'rewards/rejected': -0.2168043553829193, 'rewards/accuracies': 0.7981250286102295, 'rewards/margins': 0.1716121882200241, 'logps/rejected': -3.9959867000579834, 'logps/chosen': -3.8451263904571533, 'logits/rejected': -35.96443176269531, 'logits/chosen': -35.226078033447266, 'epoch': 1.67}\n{'loss': 0.0584, 'grad_norm': 1.4679007530212402, 'learning_rate': 2e-06, 'rewards/chosen': -0.04454067349433899, 'rewards/rejected': -0.21893861889839172, 'rewards/accuracies': 0.8129687309265137, 'rewards/margins': 0.17439799010753632, 'logps/rejected': -3.9859752655029297, 'logps/chosen': -3.867962121963501, 'logits/rejected': -36.13100051879883, 'logits/chosen': -35.57581329345703, 'epoch': 1.71}\n{'loss': 0.0595, 'grad_norm': 1.2433242797851562, 'learning_rate': 2e-06, 'rewards/chosen': -0.044973984360694885, 'rewards/rejected': -0.21580764651298523, 'rewards/accuracies': 0.8012499809265137, 'rewards/margins': 0.17083366215229034, 'logps/rejected': -3.9814465045928955, 'logps/chosen': -3.8616464138031006, 'logits/rejected': -36.10189437866211, 'logits/chosen': -35.614013671875, 'epoch': 1.76}\n{'loss': 0.0579, 'grad_norm': 1.398208498954773, 'learning_rate': 2e-06, 'rewards/chosen': -0.042407404631376266, 'rewards/rejected': -0.2172294557094574, 'rewards/accuracies': 0.8109375238418579, 'rewards/margins': 0.17482203245162964, 'logps/rejected': -4.00747537612915, 'logps/chosen': -3.8492214679718018, 'logits/rejected': -36.2352180480957, 'logits/chosen': -35.49153137207031, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [37:36<23:55,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.62it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.56it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.95it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:31,  1.61it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:05<00:29,  1.67it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:28,  1.70it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:27,  1.74it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:26,  1.76it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.75it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:08<00:24,  1.77it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:24,  1.79it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:09<00:23,  1.80it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.80it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:10<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:14<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:15<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:19<00:13,  1.81it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:20<00:12,  1.80it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.78it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.79it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:24<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:25<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:29<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:30<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.06326546519994736, 'eval_runtime': 32.7214, 'eval_samples_per_second': 228.26, 'eval_steps_per_second': 1.803, 'eval_rewards/chosen': -0.05546846240758896, 'eval_rewards/rejected': -0.2165265530347824, 'eval_rewards/accuracies': 0.7799788117408752, 'eval_rewards/margins': 0.16105809807777405, 'eval_logps/rejected': -3.9781031608581543, 'eval_logps/chosen': -3.855780601501465, 'eval_logits/rejected': -36.303741455078125, 'eval_logits/chosen': -35.6228141784668, 'epoch': 1.8}\n 60%|███████████████████████▍               | 2000/3327 [38:08<23:55,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:32<00:00,  2.20it/s]\u001b[A\n{'loss': 0.0576, 'grad_norm': 1.535382628440857, 'learning_rate': 2e-06, 'rewards/chosen': -0.0444137305021286, 'rewards/rejected': -0.2244807779788971, 'rewards/accuracies': 0.8104687333106995, 'rewards/margins': 0.1800670474767685, 'logps/rejected': -3.9667410850524902, 'logps/chosen': -3.8500442504882812, 'logits/rejected': -36.696510314941406, 'logits/chosen': -35.99062728881836, 'epoch': 1.85}\n{'loss': 0.0575, 'grad_norm': 1.440394639968872, 'learning_rate': 2e-06, 'rewards/chosen': -0.041082121431827545, 'rewards/rejected': -0.21948346495628357, 'rewards/accuracies': 0.8084375262260437, 'rewards/margins': 0.17840135097503662, 'logps/rejected': -3.9971673488616943, 'logps/chosen': -3.859983444213867, 'logits/rejected': -36.354736328125, 'logits/chosen': -35.83673858642578, 'epoch': 1.89}\n{'loss': 0.0581, 'grad_norm': 1.4303748607635498, 'learning_rate': 2e-06, 'rewards/chosen': -0.046324919909238815, 'rewards/rejected': -0.22110728919506073, 'rewards/accuracies': 0.8059375286102295, 'rewards/margins': 0.17478235065937042, 'logps/rejected': -3.9851367473602295, 'logps/chosen': -3.8693485260009766, 'logits/rejected': -36.433326721191406, 'logits/chosen': -35.816856384277344, 'epoch': 1.94}\n{'loss': 0.0569, 'grad_norm': 1.4011847972869873, 'learning_rate': 2e-06, 'rewards/chosen': -0.04655933380126953, 'rewards/rejected': -0.22937291860580444, 'rewards/accuracies': 0.8100000023841858, 'rewards/margins': 0.1828135848045349, 'logps/rejected': -3.983980417251587, 'logps/chosen': -3.864001512527466, 'logits/rejected': -36.407554626464844, 'logits/chosen': -35.70759201049805, 'epoch': 1.98}\n{'loss': 0.0536, 'grad_norm': 1.3479939699172974, 'learning_rate': 2e-06, 'rewards/chosen': -0.03686713054776192, 'rewards/rejected': -0.2284078598022461, 'rewards/accuracies': 0.8379281759262085, 'rewards/margins': 0.19154071807861328, 'logps/rejected': -3.987978935241699, 'logps/chosen': -3.857877731323242, 'logits/rejected': -36.42262649536133, 'logits/chosen': -35.8117561340332, 'epoch': 2.03}\n{'loss': 0.0513, 'grad_norm': 1.1859525442123413, 'learning_rate': 2e-06, 'rewards/chosen': -0.03356646001338959, 'rewards/rejected': -0.2318330705165863, 'rewards/accuracies': 0.8442187309265137, 'rewards/margins': 0.1982666254043579, 'logps/rejected': -3.9731404781341553, 'logps/chosen': -3.8650176525115967, 'logits/rejected': -36.696128845214844, 'logits/chosen': -35.76093292236328, 'epoch': 2.07}\n{'loss': 0.0508, 'grad_norm': 1.3817964792251587, 'learning_rate': 2e-06, 'rewards/chosen': -0.0327448807656765, 'rewards/rejected': -0.2326391637325287, 'rewards/accuracies': 0.8540624976158142, 'rewards/margins': 0.1998942494392395, 'logps/rejected': -3.9841599464416504, 'logps/chosen': -3.8529415130615234, 'logits/rejected': -36.442474365234375, 'logits/chosen': -35.839454650878906, 'epoch': 2.12}\n{'loss': 0.051, 'grad_norm': 1.2375178337097168, 'learning_rate': 2e-06, 'rewards/chosen': -0.034675806760787964, 'rewards/rejected': -0.23371939361095428, 'rewards/accuracies': 0.8587499856948853, 'rewards/margins': 0.19904354214668274, 'logps/rejected': -3.9930496215820312, 'logps/chosen': -3.855398178100586, 'logits/rejected': -36.251041412353516, 'logits/chosen': -35.89360427856445, 'epoch': 2.16}\n{'loss': 0.0514, 'grad_norm': 1.376701831817627, 'learning_rate': 2e-06, 'rewards/chosen': -0.04221033677458763, 'rewards/rejected': -0.24116188287734985, 'rewards/accuracies': 0.8424999713897705, 'rewards/margins': 0.19895154237747192, 'logps/rejected': -4.00794792175293, 'logps/chosen': -3.846308946609497, 'logits/rejected': -36.69894027709961, 'logits/chosen': -36.20637893676758, 'epoch': 2.21}\n{'loss': 0.0497, 'grad_norm': 1.306963562965393, 'learning_rate': 2e-06, 'rewards/chosen': -0.03764617443084717, 'rewards/rejected': -0.240972101688385, 'rewards/accuracies': 0.8553125262260437, 'rewards/margins': 0.20332592725753784, 'logps/rejected': -4.022006034851074, 'logps/chosen': -3.865091562271118, 'logits/rejected': -36.917869567871094, 'logits/chosen': -36.1728401184082, 'epoch': 2.25}\n 75%|█████████████████████████████▎         | 2500/3327 [47:09<14:51,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.66it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.82it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.82it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.81it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.81it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.81it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.81it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.81it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.81it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.81it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.81it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.81it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:16,  1.81it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.81it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.81it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.78it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.82it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.77it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.06173091009259224, 'eval_runtime': 32.4758, 'eval_samples_per_second': 229.987, 'eval_steps_per_second': 1.817, 'eval_rewards/chosen': -0.057381827384233475, 'eval_rewards/rejected': -0.22689267992973328, 'eval_rewards/accuracies': 0.7846339344978333, 'eval_rewards/margins': 0.1695108562707901, 'eval_logps/rejected': -3.984581708908081, 'eval_logps/chosen': -3.856976270675659, 'eval_logits/rejected': -36.888057708740234, 'eval_logits/chosen': -36.221710205078125, 'epoch': 2.25}\n 75%|█████████████████████████████▎         | 2500/3327 [47:42<14:51,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.05, 'grad_norm': 1.3095026016235352, 'learning_rate': 2e-06, 'rewards/chosen': -0.041072506457567215, 'rewards/rejected': -0.24859052896499634, 'rewards/accuracies': 0.8540624976158142, 'rewards/margins': 0.20751801133155823, 'logps/rejected': -3.998591423034668, 'logps/chosen': -3.8631179332733154, 'logits/rejected': -37.00765609741211, 'logits/chosen': -36.18291473388672, 'epoch': 2.3}\n{'loss': 0.0498, 'grad_norm': 1.3526387214660645, 'learning_rate': 2e-06, 'rewards/chosen': -0.03314332664012909, 'rewards/rejected': -0.2391858845949173, 'rewards/accuracies': 0.8526562452316284, 'rewards/margins': 0.2060425728559494, 'logps/rejected': -4.014453887939453, 'logps/chosen': -3.8411028385162354, 'logits/rejected': -36.93864059448242, 'logits/chosen': -36.29494094848633, 'epoch': 2.34}\n{'loss': 0.0504, 'grad_norm': 1.2422692775726318, 'learning_rate': 2e-06, 'rewards/chosen': -0.04100622236728668, 'rewards/rejected': -0.2465793639421463, 'rewards/accuracies': 0.852343738079071, 'rewards/margins': 0.20557314157485962, 'logps/rejected': -4.0211100578308105, 'logps/chosen': -3.8522260189056396, 'logits/rejected': -36.858524322509766, 'logits/chosen': -36.279354095458984, 'epoch': 2.39}\n{'loss': 0.0513, 'grad_norm': 1.4625078439712524, 'learning_rate': 2e-06, 'rewards/chosen': -0.040775593370199203, 'rewards/rejected': -0.2451036125421524, 'rewards/accuracies': 0.8495312333106995, 'rewards/margins': 0.20432798564434052, 'logps/rejected': -3.985182523727417, 'logps/chosen': -3.831721782684326, 'logits/rejected': -37.108795166015625, 'logits/chosen': -36.5157585144043, 'epoch': 2.43}\n{'loss': 0.0508, 'grad_norm': 1.3695465326309204, 'learning_rate': 2e-06, 'rewards/chosen': -0.03991236165165901, 'rewards/rejected': -0.2450961321592331, 'rewards/accuracies': 0.83984375, 'rewards/margins': 0.20518377423286438, 'logps/rejected': -3.9919214248657227, 'logps/chosen': -3.8390860557556152, 'logits/rejected': -37.37680435180664, 'logits/chosen': -36.69559097290039, 'epoch': 2.48}\n{'loss': 0.0512, 'grad_norm': 1.3699097633361816, 'learning_rate': 2e-06, 'rewards/chosen': -0.04610048234462738, 'rewards/rejected': -0.24710628390312195, 'rewards/accuracies': 0.846875011920929, 'rewards/margins': 0.20100581645965576, 'logps/rejected': -3.9981369972229004, 'logps/chosen': -3.863826274871826, 'logits/rejected': -37.294708251953125, 'logits/chosen': -36.72954177856445, 'epoch': 2.52}\n{'loss': 0.051, 'grad_norm': 1.4043830633163452, 'learning_rate': 2e-06, 'rewards/chosen': -0.03798437491059303, 'rewards/rejected': -0.23951415717601776, 'rewards/accuracies': 0.8506249785423279, 'rewards/margins': 0.20152978599071503, 'logps/rejected': -4.003182411193848, 'logps/chosen': -3.849846839904785, 'logits/rejected': -37.233856201171875, 'logits/chosen': -36.74599075317383, 'epoch': 2.57}\n{'loss': 0.0488, 'grad_norm': 1.4854069948196411, 'learning_rate': 2e-06, 'rewards/chosen': -0.03810880333185196, 'rewards/rejected': -0.25052833557128906, 'rewards/accuracies': 0.8604687452316284, 'rewards/margins': 0.2124195545911789, 'logps/rejected': -3.9928836822509766, 'logps/chosen': -3.8460893630981445, 'logits/rejected': -37.343406677246094, 'logits/chosen': -36.59879684448242, 'epoch': 2.61}\n{'loss': 0.0498, 'grad_norm': 1.4310141801834106, 'learning_rate': 2e-06, 'rewards/chosen': -0.04022962599992752, 'rewards/rejected': -0.24720868468284607, 'rewards/accuracies': 0.8531249761581421, 'rewards/margins': 0.20697908103466034, 'logps/rejected': -4.007758617401123, 'logps/chosen': -3.854388952255249, 'logits/rejected': -37.37258529663086, 'logits/chosen': -36.63878631591797, 'epoch': 2.66}\n{'loss': 0.0492, 'grad_norm': 1.3919343948364258, 'learning_rate': 2e-06, 'rewards/chosen': -0.043164853006601334, 'rewards/rejected': -0.2539844810962677, 'rewards/accuracies': 0.8576562404632568, 'rewards/margins': 0.21081964671611786, 'logps/rejected': -4.019452095031738, 'logps/chosen': -3.845097064971924, 'logits/rejected': -37.32826232910156, 'logits/chosen': -36.7698860168457, 'epoch': 2.71}\n 90%|███████████████████████████████████▏   | 3000/3327 [56:41<05:52,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|█▍                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|██▏                                         | 3/59 [00:01<00:21,  2.57it/s]\u001b[A\n  7%|██▉                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|███▋                                        | 5/59 [00:02<00:26,  2.03it/s]\u001b[A\n 10%|████▍                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|█████▏                                      | 7/59 [00:03<00:27,  1.91it/s]\u001b[A\n 14%|█████▉                                      | 8/59 [00:03<00:27,  1.88it/s]\u001b[A\n 15%|██████▋                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|███████▎                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|████████                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|████████▋                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|█████████▍                                 | 13/59 [00:06<00:25,  1.82it/s]\u001b[A\n 24%|██████████▏                                | 14/59 [00:07<00:25,  1.79it/s]\u001b[A\n 25%|██████████▉                                | 15/59 [00:07<00:24,  1.79it/s]\u001b[A\n 27%|███████████▋                               | 16/59 [00:08<00:23,  1.80it/s]\u001b[A\n 29%|████████████▍                              | 17/59 [00:08<00:23,  1.80it/s]\u001b[A\n 31%|█████████████                              | 18/59 [00:09<00:22,  1.81it/s]\u001b[A\n 32%|█████████████▊                             | 19/59 [00:09<00:22,  1.81it/s]\u001b[A\n 34%|██████████████▌                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|███████████████▎                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|████████████████                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|████████████████▊                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|█████████████████▍                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|██████████████████▏                        | 25/59 [00:13<00:18,  1.81it/s]\u001b[A\n 44%|██████████████████▉                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|███████████████████▋                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|████████████████████▍                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|█████████████████████▏                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|█████████████████████▊                     | 30/59 [00:16<00:15,  1.82it/s]\u001b[A\n 53%|██████████████████████▌                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|███████████████████████▎                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|████████████████████████                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|████████████████████████▊                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|█████████████████████████▌                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|██████████████████████████▏                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|██████████████████████████▉                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|███████████████████████████▋               | 38/59 [00:20<00:11,  1.81it/s]\u001b[A\n 66%|████████████████████████████▍              | 39/59 [00:21<00:11,  1.81it/s]\u001b[A\n 68%|█████████████████████████████▏             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▉             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|██████████████████████████████▌            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|███████████████████████████████▎           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|████████████████████████████████           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|████████████████████████████████▊          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▌         | 46/59 [00:24<00:07,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▎        | 47/59 [00:25<00:06,  1.80it/s]\u001b[A\n 81%|██████████████████████████████████▉        | 48/59 [00:26<00:06,  1.78it/s]\u001b[A\n 83%|███████████████████████████████████▋       | 49/59 [00:26<00:05,  1.79it/s]\u001b[A\n 85%|████████████████████████████████████▍      | 50/59 [00:27<00:05,  1.80it/s]\u001b[A\n 86%|█████████████████████████████████████▏     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|█████████████████████████████████████▉     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 53/59 [00:28<00:03,  1.81it/s]\u001b[A\n 92%|███████████████████████████████████████▎   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|████████████████████████████████████████   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|████████████████████████████████████████▊  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|█████████████████████████████████████████▌ | 57/59 [00:31<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████▎| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.06043431535363197, 'eval_runtime': 32.4582, 'eval_samples_per_second': 230.111, 'eval_steps_per_second': 1.818, 'eval_rewards/chosen': -0.059976447373628616, 'eval_rewards/rejected': -0.23746336996555328, 'eval_rewards/accuracies': 0.7897775173187256, 'eval_rewards/margins': 0.17748692631721497, 'eval_logps/rejected': -3.9911885261535645, 'eval_logps/chosen': -3.858597993850708, 'eval_logits/rejected': -37.17308807373047, 'eval_logits/chosen': -36.51342010498047, 'epoch': 2.71}\n 90%|███████████████████████████████████▏   | 3000/3327 [57:13<05:52,  1.08s/it]\n100%|███████████████████████████████████████████| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n{'loss': 0.0502, 'grad_norm': 1.3748003244400024, 'learning_rate': 2e-06, 'rewards/chosen': -0.04139639809727669, 'rewards/rejected': -0.24887502193450928, 'rewards/accuracies': 0.8548437356948853, 'rewards/margins': 0.2074786126613617, 'logps/rejected': -4.001142978668213, 'logps/chosen': -3.8358325958251953, 'logits/rejected': -37.37096405029297, 'logits/chosen': -36.689971923828125, 'epoch': 2.75}\n{'loss': 0.0491, 'grad_norm': 1.4025894403457642, 'learning_rate': 2e-06, 'rewards/chosen': -0.039197131991386414, 'rewards/rejected': -0.25026455521583557, 'rewards/accuracies': 0.8617187738418579, 'rewards/margins': 0.21106740832328796, 'logps/rejected': -4.001216411590576, 'logps/chosen': -3.854015588760376, 'logits/rejected': -37.19834899902344, 'logits/chosen': -36.52671813964844, 'epoch': 2.8}\n{'loss': 0.0497, 'grad_norm': 1.3233213424682617, 'learning_rate': 2e-06, 'rewards/chosen': -0.03995976969599724, 'rewards/rejected': -0.25078284740448, 'rewards/accuracies': 0.8539062738418579, 'rewards/margins': 0.21082304418087006, 'logps/rejected': -4.0166015625, 'logps/chosen': -3.864067316055298, 'logits/rejected': -37.400978088378906, 'logits/chosen': -36.646507263183594, 'epoch': 2.84}\n{'loss': 0.0493, 'grad_norm': 1.3184090852737427, 'learning_rate': 2e-06, 'rewards/chosen': -0.038276251405477524, 'rewards/rejected': -0.250061959028244, 'rewards/accuracies': 0.854687511920929, 'rewards/margins': 0.2117857187986374, 'logps/rejected': -3.99338436126709, 'logps/chosen': -3.8629212379455566, 'logits/rejected': -37.295745849609375, 'logits/chosen': -36.55070877075195, 'epoch': 2.89}\n{'loss': 0.0502, 'grad_norm': 1.3611024618148804, 'learning_rate': 2e-06, 'rewards/chosen': -0.03911103680729866, 'rewards/rejected': -0.24726134538650513, 'rewards/accuracies': 0.8470312356948853, 'rewards/margins': 0.20815032720565796, 'logps/rejected': -3.9768643379211426, 'logps/chosen': -3.850853204727173, 'logits/rejected': -37.31431579589844, 'logits/chosen': -36.66755676269531, 'epoch': 2.93}\n{'loss': 0.0496, 'grad_norm': 1.4099407196044922, 'learning_rate': 2e-06, 'rewards/chosen': -0.039908185601234436, 'rewards/rejected': -0.24924665689468384, 'rewards/accuracies': 0.8542187213897705, 'rewards/margins': 0.2093384861946106, 'logps/rejected': -4.012207508087158, 'logps/chosen': -3.851879596710205, 'logits/rejected': -37.50889205932617, 'logits/chosen': -36.95817565917969, 'epoch': 2.98}\n{'train_runtime': 3804.7982, 'train_samples_per_second': 111.886, 'train_steps_per_second': 0.874, 'train_loss': 0.06135602913929028, 'epoch': 3.0}\n100%|█████████████████████████████████████| 3327/3327 [1:03:07<00:00,  1.14s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python ppo.py --exp_name=eval --eval_model=./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-3327\n!python ppo.py --exp_name=eval --eval_model=./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-2218\n!python ppo.py --exp_name=eval --eval_model=./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-1109","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:31:32.106571Z","iopub.execute_input":"2024-05-26T03:31:32.106998Z","iopub.status.idle":"2024-05-26T03:46:00.419352Z","shell.execute_reply.started":"2024-05-26T03:31:32.106964Z","shell.execute_reply":"2024-05-26T03:46:00.418112Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"2024-05-26 03:31:38.421606: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 03:31:38.421680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 03:31:38.423041: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-3327', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.03.31'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-3327\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_033151-zn8lr22t\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.03.31\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/zn8lr22t\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:26<03:33, 26.73s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:53<03:05, 26.47s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:19<02:38, 26.43s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:45<02:12, 26.48s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:12<01:45, 26.48s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:38<01:19, 26.43s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:05<00:52, 26.49s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:31<00:26, 26.48s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [03:58<00:00, 26.49s/it]\nmean test reward 0.7784877918286384 +/- 0.008535654607992176 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9983283877372742 from 0.00922983093187213\nmean KL -0.2180928284392899 +/- 0.04308438666139048 full 1.6405885994770668 +/- 0.01386613161735173\nmedian KL -0.004783987998962402 full 1.515143096446991\n2024-05-26 03:36:24.013090: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 03:36:24.013147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 03:36:24.014596: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-2218', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.03.36'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-2218\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_033637-xfev1ihm\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.03.36\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/xfev1ihm\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:27<03:38, 27.31s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:54<03:10, 27.22s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:21<02:43, 27.24s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:49<02:16, 27.26s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:16<01:49, 27.29s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:43<01:22, 27.36s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:11<00:54, 27.35s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:38<00:27, 27.38s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [04:05<00:00, 27.33s/it]\nmean test reward 0.765375039290676 +/- 0.008710274242926851 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9982102513313293 from 0.00922983093187213\nmean KL -0.04749138478655368 +/- 0.03815292900254592 full 1.4514831021014187 +/- 0.013627293001758087\nmedian KL 0.10297183692455292 full 1.3156929016113281\n2024-05-26 03:41:18.101947: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 03:41:18.102009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 03:41:18.103467: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPPOConfig: PPOConfig(exp_name='eval', dry_run=False, eval_model='./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-1109', seed=0, log_with='wandb', task_name=None, model_name='lvwerra/gpt2-imdb', query_dataset='imdb', reward_model='sentiment-analysis:siebert/sentiment-roberta-large-english', remove_unused_columns=True, tracker_kwargs={'wandb': {'name': 'eval-2024.05.26.03.41'}}, accelerator_kwargs={}, project_kwargs={}, tracker_project_name='cs234', push_to_hub_if_best_kwargs={}, steps=20000, learning_rate=1.41e-05, adap_kl_ctrl=False, init_kl_coef=0.2, kl_penalty='kl', target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=0.1, batch_size=256, forward_batch_size=None, mini_batch_size=256, gradient_accumulation_steps=1, world_size=None, ppo_epochs=4, max_grad_norm=None, optimize_cuda_cache=None, optimize_device_cache=False, early_stopping=False, target_kl=1, compare_steps=1, ratio_threshold=10.0, use_score_scaling=False, use_score_norm=False, score_clip=None, whiten_rewards=False, is_encoder_decoder=None, is_peft_model=None, backward_batch_size=256, global_backward_batch_size=None, global_batch_size=None)\nload ref model lvwerra/gpt2-imdb\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nload train model ./test_ipo_1_6_lr2e_6-2024.05.26.02.27/checkpoint-1109\n****** hi ******\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240526_034131-jqp29ldv\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meval-2024.05.26.03.41\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/cs234/runs/jqp29ldv\u001b[0m\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 11%|█████                                        | 1/9 [00:27<03:36, 27.06s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 22%|██████████                                   | 2/9 [00:53<03:06, 26.67s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 33%|███████████████                              | 3/9 [01:20<02:40, 26.72s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 44%|████████████████████                         | 4/9 [01:47<02:13, 26.77s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 56%|█████████████████████████                    | 5/9 [02:13<01:46, 26.71s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/kaggle/working/cs234-project/ppo.py\", line 238, in <module>\n    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py\", line 156, in __call__\n    result = super().__call__(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\n****** hi yo scores ******\n****** hi yo scores ******\n 67%|██████████████████████████████               | 6/9 [02:40<01:20, 26.70s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 78%|███████████████████████████████████          | 7/9 [03:06<00:53, 26.68s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n 89%|████████████████████████████████████████     | 8/9 [03:33<00:26, 26.67s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n****** hi yo scores ******\n****** hi yo scores ******\n100%|█████████████████████████████████████████████| 9/9 [04:00<00:00, 26.71s/it]\nmean test reward 0.7376512259009158 +/- 0.009044502174408825 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9979890584945679 from 0.00922983093187213\nmean KL 0.3941970775971034 +/- 0.034605531152989755 full 1.2829640487131353 +/- 0.013112264071765842\nmedian KL 0.5194036662578583 full 1.15664142370224\n","output_type":"stream"}]}]}