{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install aiohttp -y\n!git clone https://github.com/mattjhayes3/cs234-project.git\n%cd /kaggle/working/cs234-project\n!git pull --rebase\n!pip install wandb\nimport wandb\n\nwandb.login(key=\"KEY\")\n# wandb.init()\n\nfrom huggingface_hub import notebook_login,login\n\n# notebook_login(\"KEY\")\nlogin(\"KEY\")\n\n# !gdown --id 1TTg8s_dj60EKl4No2unSvYmMyMopPVJ6\n# !gdown --id 1Z7HvAokBQu65jew4ou2DjOYRi23OrJdr\n!mkdir results\n!pip install datasets>=1.17.0 torch>=1.4.0 tqdm transformers accelerate peft>=0.3.0 tyro>=0.5.7\n!pip install git+https://github.com/mattjhayes3/trl.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T01:11:35.710730Z","iopub.execute_input":"2024-06-10T01:11:35.710990Z","iopub.status.idle":"2024-06-10T01:14:16.709142Z","shell.execute_reply.started":"2024-06-10T01:11:35.710965Z","shell.execute_reply":"2024-06-10T01:14:16.707864Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - aiohttp\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    aiohttp-3.9.5              |  py310h2372a71_0         682 KB  conda-forge\n    openssl-3.3.1              |       h4ab18f5_0         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.4 MB\n\nThe following packages will be UPDATED:\n\n  aiohttp                             3.9.1-py310h2372a71_0 --> 3.9.5-py310h2372a71_0 \n  openssl                                  3.3.0-h4ab18f5_3 --> 3.3.1-h4ab18f5_0 \n\n\n\nDownloading and Extracting Packages:\nopenssl-3.3.1        | 2.8 MB    |                                       |   0% \nopenssl-3.3.1        | 2.8 MB    | 8                                     |   2% \u001b[A\naiohttp-3.9.5        | 682 KB    | #######8                              |  21% \u001b[A\naiohttp-3.9.5        | 682 KB    | ##################################### | 100% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nCloning into 'cs234-project'...\nremote: Enumerating objects: 325, done.\u001b[K\nremote: Counting objects: 100% (105/105), done.\u001b[K\nremote: Compressing objects: 100% (69/69), done.\u001b[K\nremote: Total 325 (delta 63), reused 77 (delta 36), pack-reused 220\u001b[K\nReceiving objects: 100% (325/325), 66.93 MiB | 22.31 MiB/s, done.\nResolving deltas: 100% (170/170), done.\nUpdating files: 100% (129/129), done.\n/kaggle/working/cs234-project\nAlready up to date.\nCurrent branch main is up to date.\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.3.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\nCollecting git+https://github.com/mattjhayes3/trl.git\n  Cloning https://github.com/mattjhayes3/trl.git to /tmp/pip-req-build-zizsl0_a\n  Running command git clone --filter=blob:none --quiet https://github.com/mattjhayes3/trl.git /tmp/pip-req-build-zizsl0_a\n  Resolved https://github.com/mattjhayes3/trl.git to commit fce91ab1b2401a45a767d7ca6eeb940790cdd954\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (4.41.2)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (0.30.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (2.19.2)\nRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.7.dev0) (0.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.7.dev0) (2024.3.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.23.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.7.dev0) (4.66.4)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (13.7.0)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.7.dev0) (1.7.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.8.7.dev0) (5.9.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.7.dev0) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (1.9.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.7.dev0) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.8.7.dev0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.7.dev0) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.8.7.dev0) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.7.dev0) (2023.4)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.8.7.dev0) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.7.dev0) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.7.dev0) (1.16.0)\nBuilding wheels for collected packages: trl\n  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for trl: filename=trl-0.8.7.dev0-py3-none-any.whl size=209807 sha256=be9c104fdfa9dbffbf7dce6266f5e6f62ba5966dabad8ec85dc2da8dbda76f09\n  Stored in directory: /tmp/pip-ephem-wheel-cache-v0e8siw_/wheels/b5/f5/74/f982e27bdb1c23b205f8bfcaaed174cf3d2c06bd1a5f5926cc\nSuccessfully built trl\nInstalling collected packages: trl\nSuccessfully installed trl-0.8.7.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"!python dpo.py  --output_dir=test_dpo_0_1_lr2e_6  --beta=0.1 --dataset_name=./pref_pairs_16_token_tokenized_split     --model_name_or_path=lvwerra/gpt2-imdb     --per_device_train_batch_size 128 --per_device_eval_batch_size 128    --learning_rate 2e-6     --gradient_accumulation_steps 1  --warmup_steps 150     --report_to wandb     --logging_first_step --logging_steps 10   --no_remove_unused_columns --save_total_limit=4 --load_best_model_at_end=True --evaluation_strategy='epoch' --lr_scheduler_type=constant_with_warmup --save_strategy='epoch'","metadata":{"execution":{"iopub.status.busy":"2024-06-10T01:35:58.301041Z","iopub.execute_input":"2024-06-10T01:35:58.301825Z","iopub.status.idle":"2024-06-10T02:59:12.527652Z","shell.execute_reply.started":"2024-06-10T01:35:58.301788Z","shell.execute_reply":"2024-06-10T02:59:12.526491Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"2024-06-10 01:36:04.225823: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-10 01:36:04.225894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-10 01:36:04.227357: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nLoad model  lvwerra/gpt2-imdb\nLoad ref model  lvwerra/gpt2-imdb\nds len 149370\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjh388\u001b[0m (\u001b[33mmhayes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.1 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/cs234-project/wandb/run-20240610_013610-nr8umk39\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtest_dpo_0_1_lr2e_6\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhayes/huggingface/runs/nr8umk39\u001b[0m\n  0%|                                                  | 0/3327 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n{'loss': 0.6931, 'grad_norm': 2.206209421157837, 'learning_rate': 1.3333333333333334e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -58.112220764160156, 'logps/chosen': -60.65317153930664, 'logits/rejected': -39.777442932128906, 'logits/chosen': -37.3552131652832, 'epoch': 0.0}\n{'loss': 0.6931, 'grad_norm': 2.2196736335754395, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 2.6009378416347317e-05, 'rewards/rejected': -1.7498754459666088e-05, 'rewards/accuracies': 0.5607638955116272, 'rewards/margins': 4.3508131057024e-05, 'logps/rejected': -60.52594757080078, 'logps/chosen': -60.67599868774414, 'logits/rejected': -37.398189544677734, 'logits/chosen': -36.34072494506836, 'epoch': 0.01}\n{'loss': 0.6929, 'grad_norm': 2.19868803024292, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': 0.00019831587269436568, 'rewards/rejected': -0.00023504093405790627, 'rewards/accuracies': 0.69921875, 'rewards/margins': 0.0004333568213041872, 'logps/rejected': -61.05390167236328, 'logps/chosen': -60.11763381958008, 'logits/rejected': -37.53373718261719, 'logits/chosen': -36.52681350708008, 'epoch': 0.02}\n{'loss': 0.6926, 'grad_norm': 2.414876699447632, 'learning_rate': 4e-07, 'rewards/chosen': 0.000515650084707886, 'rewards/rejected': -0.0005247484659776092, 'rewards/accuracies': 0.659375011920929, 'rewards/margins': 0.0010403984924778342, 'logps/rejected': -60.564231872558594, 'logps/chosen': -60.30865478515625, 'logits/rejected': -37.393863677978516, 'logits/chosen': -36.647674560546875, 'epoch': 0.03}\n{'loss': 0.6921, 'grad_norm': 2.3617773056030273, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.0010985084809362888, 'rewards/rejected': -0.0011015095515176654, 'rewards/accuracies': 0.671875, 'rewards/margins': 0.002200018148869276, 'logps/rejected': -60.578163146972656, 'logps/chosen': -60.529930114746094, 'logits/rejected': -37.4261589050293, 'logits/chosen': -36.589637756347656, 'epoch': 0.04}\n{'loss': 0.6911, 'grad_norm': 2.3546717166900635, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': 0.001722553395666182, 'rewards/rejected': -0.002400221535935998, 'rewards/accuracies': 0.7046874761581421, 'rewards/margins': 0.004122775048017502, 'logps/rejected': -61.045196533203125, 'logps/chosen': -60.83582305908203, 'logits/rejected': -37.71697235107422, 'logits/chosen': -36.47663879394531, 'epoch': 0.05}\n{'loss': 0.6901, 'grad_norm': 2.210031270980835, 'learning_rate': 8e-07, 'rewards/chosen': 0.0026631024666130543, 'rewards/rejected': -0.00356738711707294, 'rewards/accuracies': 0.6968749761581421, 'rewards/margins': 0.0062304893508553505, 'logps/rejected': -60.686004638671875, 'logps/chosen': -60.535728454589844, 'logits/rejected': -37.1398811340332, 'logits/chosen': -36.17345428466797, 'epoch': 0.05}\n{'loss': 0.6893, 'grad_norm': 2.2465147972106934, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': 0.0028709452599287033, 'rewards/rejected': -0.004819322843104601, 'rewards/accuracies': 0.671875, 'rewards/margins': 0.0076902685686945915, 'logps/rejected': -59.82257843017578, 'logps/chosen': -60.28399658203125, 'logits/rejected': -37.407413482666016, 'logits/chosen': -36.58540344238281, 'epoch': 0.06}\n{'loss': 0.6873, 'grad_norm': 2.2527647018432617, 'learning_rate': 1.0666666666666667e-06, 'rewards/chosen': 0.003839795710518956, 'rewards/rejected': -0.007916226983070374, 'rewards/accuracies': 0.7046874761581421, 'rewards/margins': 0.011756022460758686, 'logps/rejected': -60.656463623046875, 'logps/chosen': -59.98198699951172, 'logits/rejected': -37.51721954345703, 'logits/chosen': -36.73139190673828, 'epoch': 0.07}\n{'loss': 0.686, 'grad_norm': 2.218076705932617, 'learning_rate': 1.2e-06, 'rewards/chosen': 0.0054138158448040485, 'rewards/rejected': -0.009239105507731438, 'rewards/accuracies': 0.6781250238418579, 'rewards/margins': 0.014652922749519348, 'logps/rejected': -60.53639602661133, 'logps/chosen': -59.5637092590332, 'logits/rejected': -37.00273132324219, 'logits/chosen': -36.201419830322266, 'epoch': 0.08}\n{'loss': 0.6841, 'grad_norm': 2.3773138523101807, 'learning_rate': 1.3333333333333332e-06, 'rewards/chosen': 0.005364722106605768, 'rewards/rejected': -0.013166944496333599, 'rewards/accuracies': 0.6859375238418579, 'rewards/margins': 0.018531667068600655, 'logps/rejected': -60.6842155456543, 'logps/chosen': -60.112762451171875, 'logits/rejected': -36.77186965942383, 'logits/chosen': -36.37771987915039, 'epoch': 0.09}\n{'loss': 0.682, 'grad_norm': 2.2305641174316406, 'learning_rate': 1.4666666666666665e-06, 'rewards/chosen': 0.0043454417027533054, 'rewards/rejected': -0.01869150623679161, 'rewards/accuracies': 0.696093738079071, 'rewards/margins': 0.023036949336528778, 'logps/rejected': -61.30353546142578, 'logps/chosen': -59.916961669921875, 'logits/rejected': -36.904476165771484, 'logits/chosen': -36.514923095703125, 'epoch': 0.1}\n{'loss': 0.6802, 'grad_norm': 2.1293323040008545, 'learning_rate': 1.6e-06, 'rewards/chosen': 0.005659875459969044, 'rewards/rejected': -0.02110535278916359, 'rewards/accuracies': 0.686718761920929, 'rewards/margins': 0.026765231043100357, 'logps/rejected': -61.51784133911133, 'logps/chosen': -60.52507781982422, 'logits/rejected': -36.5270881652832, 'logits/chosen': -35.330074310302734, 'epoch': 0.11}\n{'loss': 0.6791, 'grad_norm': 2.2294347286224365, 'learning_rate': 1.7333333333333334e-06, 'rewards/chosen': 0.0028917542658746243, 'rewards/rejected': -0.026376482099294662, 'rewards/accuracies': 0.6703125238418579, 'rewards/margins': 0.029268234968185425, 'logps/rejected': -60.97468948364258, 'logps/chosen': -59.945648193359375, 'logits/rejected': -37.04438018798828, 'logits/chosen': -36.18921661376953, 'epoch': 0.12}\n{'loss': 0.6744, 'grad_norm': 2.179736852645874, 'learning_rate': 1.8666666666666667e-06, 'rewards/chosen': 0.0033394843339920044, 'rewards/rejected': -0.03575098142027855, 'rewards/accuracies': 0.71484375, 'rewards/margins': 0.03909046947956085, 'logps/rejected': -61.376426696777344, 'logps/chosen': -59.658912658691406, 'logits/rejected': -36.97881317138672, 'logits/chosen': -36.01850509643555, 'epoch': 0.13}\n{'loss': 0.6729, 'grad_norm': 2.2187156677246094, 'learning_rate': 2e-06, 'rewards/chosen': 0.0012664615642279387, 'rewards/rejected': -0.04131290689110756, 'rewards/accuracies': 0.6968749761581421, 'rewards/margins': 0.04257936403155327, 'logps/rejected': -61.5006103515625, 'logps/chosen': -59.96140670776367, 'logits/rejected': -36.87626266479492, 'logits/chosen': -35.70714569091797, 'epoch': 0.14}\n{'loss': 0.6705, 'grad_norm': 2.3344404697418213, 'learning_rate': 2e-06, 'rewards/chosen': -0.0021140328608453274, 'rewards/rejected': -0.050311435014009476, 'rewards/accuracies': 0.692187488079071, 'rewards/margins': 0.04819740355014801, 'logps/rejected': -60.727516174316406, 'logps/chosen': -60.1165885925293, 'logits/rejected': -36.97166442871094, 'logits/chosen': -36.2152099609375, 'epoch': 0.14}\n{'loss': 0.6676, 'grad_norm': 2.2636308670043945, 'learning_rate': 2e-06, 'rewards/chosen': -0.005922203883528709, 'rewards/rejected': -0.06061827018857002, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.05469605326652527, 'logps/rejected': -60.98754119873047, 'logps/chosen': -60.563987731933594, 'logits/rejected': -36.899627685546875, 'logits/chosen': -35.803043365478516, 'epoch': 0.15}\n{'loss': 0.6639, 'grad_norm': 2.3018431663513184, 'learning_rate': 2e-06, 'rewards/chosen': -0.012509092688560486, 'rewards/rejected': -0.0757201686501503, 'rewards/accuracies': 0.686718761920929, 'rewards/margins': 0.06321107596158981, 'logps/rejected': -60.60137939453125, 'logps/chosen': -60.39003372192383, 'logits/rejected': -36.62339401245117, 'logits/chosen': -36.092079162597656, 'epoch': 0.16}\n{'loss': 0.6602, 'grad_norm': 2.2434937953948975, 'learning_rate': 2e-06, 'rewards/chosen': -0.012844149954617023, 'rewards/rejected': -0.08461697399616241, 'rewards/accuracies': 0.7015625238418579, 'rewards/margins': 0.07177283614873886, 'logps/rejected': -61.22901153564453, 'logps/chosen': -60.008575439453125, 'logits/rejected': -37.033592224121094, 'logits/chosen': -35.824195861816406, 'epoch': 0.17}\n{'loss': 0.6583, 'grad_norm': 2.2233083248138428, 'learning_rate': 2e-06, 'rewards/chosen': -0.023494847118854523, 'rewards/rejected': -0.10032176971435547, 'rewards/accuracies': 0.6898437738418579, 'rewards/margins': 0.07682692259550095, 'logps/rejected': -61.138824462890625, 'logps/chosen': -60.44190216064453, 'logits/rejected': -36.32917022705078, 'logits/chosen': -35.806617736816406, 'epoch': 0.18}\n{'loss': 0.6553, 'grad_norm': 2.1471047401428223, 'learning_rate': 2e-06, 'rewards/chosen': -0.029337147250771523, 'rewards/rejected': -0.11292199790477753, 'rewards/accuracies': 0.70703125, 'rewards/margins': 0.08358485251665115, 'logps/rejected': -61.391387939453125, 'logps/chosen': -60.72154998779297, 'logits/rejected': -36.65986251831055, 'logits/chosen': -36.23186492919922, 'epoch': 0.19}\n{'loss': 0.6531, 'grad_norm': 2.216031789779663, 'learning_rate': 2e-06, 'rewards/chosen': -0.038587529212236404, 'rewards/rejected': -0.1281680315732956, 'rewards/accuracies': 0.688281238079071, 'rewards/margins': 0.08958049863576889, 'logps/rejected': -61.34777069091797, 'logps/chosen': -60.89554977416992, 'logits/rejected': -36.24713897705078, 'logits/chosen': -35.66328048706055, 'epoch': 0.2}\n{'loss': 0.6499, 'grad_norm': 2.1901543140411377, 'learning_rate': 2e-06, 'rewards/chosen': -0.045421112328767776, 'rewards/rejected': -0.14259123802185059, 'rewards/accuracies': 0.690625011920929, 'rewards/margins': 0.09717012941837311, 'logps/rejected': -61.4637565612793, 'logps/chosen': -59.81934356689453, 'logits/rejected': -36.978206634521484, 'logits/chosen': -35.91460418701172, 'epoch': 0.21}\n{'loss': 0.645, 'grad_norm': 2.2636849880218506, 'learning_rate': 2e-06, 'rewards/chosen': -0.05361473560333252, 'rewards/rejected': -0.16255870461463928, 'rewards/accuracies': 0.702343761920929, 'rewards/margins': 0.10894395411014557, 'logps/rejected': -62.2420654296875, 'logps/chosen': -60.078765869140625, 'logits/rejected': -36.523895263671875, 'logits/chosen': -35.85840606689453, 'epoch': 0.22}\n{'loss': 0.6497, 'grad_norm': 2.3042101860046387, 'learning_rate': 2e-06, 'rewards/chosen': -0.07625430822372437, 'rewards/rejected': -0.177012637257576, 'rewards/accuracies': 0.6890624761581421, 'rewards/margins': 0.10075831413269043, 'logps/rejected': -62.3745002746582, 'logps/chosen': -61.03203582763672, 'logits/rejected': -36.58848571777344, 'logits/chosen': -35.77299118041992, 'epoch': 0.23}\n{'loss': 0.6429, 'grad_norm': 2.1404876708984375, 'learning_rate': 2e-06, 'rewards/chosen': -0.07813111692667007, 'rewards/rejected': -0.19406245648860931, 'rewards/accuracies': 0.6898437738418579, 'rewards/margins': 0.11593134701251984, 'logps/rejected': -62.74753952026367, 'logps/chosen': -60.320648193359375, 'logits/rejected': -36.547584533691406, 'logits/chosen': -36.13105010986328, 'epoch': 0.23}\n{'loss': 0.6466, 'grad_norm': 2.1084535121917725, 'learning_rate': 2e-06, 'rewards/chosen': -0.09145228564739227, 'rewards/rejected': -0.20231112837791443, 'rewards/accuracies': 0.6851562261581421, 'rewards/margins': 0.11085883527994156, 'logps/rejected': -62.91184616088867, 'logps/chosen': -60.6464958190918, 'logits/rejected': -36.55632781982422, 'logits/chosen': -36.093074798583984, 'epoch': 0.24}\n{'loss': 0.6378, 'grad_norm': 2.2305424213409424, 'learning_rate': 2e-06, 'rewards/chosen': -0.09833109378814697, 'rewards/rejected': -0.23021042346954346, 'rewards/accuracies': 0.694531261920929, 'rewards/margins': 0.13187934458255768, 'logps/rejected': -62.84038162231445, 'logps/chosen': -61.327178955078125, 'logits/rejected': -35.869041442871094, 'logits/chosen': -35.55956268310547, 'epoch': 0.25}\n{'loss': 0.6402, 'grad_norm': 2.1821765899658203, 'learning_rate': 2e-06, 'rewards/chosen': -0.1190928965806961, 'rewards/rejected': -0.2455616295337677, 'rewards/accuracies': 0.68359375, 'rewards/margins': 0.126468688249588, 'logps/rejected': -63.247901916503906, 'logps/chosen': -61.59287643432617, 'logits/rejected': -36.13456344604492, 'logits/chosen': -35.59310531616211, 'epoch': 0.26}\n{'loss': 0.6314, 'grad_norm': 2.211068630218506, 'learning_rate': 2e-06, 'rewards/chosen': -0.12607000768184662, 'rewards/rejected': -0.2747803032398224, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.14871031045913696, 'logps/rejected': -62.6090202331543, 'logps/chosen': -61.4512825012207, 'logits/rejected': -36.002098083496094, 'logits/chosen': -35.75731658935547, 'epoch': 0.27}\n{'loss': 0.6363, 'grad_norm': 2.1455960273742676, 'learning_rate': 2e-06, 'rewards/chosen': -0.14429016411304474, 'rewards/rejected': -0.28474053740501404, 'rewards/accuracies': 0.680468738079071, 'rewards/margins': 0.14045032858848572, 'logps/rejected': -63.74934005737305, 'logps/chosen': -61.40929412841797, 'logits/rejected': -35.9919548034668, 'logits/chosen': -35.304847717285156, 'epoch': 0.28}\n{'loss': 0.6278, 'grad_norm': 2.1115095615386963, 'learning_rate': 2e-06, 'rewards/chosen': -0.15828271210193634, 'rewards/rejected': -0.3220629394054413, 'rewards/accuracies': 0.686718761920929, 'rewards/margins': 0.16378021240234375, 'logps/rejected': -63.14879608154297, 'logps/chosen': -60.60029220581055, 'logits/rejected': -36.163902282714844, 'logits/chosen': -35.55170440673828, 'epoch': 0.29}\n{'loss': 0.6292, 'grad_norm': 2.1339120864868164, 'learning_rate': 2e-06, 'rewards/chosen': -0.16538068652153015, 'rewards/rejected': -0.3269374370574951, 'rewards/accuracies': 0.6820312738418579, 'rewards/margins': 0.16155676543712616, 'logps/rejected': -63.46875, 'logps/chosen': -61.39970016479492, 'logits/rejected': -36.020694732666016, 'logits/chosen': -35.43324661254883, 'epoch': 0.3}\n{'loss': 0.6166, 'grad_norm': 1.9387974739074707, 'learning_rate': 2e-06, 'rewards/chosen': -0.17238442599773407, 'rewards/rejected': -0.36175501346588135, 'rewards/accuracies': 0.71484375, 'rewards/margins': 0.18937057256698608, 'logps/rejected': -64.0859375, 'logps/chosen': -61.74064254760742, 'logits/rejected': -36.20901870727539, 'logits/chosen': -35.672428131103516, 'epoch': 0.31}\n{'loss': 0.6255, 'grad_norm': 2.136577844619751, 'learning_rate': 2e-06, 'rewards/chosen': -0.20717278122901917, 'rewards/rejected': -0.38016265630722046, 'rewards/accuracies': 0.6898437738418579, 'rewards/margins': 0.1729898899793625, 'logps/rejected': -64.56395721435547, 'logps/chosen': -62.70076370239258, 'logits/rejected': -35.904579162597656, 'logits/chosen': -35.492942810058594, 'epoch': 0.32}\n{'loss': 0.6195, 'grad_norm': 1.9692935943603516, 'learning_rate': 2e-06, 'rewards/chosen': -0.2078927457332611, 'rewards/rejected': -0.3974739611148834, 'rewards/accuracies': 0.69921875, 'rewards/margins': 0.18958118557929993, 'logps/rejected': -63.997711181640625, 'logps/chosen': -61.662208557128906, 'logits/rejected': -35.939178466796875, 'logits/chosen': -35.2725715637207, 'epoch': 0.32}\n{'loss': 0.6171, 'grad_norm': 2.103527069091797, 'learning_rate': 2e-06, 'rewards/chosen': -0.23023228347301483, 'rewards/rejected': -0.4243840277194977, 'rewards/accuracies': 0.69140625, 'rewards/margins': 0.19415172934532166, 'logps/rejected': -64.93733978271484, 'logps/chosen': -63.01856231689453, 'logits/rejected': -35.95119857788086, 'logits/chosen': -35.34547805786133, 'epoch': 0.33}\n{'loss': 0.6123, 'grad_norm': 2.17160701751709, 'learning_rate': 2e-06, 'rewards/chosen': -0.24552182853221893, 'rewards/rejected': -0.45863962173461914, 'rewards/accuracies': 0.703906238079071, 'rewards/margins': 0.2131178379058838, 'logps/rejected': -64.81736755371094, 'logps/chosen': -62.68998336791992, 'logits/rejected': -36.67001724243164, 'logits/chosen': -35.44995880126953, 'epoch': 0.34}\n{'loss': 0.617, 'grad_norm': 2.148552179336548, 'learning_rate': 2e-06, 'rewards/chosen': -0.2643497884273529, 'rewards/rejected': -0.468984991312027, 'rewards/accuracies': 0.6859375238418579, 'rewards/margins': 0.20463521778583527, 'logps/rejected': -65.28300476074219, 'logps/chosen': -62.80299758911133, 'logits/rejected': -35.644561767578125, 'logits/chosen': -35.623191833496094, 'epoch': 0.35}\n{'loss': 0.6147, 'grad_norm': 1.9883545637130737, 'learning_rate': 2e-06, 'rewards/chosen': -0.29078325629234314, 'rewards/rejected': -0.5030766725540161, 'rewards/accuracies': 0.6976562738418579, 'rewards/margins': 0.21229343116283417, 'logps/rejected': -65.29874420166016, 'logps/chosen': -63.36078643798828, 'logits/rejected': -35.51448440551758, 'logits/chosen': -35.05878829956055, 'epoch': 0.36}\n{'loss': 0.6104, 'grad_norm': 2.2024877071380615, 'learning_rate': 2e-06, 'rewards/chosen': -0.30936580896377563, 'rewards/rejected': -0.5375332236289978, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.22816738486289978, 'logps/rejected': -65.09066009521484, 'logps/chosen': -63.11725616455078, 'logits/rejected': -35.759864807128906, 'logits/chosen': -35.61068344116211, 'epoch': 0.37}\n{'loss': 0.6086, 'grad_norm': 2.21431565284729, 'learning_rate': 2e-06, 'rewards/chosen': -0.3095366358757019, 'rewards/rejected': -0.5416632890701294, 'rewards/accuracies': 0.696093738079071, 'rewards/margins': 0.23212659358978271, 'logps/rejected': -66.38849639892578, 'logps/chosen': -63.08020782470703, 'logits/rejected': -36.282466888427734, 'logits/chosen': -35.58527374267578, 'epoch': 0.38}\n{'loss': 0.6031, 'grad_norm': 2.1633408069610596, 'learning_rate': 2e-06, 'rewards/chosen': -0.3336036503314972, 'rewards/rejected': -0.5841973423957825, 'rewards/accuracies': 0.69921875, 'rewards/margins': 0.2505936920642853, 'logps/rejected': -66.74787139892578, 'logps/chosen': -64.1337890625, 'logits/rejected': -36.18419647216797, 'logits/chosen': -35.384056091308594, 'epoch': 0.39}\n{'loss': 0.6179, 'grad_norm': 2.035717248916626, 'learning_rate': 2e-06, 'rewards/chosen': -0.36185580492019653, 'rewards/rejected': -0.5773295164108276, 'rewards/accuracies': 0.671093761920929, 'rewards/margins': 0.21547368168830872, 'logps/rejected': -66.10050964355469, 'logps/chosen': -63.92803192138672, 'logits/rejected': -35.86241912841797, 'logits/chosen': -35.101470947265625, 'epoch': 0.4}\n{'loss': 0.6014, 'grad_norm': 2.119922399520874, 'learning_rate': 2e-06, 'rewards/chosen': -0.35440677404403687, 'rewards/rejected': -0.6107379198074341, 'rewards/accuracies': 0.7046874761581421, 'rewards/margins': 0.2563311457633972, 'logps/rejected': -66.86426544189453, 'logps/chosen': -63.52007293701172, 'logits/rejected': -35.0254020690918, 'logits/chosen': -35.141502380371094, 'epoch': 0.41}\n{'loss': 0.5937, 'grad_norm': 1.9462069272994995, 'learning_rate': 2e-06, 'rewards/chosen': -0.3447539210319519, 'rewards/rejected': -0.6207534074783325, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.2759994864463806, 'logps/rejected': -66.65135192871094, 'logps/chosen': -63.18657684326172, 'logits/rejected': -35.35398483276367, 'logits/chosen': -34.58566665649414, 'epoch': 0.41}\n{'loss': 0.6013, 'grad_norm': 2.007795572280884, 'learning_rate': 2e-06, 'rewards/chosen': -0.38552969694137573, 'rewards/rejected': -0.6557008624076843, 'rewards/accuracies': 0.6820312738418579, 'rewards/margins': 0.270171195268631, 'logps/rejected': -67.18029022216797, 'logps/chosen': -64.46062469482422, 'logits/rejected': -35.568878173828125, 'logits/chosen': -34.827186584472656, 'epoch': 0.42}\n{'loss': 0.6061, 'grad_norm': 2.065265655517578, 'learning_rate': 2e-06, 'rewards/chosen': -0.40434569120407104, 'rewards/rejected': -0.6598930954933167, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.2555474042892456, 'logps/rejected': -66.46241760253906, 'logps/chosen': -64.61044311523438, 'logits/rejected': -35.596134185791016, 'logits/chosen': -35.17426300048828, 'epoch': 0.43}\n{'loss': 0.5889, 'grad_norm': 2.175950765609741, 'learning_rate': 2e-06, 'rewards/chosen': -0.4118477702140808, 'rewards/rejected': -0.7066433429718018, 'rewards/accuracies': 0.715624988079071, 'rewards/margins': 0.29479557275772095, 'logps/rejected': -68.18365478515625, 'logps/chosen': -64.36624145507812, 'logits/rejected': -34.847930908203125, 'logits/chosen': -34.30780792236328, 'epoch': 0.44}\n{'loss': 0.6013, 'grad_norm': 2.1033518314361572, 'learning_rate': 2e-06, 'rewards/chosen': -0.4213803708553314, 'rewards/rejected': -0.6903374791145325, 'rewards/accuracies': 0.6898437738418579, 'rewards/margins': 0.26895707845687866, 'logps/rejected': -66.49421691894531, 'logps/chosen': -64.67599487304688, 'logits/rejected': -35.429561614990234, 'logits/chosen': -34.914093017578125, 'epoch': 0.45}\n{'loss': 0.6021, 'grad_norm': 2.074492931365967, 'learning_rate': 2e-06, 'rewards/chosen': -0.43406739830970764, 'rewards/rejected': -0.7047268152236938, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.27065935730934143, 'logps/rejected': -66.92817687988281, 'logps/chosen': -64.5829849243164, 'logits/rejected': -35.61759948730469, 'logits/chosen': -34.572105407714844, 'epoch': 0.46}\n{'loss': 0.5986, 'grad_norm': 2.085033893585205, 'learning_rate': 2e-06, 'rewards/chosen': -0.44331327080726624, 'rewards/rejected': -0.7180570363998413, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.2747437655925751, 'logps/rejected': -67.84834289550781, 'logps/chosen': -64.9128189086914, 'logits/rejected': -35.03961181640625, 'logits/chosen': -34.62697982788086, 'epoch': 0.47}\n{'loss': 0.588, 'grad_norm': 1.8714962005615234, 'learning_rate': 2e-06, 'rewards/chosen': -0.4396783709526062, 'rewards/rejected': -0.751973569393158, 'rewards/accuracies': 0.707812488079071, 'rewards/margins': 0.31229519844055176, 'logps/rejected': -67.9634017944336, 'logps/chosen': -64.53889465332031, 'logits/rejected': -34.904605865478516, 'logits/chosen': -34.958290100097656, 'epoch': 0.48}\n{'loss': 0.588, 'grad_norm': 1.9480996131896973, 'learning_rate': 2e-06, 'rewards/chosen': -0.46819791197776794, 'rewards/rejected': -0.7793610095977783, 'rewards/accuracies': 0.7171875238418579, 'rewards/margins': 0.311163067817688, 'logps/rejected': -68.75074005126953, 'logps/chosen': -65.47621154785156, 'logits/rejected': -35.252418518066406, 'logits/chosen': -34.825843811035156, 'epoch': 0.49}\n{'loss': 0.5905, 'grad_norm': 1.94092857837677, 'learning_rate': 2e-06, 'rewards/chosen': -0.5001475811004639, 'rewards/rejected': -0.805549144744873, 'rewards/accuracies': 0.711718738079071, 'rewards/margins': 0.30540162324905396, 'logps/rejected': -68.88069152832031, 'logps/chosen': -65.22279357910156, 'logits/rejected': -35.26408004760742, 'logits/chosen': -34.91156768798828, 'epoch': 0.5}\n{'loss': 0.5912, 'grad_norm': 2.212515115737915, 'learning_rate': 2e-06, 'rewards/chosen': -0.5223209261894226, 'rewards/rejected': -0.8252702951431274, 'rewards/accuracies': 0.692187488079071, 'rewards/margins': 0.3029492497444153, 'logps/rejected': -69.49522399902344, 'logps/chosen': -65.05612182617188, 'logits/rejected': -34.69691848754883, 'logits/chosen': -34.25773239135742, 'epoch': 0.5}\n{'loss': 0.5894, 'grad_norm': 2.267496109008789, 'learning_rate': 2e-06, 'rewards/chosen': -0.517717719078064, 'rewards/rejected': -0.832302451133728, 'rewards/accuracies': 0.711718738079071, 'rewards/margins': 0.31458476185798645, 'logps/rejected': -68.02458190917969, 'logps/chosen': -65.15235137939453, 'logits/rejected': -35.47037887573242, 'logits/chosen': -34.229347229003906, 'epoch': 0.51}\n{'loss': 0.5822, 'grad_norm': 2.301656723022461, 'learning_rate': 2e-06, 'rewards/chosen': -0.5413298010826111, 'rewards/rejected': -0.8791878819465637, 'rewards/accuracies': 0.7085937261581421, 'rewards/margins': 0.3378579318523407, 'logps/rejected': -70.33303833007812, 'logps/chosen': -66.74522399902344, 'logits/rejected': -34.85568618774414, 'logits/chosen': -34.26284408569336, 'epoch': 0.52}\n{'loss': 0.5768, 'grad_norm': 2.154698610305786, 'learning_rate': 2e-06, 'rewards/chosen': -0.531121551990509, 'rewards/rejected': -0.8882321119308472, 'rewards/accuracies': 0.7054687738418579, 'rewards/margins': 0.35711055994033813, 'logps/rejected': -69.03421783447266, 'logps/chosen': -65.08355712890625, 'logits/rejected': -34.56058883666992, 'logits/chosen': -34.14348602294922, 'epoch': 0.53}\n{'loss': 0.5776, 'grad_norm': 2.0934360027313232, 'learning_rate': 2e-06, 'rewards/chosen': -0.5482785105705261, 'rewards/rejected': -0.9002162218093872, 'rewards/accuracies': 0.7171875238418579, 'rewards/margins': 0.35193759202957153, 'logps/rejected': -69.87001037597656, 'logps/chosen': -65.3531265258789, 'logits/rejected': -34.570499420166016, 'logits/chosen': -34.139854431152344, 'epoch': 0.54}\n{'loss': 0.5888, 'grad_norm': 2.117888927459717, 'learning_rate': 2e-06, 'rewards/chosen': -0.5858322381973267, 'rewards/rejected': -0.91407310962677, 'rewards/accuracies': 0.694531261920929, 'rewards/margins': 0.32824093103408813, 'logps/rejected': -69.94569396972656, 'logps/chosen': -66.15833282470703, 'logits/rejected': -34.888118743896484, 'logits/chosen': -34.37947082519531, 'epoch': 0.55}\n{'loss': 0.592, 'grad_norm': 2.094658136367798, 'learning_rate': 2e-06, 'rewards/chosen': -0.5943202972412109, 'rewards/rejected': -0.9197250604629517, 'rewards/accuracies': 0.6890624761581421, 'rewards/margins': 0.32540473341941833, 'logps/rejected': -70.16009521484375, 'logps/chosen': -65.87193298339844, 'logits/rejected': -34.28606414794922, 'logits/chosen': -33.97576904296875, 'epoch': 0.56}\n{'loss': 0.5855, 'grad_norm': 2.006917715072632, 'learning_rate': 2e-06, 'rewards/chosen': -0.5850424766540527, 'rewards/rejected': -0.9262102246284485, 'rewards/accuracies': 0.698437511920929, 'rewards/margins': 0.34116774797439575, 'logps/rejected': -70.49815368652344, 'logps/chosen': -66.59376525878906, 'logits/rejected': -34.21267318725586, 'logits/chosen': -34.13667297363281, 'epoch': 0.57}\n{'loss': 0.5784, 'grad_norm': 2.2156546115875244, 'learning_rate': 2e-06, 'rewards/chosen': -0.5738383531570435, 'rewards/rejected': -0.9384252429008484, 'rewards/accuracies': 0.721875011920929, 'rewards/margins': 0.36458688974380493, 'logps/rejected': -70.17485046386719, 'logps/chosen': -64.8511962890625, 'logits/rejected': -34.23815155029297, 'logits/chosen': -33.942813873291016, 'epoch': 0.58}\n{'loss': 0.5823, 'grad_norm': 2.018064260482788, 'learning_rate': 2e-06, 'rewards/chosen': -0.6086068749427795, 'rewards/rejected': -0.9623721837997437, 'rewards/accuracies': 0.703906238079071, 'rewards/margins': 0.3537653386592865, 'logps/rejected': -70.03199768066406, 'logps/chosen': -65.93647766113281, 'logits/rejected': -34.883697509765625, 'logits/chosen': -34.33708190917969, 'epoch': 0.59}\n{'loss': 0.5807, 'grad_norm': 2.2967514991760254, 'learning_rate': 2e-06, 'rewards/chosen': -0.6324114203453064, 'rewards/rejected': -0.9944846034049988, 'rewards/accuracies': 0.70703125, 'rewards/margins': 0.36207306385040283, 'logps/rejected': -69.90534973144531, 'logps/chosen': -66.69552612304688, 'logits/rejected': -34.371917724609375, 'logits/chosen': -33.881107330322266, 'epoch': 0.6}\n{'loss': 0.5668, 'grad_norm': 2.0088632106781006, 'learning_rate': 2e-06, 'rewards/chosen': -0.6152752637863159, 'rewards/rejected': -1.0067695379257202, 'rewards/accuracies': 0.7210937738418579, 'rewards/margins': 0.39149436354637146, 'logps/rejected': -70.88834381103516, 'logps/chosen': -66.05952453613281, 'logits/rejected': -34.520503997802734, 'logits/chosen': -34.09143829345703, 'epoch': 0.6}\n{'loss': 0.5874, 'grad_norm': 2.2693090438842773, 'learning_rate': 2e-06, 'rewards/chosen': -0.6491074562072754, 'rewards/rejected': -1.0082964897155762, 'rewards/accuracies': 0.690625011920929, 'rewards/margins': 0.3591890335083008, 'logps/rejected': -70.47709655761719, 'logps/chosen': -67.07109069824219, 'logits/rejected': -34.35667037963867, 'logits/chosen': -34.10013198852539, 'epoch': 0.61}\n{'loss': 0.5709, 'grad_norm': 1.903802514076233, 'learning_rate': 2e-06, 'rewards/chosen': -0.6579602956771851, 'rewards/rejected': -1.0580147504806519, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.4000545144081116, 'logps/rejected': -70.84781646728516, 'logps/chosen': -67.68840026855469, 'logits/rejected': -33.85503387451172, 'logits/chosen': -33.93704605102539, 'epoch': 0.62}\n{'loss': 0.5879, 'grad_norm': 2.0655453205108643, 'learning_rate': 2e-06, 'rewards/chosen': -0.6870739459991455, 'rewards/rejected': -1.046267032623291, 'rewards/accuracies': 0.682812511920929, 'rewards/margins': 0.3591930866241455, 'logps/rejected': -70.52779388427734, 'logps/chosen': -66.70491027832031, 'logits/rejected': -34.156349182128906, 'logits/chosen': -33.479942321777344, 'epoch': 0.63}\n{'loss': 0.5893, 'grad_norm': 1.951383352279663, 'learning_rate': 2e-06, 'rewards/chosen': -0.6756567358970642, 'rewards/rejected': -1.0328614711761475, 'rewards/accuracies': 0.684374988079071, 'rewards/margins': 0.35720473527908325, 'logps/rejected': -69.98818969726562, 'logps/chosen': -67.62360382080078, 'logits/rejected': -34.326377868652344, 'logits/chosen': -33.292564392089844, 'epoch': 0.64}\n{'loss': 0.5612, 'grad_norm': 2.0268821716308594, 'learning_rate': 2e-06, 'rewards/chosen': -0.644571840763092, 'rewards/rejected': -1.0619916915893555, 'rewards/accuracies': 0.72265625, 'rewards/margins': 0.4174196720123291, 'logps/rejected': -70.49386596679688, 'logps/chosen': -65.9693374633789, 'logits/rejected': -34.09651184082031, 'logits/chosen': -33.89180374145508, 'epoch': 0.65}\n{'loss': 0.5696, 'grad_norm': 2.16474986076355, 'learning_rate': 2e-06, 'rewards/chosen': -0.674813985824585, 'rewards/rejected': -1.081439733505249, 'rewards/accuracies': 0.703125, 'rewards/margins': 0.406625896692276, 'logps/rejected': -71.03016662597656, 'logps/chosen': -66.8515396118164, 'logits/rejected': -33.82793426513672, 'logits/chosen': -33.79206466674805, 'epoch': 0.66}\n{'loss': 0.5813, 'grad_norm': 2.1001927852630615, 'learning_rate': 2e-06, 'rewards/chosen': -0.6737033724784851, 'rewards/rejected': -1.0394184589385986, 'rewards/accuracies': 0.7015625238418579, 'rewards/margins': 0.365714967250824, 'logps/rejected': -70.98678588867188, 'logps/chosen': -67.29073333740234, 'logits/rejected': -34.102760314941406, 'logits/chosen': -33.62361145019531, 'epoch': 0.67}\n{'loss': 0.5794, 'grad_norm': 2.3818953037261963, 'learning_rate': 2e-06, 'rewards/chosen': -0.6756340265274048, 'rewards/rejected': -1.0561515092849731, 'rewards/accuracies': 0.690625011920929, 'rewards/margins': 0.38051751255989075, 'logps/rejected': -70.23003387451172, 'logps/chosen': -66.97859191894531, 'logits/rejected': -34.017921447753906, 'logits/chosen': -33.88853073120117, 'epoch': 0.68}\n{'loss': 0.5723, 'grad_norm': 2.0757739543914795, 'learning_rate': 2e-06, 'rewards/chosen': -0.6864562034606934, 'rewards/rejected': -1.0908746719360352, 'rewards/accuracies': 0.717968761920929, 'rewards/margins': 0.4044185280799866, 'logps/rejected': -70.54251861572266, 'logps/chosen': -66.5937728881836, 'logits/rejected': -34.34577178955078, 'logits/chosen': -34.058189392089844, 'epoch': 0.69}\n{'loss': 0.5873, 'grad_norm': 2.165767192840576, 'learning_rate': 2e-06, 'rewards/chosen': -0.7146464586257935, 'rewards/rejected': -1.0837455987930298, 'rewards/accuracies': 0.6953125, 'rewards/margins': 0.3690991997718811, 'logps/rejected': -72.00897979736328, 'logps/chosen': -67.27204132080078, 'logits/rejected': -34.034732818603516, 'logits/chosen': -33.65845489501953, 'epoch': 0.69}\n{'loss': 0.5816, 'grad_norm': 1.9717140197753906, 'learning_rate': 2e-06, 'rewards/chosen': -0.6833423376083374, 'rewards/rejected': -1.052335500717163, 'rewards/accuracies': 0.6968749761581421, 'rewards/margins': 0.3689931333065033, 'logps/rejected': -70.47020721435547, 'logps/chosen': -66.36841583251953, 'logits/rejected': -33.951499938964844, 'logits/chosen': -34.17527770996094, 'epoch': 0.7}\n{'loss': 0.5588, 'grad_norm': 2.1401846408843994, 'learning_rate': 2e-06, 'rewards/chosen': -0.6891375780105591, 'rewards/rejected': -1.118470311164856, 'rewards/accuracies': 0.717968761920929, 'rewards/margins': 0.4293327331542969, 'logps/rejected': -71.42190551757812, 'logps/chosen': -67.37067413330078, 'logits/rejected': -33.881961822509766, 'logits/chosen': -33.50233459472656, 'epoch': 0.71}\n{'loss': 0.5832, 'grad_norm': 2.176260471343994, 'learning_rate': 2e-06, 'rewards/chosen': -0.6978904604911804, 'rewards/rejected': -1.0730788707733154, 'rewards/accuracies': 0.7015625238418579, 'rewards/margins': 0.3751884400844574, 'logps/rejected': -70.32616424560547, 'logps/chosen': -66.90706634521484, 'logits/rejected': -33.81686019897461, 'logits/chosen': -33.203426361083984, 'epoch': 0.72}\n{'loss': 0.5674, 'grad_norm': 2.046294689178467, 'learning_rate': 2e-06, 'rewards/chosen': -0.7152115106582642, 'rewards/rejected': -1.1415953636169434, 'rewards/accuracies': 0.71484375, 'rewards/margins': 0.4263837933540344, 'logps/rejected': -71.86067199707031, 'logps/chosen': -67.2718505859375, 'logits/rejected': -34.125732421875, 'logits/chosen': -33.89744567871094, 'epoch': 0.73}\n{'loss': 0.5668, 'grad_norm': 2.0028395652770996, 'learning_rate': 2e-06, 'rewards/chosen': -0.7198397517204285, 'rewards/rejected': -1.1382218599319458, 'rewards/accuracies': 0.703125, 'rewards/margins': 0.4183819890022278, 'logps/rejected': -70.94618225097656, 'logps/chosen': -67.49003601074219, 'logits/rejected': -34.35837936401367, 'logits/chosen': -33.7766227722168, 'epoch': 0.74}\n{'loss': 0.5736, 'grad_norm': 2.078831911087036, 'learning_rate': 2e-06, 'rewards/chosen': -0.7112258672714233, 'rewards/rejected': -1.108811855316162, 'rewards/accuracies': 0.703906238079071, 'rewards/margins': 0.3975859582424164, 'logps/rejected': -70.95101928710938, 'logps/chosen': -67.81009674072266, 'logits/rejected': -33.14698028564453, 'logits/chosen': -32.94080352783203, 'epoch': 0.75}\n{'loss': 0.5483, 'grad_norm': 2.063147783279419, 'learning_rate': 2e-06, 'rewards/chosen': -0.7205098867416382, 'rewards/rejected': -1.189441204071045, 'rewards/accuracies': 0.7289062738418579, 'rewards/margins': 0.4689313471317291, 'logps/rejected': -73.37067413330078, 'logps/chosen': -67.95027923583984, 'logits/rejected': -33.34528732299805, 'logits/chosen': -32.87379837036133, 'epoch': 0.76}\n{'loss': 0.5792, 'grad_norm': 1.894871711730957, 'learning_rate': 2e-06, 'rewards/chosen': -0.784705638885498, 'rewards/rejected': -1.183778166770935, 'rewards/accuracies': 0.714062511920929, 'rewards/margins': 0.39907270669937134, 'logps/rejected': -73.13923645019531, 'logps/chosen': -68.22016906738281, 'logits/rejected': -33.35948944091797, 'logits/chosen': -33.066349029541016, 'epoch': 0.77}\n{'loss': 0.5749, 'grad_norm': 1.9538578987121582, 'learning_rate': 2e-06, 'rewards/chosen': -0.7705467343330383, 'rewards/rejected': -1.1759254932403564, 'rewards/accuracies': 0.7109375, 'rewards/margins': 0.4053788185119629, 'logps/rejected': -71.59526062011719, 'logps/chosen': -67.63565826416016, 'logits/rejected': -34.08316421508789, 'logits/chosen': -33.37125015258789, 'epoch': 0.78}\n{'loss': 0.5667, 'grad_norm': 2.111999273300171, 'learning_rate': 2e-06, 'rewards/chosen': -0.7427847981452942, 'rewards/rejected': -1.1757744550704956, 'rewards/accuracies': 0.707812488079071, 'rewards/margins': 0.43298977613449097, 'logps/rejected': -72.47122955322266, 'logps/chosen': -67.98587799072266, 'logits/rejected': -33.617801666259766, 'logits/chosen': -33.018890380859375, 'epoch': 0.78}\n{'loss': 0.5656, 'grad_norm': 2.0314900875091553, 'learning_rate': 2e-06, 'rewards/chosen': -0.7854976058006287, 'rewards/rejected': -1.2225544452667236, 'rewards/accuracies': 0.710156261920929, 'rewards/margins': 0.43705683946609497, 'logps/rejected': -72.53593444824219, 'logps/chosen': -68.50627136230469, 'logits/rejected': -33.627525329589844, 'logits/chosen': -32.7357177734375, 'epoch': 0.79}\n{'loss': 0.5751, 'grad_norm': 2.03743839263916, 'learning_rate': 2e-06, 'rewards/chosen': -0.7842447757720947, 'rewards/rejected': -1.2009021043777466, 'rewards/accuracies': 0.7046874761581421, 'rewards/margins': 0.41665729880332947, 'logps/rejected': -72.2069091796875, 'logps/chosen': -68.76605224609375, 'logits/rejected': -33.26775360107422, 'logits/chosen': -33.30154037475586, 'epoch': 0.8}\n{'loss': 0.583, 'grad_norm': 2.015662908554077, 'learning_rate': 2e-06, 'rewards/chosen': -0.8172287940979004, 'rewards/rejected': -1.2105789184570312, 'rewards/accuracies': 0.703906238079071, 'rewards/margins': 0.3933500647544861, 'logps/rejected': -72.79209899902344, 'logps/chosen': -68.5792007446289, 'logits/rejected': -33.39101791381836, 'logits/chosen': -33.469970703125, 'epoch': 0.81}\n{'loss': 0.5693, 'grad_norm': 2.1724207401275635, 'learning_rate': 2e-06, 'rewards/chosen': -0.8074407577514648, 'rewards/rejected': -1.2466017007827759, 'rewards/accuracies': 0.707812488079071, 'rewards/margins': 0.4391609728336334, 'logps/rejected': -71.92557525634766, 'logps/chosen': -67.52555847167969, 'logits/rejected': -33.84809494018555, 'logits/chosen': -33.53123092651367, 'epoch': 0.82}\n{'loss': 0.5592, 'grad_norm': 2.3882830142974854, 'learning_rate': 2e-06, 'rewards/chosen': -0.7962892651557922, 'rewards/rejected': -1.251301884651184, 'rewards/accuracies': 0.714062511920929, 'rewards/margins': 0.455012708902359, 'logps/rejected': -73.45870208740234, 'logps/chosen': -68.5413589477539, 'logits/rejected': -33.228904724121094, 'logits/chosen': -32.91179275512695, 'epoch': 0.83}\n{'loss': 0.5657, 'grad_norm': 2.105525493621826, 'learning_rate': 2e-06, 'rewards/chosen': -0.8049694299697876, 'rewards/rejected': -1.2628527879714966, 'rewards/accuracies': 0.707812488079071, 'rewards/margins': 0.4578832983970642, 'logps/rejected': -73.39937591552734, 'logps/chosen': -67.92970275878906, 'logits/rejected': -33.31318664550781, 'logits/chosen': -33.58844757080078, 'epoch': 0.84}\n{'loss': 0.5771, 'grad_norm': 2.0243492126464844, 'learning_rate': 2e-06, 'rewards/chosen': -0.8146103024482727, 'rewards/rejected': -1.2347073554992676, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.4200971722602844, 'logps/rejected': -72.28472900390625, 'logps/chosen': -67.25951385498047, 'logits/rejected': -33.38179397583008, 'logits/chosen': -32.990447998046875, 'epoch': 0.85}\n{'loss': 0.5648, 'grad_norm': 2.0178751945495605, 'learning_rate': 2e-06, 'rewards/chosen': -0.8085335493087769, 'rewards/rejected': -1.2582385540008545, 'rewards/accuracies': 0.707812488079071, 'rewards/margins': 0.44970497488975525, 'logps/rejected': -73.29911804199219, 'logps/chosen': -68.91395568847656, 'logits/rejected': -32.50786590576172, 'logits/chosen': -32.177547454833984, 'epoch': 0.86}\n{'loss': 0.5632, 'grad_norm': 2.0762176513671875, 'learning_rate': 2e-06, 'rewards/chosen': -0.8132322430610657, 'rewards/rejected': -1.2815372943878174, 'rewards/accuracies': 0.6953125, 'rewards/margins': 0.4683048725128174, 'logps/rejected': -73.39439392089844, 'logps/chosen': -68.33341979980469, 'logits/rejected': -32.828277587890625, 'logits/chosen': -32.75632858276367, 'epoch': 0.87}\n{'loss': 0.545, 'grad_norm': 1.9238007068634033, 'learning_rate': 2e-06, 'rewards/chosen': -0.8008588552474976, 'rewards/rejected': -1.2943432331085205, 'rewards/accuracies': 0.745312511920929, 'rewards/margins': 0.4934841990470886, 'logps/rejected': -73.43073272705078, 'logps/chosen': -67.20042419433594, 'logits/rejected': -32.96726989746094, 'logits/chosen': -32.579463958740234, 'epoch': 0.87}\n{'loss': 0.5594, 'grad_norm': 2.1665291786193848, 'learning_rate': 2e-06, 'rewards/chosen': -0.8268488049507141, 'rewards/rejected': -1.291501760482788, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.46465277671813965, 'logps/rejected': -73.43238830566406, 'logps/chosen': -68.19837951660156, 'logits/rejected': -32.95195388793945, 'logits/chosen': -33.006935119628906, 'epoch': 0.88}\n{'loss': 0.5613, 'grad_norm': 2.055142879486084, 'learning_rate': 2e-06, 'rewards/chosen': -0.8298311233520508, 'rewards/rejected': -1.290519118309021, 'rewards/accuracies': 0.715624988079071, 'rewards/margins': 0.4606879651546478, 'logps/rejected': -73.4603271484375, 'logps/chosen': -68.19081115722656, 'logits/rejected': -33.253807067871094, 'logits/chosen': -32.83895492553711, 'epoch': 0.89}\n{'loss': 0.5587, 'grad_norm': 2.232696771621704, 'learning_rate': 2e-06, 'rewards/chosen': -0.8745934367179871, 'rewards/rejected': -1.3576676845550537, 'rewards/accuracies': 0.70703125, 'rewards/margins': 0.4830741286277771, 'logps/rejected': -73.6273422241211, 'logps/chosen': -68.8765640258789, 'logits/rejected': -33.09668731689453, 'logits/chosen': -32.921958923339844, 'epoch': 0.9}\n{'loss': 0.5611, 'grad_norm': 2.087773561477661, 'learning_rate': 2e-06, 'rewards/chosen': -0.8747801780700684, 'rewards/rejected': -1.3466579914093018, 'rewards/accuracies': 0.7171875238418579, 'rewards/margins': 0.4718777537345886, 'logps/rejected': -74.62067413330078, 'logps/chosen': -69.17375183105469, 'logits/rejected': -32.906944274902344, 'logits/chosen': -32.48984909057617, 'epoch': 0.91}\n{'loss': 0.5653, 'grad_norm': 2.111419677734375, 'learning_rate': 2e-06, 'rewards/chosen': -0.8554272651672363, 'rewards/rejected': -1.3120867013931274, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.4566594958305359, 'logps/rejected': -73.70475769042969, 'logps/chosen': -68.1063232421875, 'logits/rejected': -33.143455505371094, 'logits/chosen': -32.923614501953125, 'epoch': 0.92}\n{'loss': 0.5532, 'grad_norm': 1.984822392463684, 'learning_rate': 2e-06, 'rewards/chosen': -0.8576386570930481, 'rewards/rejected': -1.359326958656311, 'rewards/accuracies': 0.7281249761581421, 'rewards/margins': 0.5016883015632629, 'logps/rejected': -73.59741973876953, 'logps/chosen': -68.63134765625, 'logits/rejected': -33.073875427246094, 'logits/chosen': -32.49797058105469, 'epoch': 0.93}\n{'loss': 0.5565, 'grad_norm': 2.0172886848449707, 'learning_rate': 2e-06, 'rewards/chosen': -0.878189742565155, 'rewards/rejected': -1.352205514907837, 'rewards/accuracies': 0.7085937261581421, 'rewards/margins': 0.47401586174964905, 'logps/rejected': -74.55146026611328, 'logps/chosen': -69.05561065673828, 'logits/rejected': -32.80591583251953, 'logits/chosen': -32.787288665771484, 'epoch': 0.94}\n{'loss': 0.5532, 'grad_norm': 1.9247932434082031, 'learning_rate': 2e-06, 'rewards/chosen': -0.8724879026412964, 'rewards/rejected': -1.363948106765747, 'rewards/accuracies': 0.72265625, 'rewards/margins': 0.49146026372909546, 'logps/rejected': -74.26284790039062, 'logps/chosen': -68.81268310546875, 'logits/rejected': -33.14300537109375, 'logits/chosen': -32.927635192871094, 'epoch': 0.95}\n{'loss': 0.5527, 'grad_norm': 1.9972890615463257, 'learning_rate': 2e-06, 'rewards/chosen': -0.8761148452758789, 'rewards/rejected': -1.375784993171692, 'rewards/accuracies': 0.7242187261581421, 'rewards/margins': 0.4996701180934906, 'logps/rejected': -74.2396011352539, 'logps/chosen': -68.84967041015625, 'logits/rejected': -33.23927688598633, 'logits/chosen': -32.77644348144531, 'epoch': 0.96}\n{'loss': 0.5443, 'grad_norm': 2.06199049949646, 'learning_rate': 2e-06, 'rewards/chosen': -0.8689327239990234, 'rewards/rejected': -1.388487458229065, 'rewards/accuracies': 0.735156238079071, 'rewards/margins': 0.5195547342300415, 'logps/rejected': -74.67902374267578, 'logps/chosen': -69.52055358886719, 'logits/rejected': -32.49503707885742, 'logits/chosen': -31.96468734741211, 'epoch': 0.96}\n{'loss': 0.5472, 'grad_norm': 2.0648562908172607, 'learning_rate': 2e-06, 'rewards/chosen': -0.8921293020248413, 'rewards/rejected': -1.4201427698135376, 'rewards/accuracies': 0.7171875238418579, 'rewards/margins': 0.5280133485794067, 'logps/rejected': -74.12178802490234, 'logps/chosen': -69.18385314941406, 'logits/rejected': -33.040306091308594, 'logits/chosen': -32.95936965942383, 'epoch': 0.97}\n{'loss': 0.5478, 'grad_norm': 2.0185763835906982, 'learning_rate': 2e-06, 'rewards/chosen': -0.902807891368866, 'rewards/rejected': -1.4262040853500366, 'rewards/accuracies': 0.734375, 'rewards/margins': 0.5233961343765259, 'logps/rejected': -74.69789123535156, 'logps/chosen': -69.42867279052734, 'logits/rejected': -32.71622085571289, 'logits/chosen': -32.40974044799805, 'epoch': 0.98}\n{'loss': 0.5603, 'grad_norm': 2.092651844024658, 'learning_rate': 2e-06, 'rewards/chosen': -0.9462025761604309, 'rewards/rejected': -1.4382212162017822, 'rewards/accuracies': 0.7171875238418579, 'rewards/margins': 0.49201861023902893, 'logps/rejected': -74.87843322753906, 'logps/chosen': -69.84025573730469, 'logits/rejected': -32.530426025390625, 'logits/chosen': -32.88483428955078, 'epoch': 0.99}\n 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1109/3327 [22:41<40:12,  1.09s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|‚ñà‚ñç                                          | 2/59 [00:00<00:15,  3.66it/s]\u001b[A\n  5%|‚ñà‚ñà‚ñè                                         | 3/59 [00:01<00:21,  2.55it/s]\u001b[A\n  7%|‚ñà‚ñà‚ñâ                                         | 4/59 [00:01<00:25,  2.17it/s]\u001b[A\n  8%|‚ñà‚ñà‚ñà‚ñã                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 6/59 [00:02<00:27,  1.96it/s]\u001b[A\n 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 7/59 [00:03<00:27,  1.89it/s]\u001b[A\n 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 8/59 [00:03<00:27,  1.87it/s]\u001b[A\n 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 12/59 [00:06<00:25,  1.83it/s]\u001b[A\n 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 14/59 [00:07<00:25,  1.79it/s]\u001b[A\n 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 15/59 [00:07<00:24,  1.80it/s]\u001b[A\n 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 18/59 [00:09<00:22,  1.82it/s]\u001b[A\n 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 19/59 [00:09<00:21,  1.82it/s]\u001b[A\n 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 24/59 [00:12<00:19,  1.81it/s]\u001b[A\n 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 28/59 [00:14<00:16,  1.83it/s]\u001b[A\n 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 29/59 [00:15<00:16,  1.83it/s]\u001b[A\n 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 33/59 [00:17<00:14,  1.80it/s]\u001b[A\n 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 34/59 [00:18<00:13,  1.80it/s]\u001b[A\n 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 36/59 [00:19<00:12,  1.82it/s]\u001b[A\n 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 37/59 [00:19<00:12,  1.82it/s]\u001b[A\n 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 39/59 [00:20<00:10,  1.82it/s]\u001b[A\n 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 44/59 [00:23<00:08,  1.82it/s]\u001b[A\n 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 47/59 [00:25<00:06,  1.81it/s]\u001b[A\n 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 48/59 [00:25<00:06,  1.79it/s]\u001b[A\n 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 50/59 [00:27<00:04,  1.81it/s]\u001b[A\n 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 52/59 [00:28<00:03,  1.82it/s]\u001b[A\n 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 53/59 [00:28<00:03,  1.82it/s]\u001b[A\n 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 57/59 [00:31<00:01,  1.76it/s]\u001b[A\n 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5530712008476257, 'eval_runtime': 32.3701, 'eval_samples_per_second': 230.738, 'eval_steps_per_second': 1.823, 'eval_rewards/chosen': -0.9202151298522949, 'eval_rewards/rejected': -1.4250231981277466, 'eval_rewards/accuracies': 0.7189059257507324, 'eval_rewards/margins': 0.5048081874847412, 'eval_logps/rejected': -74.51709747314453, 'eval_logps/chosen': -69.17178344726562, 'eval_logits/rejected': -32.51547622680664, 'eval_logits/chosen': -32.31167221069336, 'epoch': 1.0}\n 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1109/3327 [23:14<40:12,  1.09s/it]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59/59 [00:31<00:00,  2.21it/s]\u001b[A\n{'loss': 0.5655, 'grad_norm': 1.9497023820877075, 'learning_rate': 2e-06, 'rewards/chosen': -0.9102412462234497, 'rewards/rejected': -1.392452597618103, 'rewards/accuracies': 0.7105011940002441, 'rewards/margins': 0.4822116494178772, 'logps/rejected': -73.68193817138672, 'logps/chosen': -67.87093353271484, 'logits/rejected': -32.67476272583008, 'logits/chosen': -32.076377868652344, 'epoch': 1.0}\n{'loss': 0.5481, 'grad_norm': 2.045541286468506, 'learning_rate': 2e-06, 'rewards/chosen': -0.8796990513801575, 'rewards/rejected': -1.3898617029190063, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.5101624727249146, 'logps/rejected': -74.1929931640625, 'logps/chosen': -68.89726257324219, 'logits/rejected': -32.55139923095703, 'logits/chosen': -32.14595413208008, 'epoch': 1.01}\n{'loss': 0.5568, 'grad_norm': 2.073364734649658, 'learning_rate': 2e-06, 'rewards/chosen': -0.9268397092819214, 'rewards/rejected': -1.4200794696807861, 'rewards/accuracies': 0.7265625, 'rewards/margins': 0.4932396411895752, 'logps/rejected': -74.0124282836914, 'logps/chosen': -69.36732482910156, 'logits/rejected': -32.66996383666992, 'logits/chosen': -32.57551956176758, 'epoch': 1.02}\n{'loss': 0.5251, 'grad_norm': 2.1087653636932373, 'learning_rate': 2e-06, 'rewards/chosen': -0.8907674551010132, 'rewards/rejected': -1.4778445959091187, 'rewards/accuracies': 0.753125011920929, 'rewards/margins': 0.5870770215988159, 'logps/rejected': -74.81706237792969, 'logps/chosen': -68.50302124023438, 'logits/rejected': -33.04423904418945, 'logits/chosen': -32.8068962097168, 'epoch': 1.03}\n{'loss': 0.5401, 'grad_norm': 1.9831900596618652, 'learning_rate': 2e-06, 'rewards/chosen': -0.9307271242141724, 'rewards/rejected': -1.4798544645309448, 'rewards/accuracies': 0.7398437261581421, 'rewards/margins': 0.549127459526062, 'logps/rejected': -74.7059326171875, 'logps/chosen': -68.70799255371094, 'logits/rejected': -32.652801513671875, 'logits/chosen': -32.12873077392578, 'epoch': 1.04}\n{'loss': 0.5145, 'grad_norm': 1.976619839668274, 'learning_rate': 2e-06, 'rewards/chosen': -0.9237987399101257, 'rewards/rejected': -1.5222511291503906, 'rewards/accuracies': 0.76171875, 'rewards/margins': 0.5984523892402649, 'logps/rejected': -75.51412963867188, 'logps/chosen': -70.02452087402344, 'logits/rejected': -32.34160614013672, 'logits/chosen': -31.77522850036621, 'epoch': 1.05}\n{'loss': 0.5377, 'grad_norm': 1.9339110851287842, 'learning_rate': 2e-06, 'rewards/chosen': -0.9078632593154907, 'rewards/rejected': -1.4687700271606445, 'rewards/accuracies': 0.750781238079071, 'rewards/margins': 0.5609068274497986, 'logps/rejected': -75.58333587646484, 'logps/chosen': -69.87715148925781, 'logits/rejected': -32.62828826904297, 'logits/chosen': -32.093406677246094, 'epoch': 1.06}\n{'loss': 0.5209, 'grad_norm': 1.9065616130828857, 'learning_rate': 2e-06, 'rewards/chosen': -0.9035757184028625, 'rewards/rejected': -1.5046517848968506, 'rewards/accuracies': 0.7515624761581421, 'rewards/margins': 0.6010760068893433, 'logps/rejected': -75.2481689453125, 'logps/chosen': -68.60334777832031, 'logits/rejected': -32.552223205566406, 'logits/chosen': -32.32088851928711, 'epoch': 1.06}\n{'loss': 0.5473, 'grad_norm': 2.2123401165008545, 'learning_rate': 2e-06, 'rewards/chosen': -0.9712021946907043, 'rewards/rejected': -1.5182693004608154, 'rewards/accuracies': 0.72265625, 'rewards/margins': 0.5470670461654663, 'logps/rejected': -76.71052551269531, 'logps/chosen': -69.726318359375, 'logits/rejected': -32.09505844116211, 'logits/chosen': -32.218482971191406, 'epoch': 1.07}\n{'loss': 0.5487, 'grad_norm': 2.132662534713745, 'learning_rate': 2e-06, 'rewards/chosen': -0.9727398157119751, 'rewards/rejected': -1.5101412534713745, 'rewards/accuracies': 0.72265625, 'rewards/margins': 0.5374016761779785, 'logps/rejected': -75.9813461303711, 'logps/chosen': -69.76326751708984, 'logits/rejected': -32.4046745300293, 'logits/chosen': -32.034263610839844, 'epoch': 1.08}\n{'loss': 0.5369, 'grad_norm': 1.9899168014526367, 'learning_rate': 2e-06, 'rewards/chosen': -0.9559372067451477, 'rewards/rejected': -1.5175977945327759, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.5616605877876282, 'logps/rejected': -74.76432800292969, 'logps/chosen': -69.76070404052734, 'logits/rejected': -33.035240173339844, 'logits/chosen': -32.47307586669922, 'epoch': 1.09}\n{'loss': 0.5382, 'grad_norm': 2.0178351402282715, 'learning_rate': 2e-06, 'rewards/chosen': -0.9452042579650879, 'rewards/rejected': -1.4971210956573486, 'rewards/accuracies': 0.7421875, 'rewards/margins': 0.551916778087616, 'logps/rejected': -74.80210876464844, 'logps/chosen': -68.90118408203125, 'logits/rejected': -33.01833724975586, 'logits/chosen': -32.48346710205078, 'epoch': 1.1}\n{'loss': 0.5321, 'grad_norm': 1.869753122329712, 'learning_rate': 2e-06, 'rewards/chosen': -0.993531346321106, 'rewards/rejected': -1.5762240886688232, 'rewards/accuracies': 0.7367187738418579, 'rewards/margins': 0.5826928019523621, 'logps/rejected': -76.07086181640625, 'logps/chosen': -69.71247863769531, 'logits/rejected': -32.570064544677734, 'logits/chosen': -32.258216857910156, 'epoch': 1.11}\n{'loss': 0.5427, 'grad_norm': 1.9882104396820068, 'learning_rate': 2e-06, 'rewards/chosen': -1.0020129680633545, 'rewards/rejected': -1.5693962574005127, 'rewards/accuracies': 0.7281249761581421, 'rewards/margins': 0.5673832893371582, 'logps/rejected': -75.13663482666016, 'logps/chosen': -70.07616424560547, 'logits/rejected': -32.56141662597656, 'logits/chosen': -32.69988250732422, 'epoch': 1.12}\n{'loss': 0.5412, 'grad_norm': 2.0025129318237305, 'learning_rate': 2e-06, 'rewards/chosen': -1.003885269165039, 'rewards/rejected': -1.5804678201675415, 'rewards/accuracies': 0.7398437261581421, 'rewards/margins': 0.5765824913978577, 'logps/rejected': -76.65563201904297, 'logps/chosen': -70.81695556640625, 'logits/rejected': -32.777488708496094, 'logits/chosen': -32.89219284057617, 'epoch': 1.13}\n{'loss': 0.5291, 'grad_norm': 1.9487055540084839, 'learning_rate': 2e-06, 'rewards/chosen': -0.9925581216812134, 'rewards/rejected': -1.5712839365005493, 'rewards/accuracies': 0.7523437738418579, 'rewards/margins': 0.5787256956100464, 'logps/rejected': -77.03196716308594, 'logps/chosen': -69.4875259399414, 'logits/rejected': -32.448280334472656, 'logits/chosen': -32.733421325683594, 'epoch': 1.14}\n{'loss': 0.5243, 'grad_norm': 1.9463332891464233, 'learning_rate': 2e-06, 'rewards/chosen': -0.9800087213516235, 'rewards/rejected': -1.5864683389663696, 'rewards/accuracies': 0.7289062738418579, 'rewards/margins': 0.6064596176147461, 'logps/rejected': -76.42210388183594, 'logps/chosen': -70.21964263916016, 'logits/rejected': -32.7299919128418, 'logits/chosen': -32.145362854003906, 'epoch': 1.15}\n{'loss': 0.536, 'grad_norm': 2.1107988357543945, 'learning_rate': 2e-06, 'rewards/chosen': -1.0232408046722412, 'rewards/rejected': -1.5919541120529175, 'rewards/accuracies': 0.719531238079071, 'rewards/margins': 0.5687133073806763, 'logps/rejected': -76.15766906738281, 'logps/chosen': -70.78861236572266, 'logits/rejected': -32.42991638183594, 'logits/chosen': -32.10160446166992, 'epoch': 1.15}\n{'loss': 0.5238, 'grad_norm': 2.138115167617798, 'learning_rate': 2e-06, 'rewards/chosen': -1.0070613622665405, 'rewards/rejected': -1.618146538734436, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.611085057258606, 'logps/rejected': -76.3520736694336, 'logps/chosen': -70.68242645263672, 'logits/rejected': -32.618438720703125, 'logits/chosen': -32.24626159667969, 'epoch': 1.16}\n{'loss': 0.5191, 'grad_norm': 1.9336472749710083, 'learning_rate': 2e-06, 'rewards/chosen': -0.9888232350349426, 'rewards/rejected': -1.6140117645263672, 'rewards/accuracies': 0.760937511920929, 'rewards/margins': 0.6251885890960693, 'logps/rejected': -76.23934936523438, 'logps/chosen': -69.18544006347656, 'logits/rejected': -32.428932189941406, 'logits/chosen': -32.00010681152344, 'epoch': 1.17}\n{'loss': 0.5182, 'grad_norm': 2.049024820327759, 'learning_rate': 2e-06, 'rewards/chosen': -1.0147911310195923, 'rewards/rejected': -1.6451553106307983, 'rewards/accuracies': 0.753125011920929, 'rewards/margins': 0.630364179611206, 'logps/rejected': -77.99153137207031, 'logps/chosen': -70.18057250976562, 'logits/rejected': -32.09062194824219, 'logits/chosen': -32.25636291503906, 'epoch': 1.18}\n{'loss': 0.5379, 'grad_norm': 2.0388121604919434, 'learning_rate': 2e-06, 'rewards/chosen': -1.0421751737594604, 'rewards/rejected': -1.6289905309677124, 'rewards/accuracies': 0.741406261920929, 'rewards/margins': 0.5868154764175415, 'logps/rejected': -77.13248443603516, 'logps/chosen': -69.88613891601562, 'logits/rejected': -31.749425888061523, 'logits/chosen': -32.05089569091797, 'epoch': 1.19}\n{'loss': 0.5223, 'grad_norm': 1.9736003875732422, 'learning_rate': 2e-06, 'rewards/chosen': -1.0618458986282349, 'rewards/rejected': -1.7021064758300781, 'rewards/accuracies': 0.742968738079071, 'rewards/margins': 0.6402606964111328, 'logps/rejected': -77.65061950683594, 'logps/chosen': -71.11608123779297, 'logits/rejected': -32.21100616455078, 'logits/chosen': -32.396751403808594, 'epoch': 1.2}\n{'loss': 0.526, 'grad_norm': 1.9005212783813477, 'learning_rate': 2e-06, 'rewards/chosen': -1.0305025577545166, 'rewards/rejected': -1.6376006603240967, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.6070982217788696, 'logps/rejected': -76.75465393066406, 'logps/chosen': -70.46754455566406, 'logits/rejected': -32.08936309814453, 'logits/chosen': -31.79220962524414, 'epoch': 1.21}\n{'loss': 0.5302, 'grad_norm': 1.9971370697021484, 'learning_rate': 2e-06, 'rewards/chosen': -1.080182433128357, 'rewards/rejected': -1.6946033239364624, 'rewards/accuracies': 0.735156238079071, 'rewards/margins': 0.6144208908081055, 'logps/rejected': -77.69425964355469, 'logps/chosen': -70.9237060546875, 'logits/rejected': -31.65165138244629, 'logits/chosen': -31.98202896118164, 'epoch': 1.22}\n{'loss': 0.5346, 'grad_norm': 2.166767120361328, 'learning_rate': 2e-06, 'rewards/chosen': -1.114696741104126, 'rewards/rejected': -1.71237051486969, 'rewards/accuracies': 0.735156238079071, 'rewards/margins': 0.5976736545562744, 'logps/rejected': -78.08135986328125, 'logps/chosen': -71.53748321533203, 'logits/rejected': -31.960973739624023, 'logits/chosen': -31.98200035095215, 'epoch': 1.23}\n{'loss': 0.5482, 'grad_norm': 2.1051223278045654, 'learning_rate': 2e-06, 'rewards/chosen': -1.1370964050292969, 'rewards/rejected': -1.713057518005371, 'rewards/accuracies': 0.7289062738418579, 'rewards/margins': 0.5759610533714294, 'logps/rejected': -77.59442138671875, 'logps/chosen': -72.10266876220703, 'logits/rejected': -32.065391540527344, 'logits/chosen': -31.721797943115234, 'epoch': 1.24}\n{'loss': 0.525, 'grad_norm': 2.068183422088623, 'learning_rate': 2e-06, 'rewards/chosen': -1.1044723987579346, 'rewards/rejected': -1.7179847955703735, 'rewards/accuracies': 0.742968738079071, 'rewards/margins': 0.6135126948356628, 'logps/rejected': -77.48640441894531, 'logps/chosen': -72.00230407714844, 'logits/rejected': -31.824146270751953, 'logits/chosen': -31.88492202758789, 'epoch': 1.24}\n{'loss': 0.5191, 'grad_norm': 2.0291035175323486, 'learning_rate': 2e-06, 'rewards/chosen': -1.0937451124191284, 'rewards/rejected': -1.7239841222763062, 'rewards/accuracies': 0.7632812261581421, 'rewards/margins': 0.630238950252533, 'logps/rejected': -77.35063171386719, 'logps/chosen': -71.66776275634766, 'logits/rejected': -32.166927337646484, 'logits/chosen': -31.939783096313477, 'epoch': 1.25}\n{'loss': 0.5307, 'grad_norm': 1.9787217378616333, 'learning_rate': 2e-06, 'rewards/chosen': -1.080885648727417, 'rewards/rejected': -1.6840356588363647, 'rewards/accuracies': 0.7265625, 'rewards/margins': 0.6031500697135925, 'logps/rejected': -77.4621810913086, 'logps/chosen': -71.18274688720703, 'logits/rejected': -32.20981216430664, 'logits/chosen': -32.01963806152344, 'epoch': 1.26}\n{'loss': 0.5341, 'grad_norm': 2.055579423904419, 'learning_rate': 2e-06, 'rewards/chosen': -1.0851354598999023, 'rewards/rejected': -1.712955117225647, 'rewards/accuracies': 0.7289062738418579, 'rewards/margins': 0.6278195977210999, 'logps/rejected': -77.36296081542969, 'logps/chosen': -70.52638244628906, 'logits/rejected': -32.51787567138672, 'logits/chosen': -31.971294403076172, 'epoch': 1.27}\n{'loss': 0.5452, 'grad_norm': 2.086045026779175, 'learning_rate': 2e-06, 'rewards/chosen': -1.12096107006073, 'rewards/rejected': -1.7059342861175537, 'rewards/accuracies': 0.725781261920929, 'rewards/margins': 0.5849732160568237, 'logps/rejected': -77.1011962890625, 'logps/chosen': -70.65208435058594, 'logits/rejected': -32.25359344482422, 'logits/chosen': -32.061607360839844, 'epoch': 1.28}\n{'loss': 0.5372, 'grad_norm': 2.1157281398773193, 'learning_rate': 2e-06, 'rewards/chosen': -1.0876457691192627, 'rewards/rejected': -1.6844924688339233, 'rewards/accuracies': 0.742968738079071, 'rewards/margins': 0.5968466997146606, 'logps/rejected': -77.45609283447266, 'logps/chosen': -71.31903076171875, 'logits/rejected': -32.030555725097656, 'logits/chosen': -31.957305908203125, 'epoch': 1.29}\n{'loss': 0.5205, 'grad_norm': 2.0280632972717285, 'learning_rate': 2e-06, 'rewards/chosen': -1.0537177324295044, 'rewards/rejected': -1.6922712326049805, 'rewards/accuracies': 0.746874988079071, 'rewards/margins': 0.6385536193847656, 'logps/rejected': -78.4217529296875, 'logps/chosen': -70.6375961303711, 'logits/rejected': -31.401962280273438, 'logits/chosen': -31.864398956298828, 'epoch': 1.3}\n{'loss': 0.5316, 'grad_norm': 2.1111717224121094, 'learning_rate': 2e-06, 'rewards/chosen': -1.0915439128875732, 'rewards/rejected': -1.7221593856811523, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.6306155920028687, 'logps/rejected': -77.57901000976562, 'logps/chosen': -71.38707733154297, 'logits/rejected': -31.708606719970703, 'logits/chosen': -31.415258407592773, 'epoch': 1.31}\n{'loss': 0.5416, 'grad_norm': 2.065678119659424, 'learning_rate': 2e-06, 'rewards/chosen': -1.1470547914505005, 'rewards/rejected': -1.7315263748168945, 'rewards/accuracies': 0.719531238079071, 'rewards/margins': 0.584471583366394, 'logps/rejected': -77.03118896484375, 'logps/chosen': -71.95237731933594, 'logits/rejected': -31.60568618774414, 'logits/chosen': -31.569732666015625, 'epoch': 1.32}\n{'loss': 0.5507, 'grad_norm': 1.8657268285751343, 'learning_rate': 2e-06, 'rewards/chosen': -1.1148908138275146, 'rewards/rejected': -1.6694809198379517, 'rewards/accuracies': 0.717968761920929, 'rewards/margins': 0.5545900464057922, 'logps/rejected': -76.86439514160156, 'logps/chosen': -71.0045166015625, 'logits/rejected': -31.27215576171875, 'logits/chosen': -31.17658042907715, 'epoch': 1.33}\n{'loss': 0.5384, 'grad_norm': 2.0491762161254883, 'learning_rate': 2e-06, 'rewards/chosen': -1.1141126155853271, 'rewards/rejected': -1.691495656967163, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.5773831605911255, 'logps/rejected': -77.49595642089844, 'logps/chosen': -71.38419342041016, 'logits/rejected': -31.824081420898438, 'logits/chosen': -31.801631927490234, 'epoch': 1.33}\n{'loss': 0.5484, 'grad_norm': 2.1976261138916016, 'learning_rate': 2e-06, 'rewards/chosen': -1.1080453395843506, 'rewards/rejected': -1.657907247543335, 'rewards/accuracies': 0.7328125238418579, 'rewards/margins': 0.5498621463775635, 'logps/rejected': -76.98057556152344, 'logps/chosen': -71.53345489501953, 'logits/rejected': -31.740604400634766, 'logits/chosen': -31.239822387695312, 'epoch': 1.34}\n{'loss': 0.5227, 'grad_norm': 2.042074203491211, 'learning_rate': 2e-06, 'rewards/chosen': -1.1110382080078125, 'rewards/rejected': -1.7414076328277588, 'rewards/accuracies': 0.7406250238418579, 'rewards/margins': 0.6303693056106567, 'logps/rejected': -78.09270477294922, 'logps/chosen': -71.2524642944336, 'logits/rejected': -31.711456298828125, 'logits/chosen': -31.853275299072266, 'epoch': 1.35}\n{'loss': 0.5225, 'grad_norm': 1.9090396165847778, 'learning_rate': 2e-06, 'rewards/chosen': -1.0965169668197632, 'rewards/rejected': -1.7257407903671265, 'rewards/accuracies': 0.742968738079071, 'rewards/margins': 0.6292240023612976, 'logps/rejected': -76.92403411865234, 'logps/chosen': -70.95276641845703, 'logits/rejected': -31.79329490661621, 'logits/chosen': -31.845905303955078, 'epoch': 1.36}\n{'loss': 0.533, 'grad_norm': 2.0120973587036133, 'learning_rate': 2e-06, 'rewards/chosen': -1.1044561862945557, 'rewards/rejected': -1.7114143371582031, 'rewards/accuracies': 0.7328125238418579, 'rewards/margins': 0.6069582104682922, 'logps/rejected': -77.10490417480469, 'logps/chosen': -71.26802062988281, 'logits/rejected': -31.824777603149414, 'logits/chosen': -31.69436264038086, 'epoch': 1.37}\n{'loss': 0.5319, 'grad_norm': 2.151015520095825, 'learning_rate': 2e-06, 'rewards/chosen': -1.1038429737091064, 'rewards/rejected': -1.7313811779022217, 'rewards/accuracies': 0.7320312261581421, 'rewards/margins': 0.6275384426116943, 'logps/rejected': -78.13697814941406, 'logps/chosen': -71.34679412841797, 'logits/rejected': -31.6827335357666, 'logits/chosen': -31.466861724853516, 'epoch': 1.38}\n{'loss': 0.5075, 'grad_norm': 2.0885567665100098, 'learning_rate': 2e-06, 'rewards/chosen': -1.1185864210128784, 'rewards/rejected': -1.7618348598480225, 'rewards/accuracies': 0.7710937261581421, 'rewards/margins': 0.6432483196258545, 'logps/rejected': -77.92417907714844, 'logps/chosen': -70.88969421386719, 'logits/rejected': -32.1507568359375, 'logits/chosen': -32.02055358886719, 'epoch': 1.39}\n{'loss': 0.5299, 'grad_norm': 2.2126245498657227, 'learning_rate': 2e-06, 'rewards/chosen': -1.0966802835464478, 'rewards/rejected': -1.7318683862686157, 'rewards/accuracies': 0.735156238079071, 'rewards/margins': 0.6351878046989441, 'logps/rejected': -77.16633605957031, 'logps/chosen': -71.32648468017578, 'logits/rejected': -32.5526237487793, 'logits/chosen': -31.64754295349121, 'epoch': 1.4}\n{'loss': 0.5196, 'grad_norm': 2.2226765155792236, 'learning_rate': 2e-06, 'rewards/chosen': -1.1116334199905396, 'rewards/rejected': -1.7633002996444702, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.6516668200492859, 'logps/rejected': -78.101318359375, 'logps/chosen': -70.40792846679688, 'logits/rejected': -32.59789276123047, 'logits/chosen': -32.383785247802734, 'epoch': 1.41}\n{'loss': 0.5217, 'grad_norm': 2.0014030933380127, 'learning_rate': 2e-06, 'rewards/chosen': -1.1184570789337158, 'rewards/rejected': -1.781853437423706, 'rewards/accuracies': 0.746874988079071, 'rewards/margins': 0.6633962392807007, 'logps/rejected': -77.57430267333984, 'logps/chosen': -70.92454528808594, 'logits/rejected': -32.22393798828125, 'logits/chosen': -32.037742614746094, 'epoch': 1.42}\n{'loss': 0.5217, 'grad_norm': 2.05979323387146, 'learning_rate': 2e-06, 'rewards/chosen': -1.1514798402786255, 'rewards/rejected': -1.8134466409683228, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.661966860294342, 'logps/rejected': -78.63086700439453, 'logps/chosen': -71.61863708496094, 'logits/rejected': -32.41890335083008, 'logits/chosen': -32.512672424316406, 'epoch': 1.42}\n{'loss': 0.5177, 'grad_norm': 1.9978859424591064, 'learning_rate': 2e-06, 'rewards/chosen': -1.1288604736328125, 'rewards/rejected': -1.7829784154891968, 'rewards/accuracies': 0.7406250238418579, 'rewards/margins': 0.6541181802749634, 'logps/rejected': -78.15412139892578, 'logps/chosen': -71.08097076416016, 'logits/rejected': -32.46179962158203, 'logits/chosen': -31.935565948486328, 'epoch': 1.43}\n{'loss': 0.5147, 'grad_norm': 2.073995351791382, 'learning_rate': 2e-06, 'rewards/chosen': -1.143061637878418, 'rewards/rejected': -1.7931139469146729, 'rewards/accuracies': 0.75390625, 'rewards/margins': 0.6500522494316101, 'logps/rejected': -78.82566833496094, 'logps/chosen': -71.80445861816406, 'logits/rejected': -32.66421127319336, 'logits/chosen': -32.37599182128906, 'epoch': 1.44}\n{'loss': 0.5288, 'grad_norm': 2.106478214263916, 'learning_rate': 2e-06, 'rewards/chosen': -1.148629903793335, 'rewards/rejected': -1.7704569101333618, 'rewards/accuracies': 0.749218761920929, 'rewards/margins': 0.6218269467353821, 'logps/rejected': -78.20797729492188, 'logps/chosen': -71.97013092041016, 'logits/rejected': -33.205589294433594, 'logits/chosen': -32.539363861083984, 'epoch': 1.45}\n{'loss': 0.516, 'grad_norm': 1.8860386610031128, 'learning_rate': 2e-06, 'rewards/chosen': -1.1724252700805664, 'rewards/rejected': -1.8479512929916382, 'rewards/accuracies': 0.7476562261581421, 'rewards/margins': 0.6755260825157166, 'logps/rejected': -78.67220306396484, 'logps/chosen': -71.4179916381836, 'logits/rejected': -31.803234100341797, 'logits/chosen': -32.20981216430664, 'epoch': 1.46}\n{'loss': 0.509, 'grad_norm': 1.9636577367782593, 'learning_rate': 2e-06, 'rewards/chosen': -1.1449415683746338, 'rewards/rejected': -1.8387924432754517, 'rewards/accuracies': 0.73828125, 'rewards/margins': 0.6938508749008179, 'logps/rejected': -78.8086929321289, 'logps/chosen': -71.47309875488281, 'logits/rejected': -31.854400634765625, 'logits/chosen': -31.45549964904785, 'epoch': 1.47}\n{'loss': 0.5351, 'grad_norm': 2.1665852069854736, 'learning_rate': 2e-06, 'rewards/chosen': -1.1982276439666748, 'rewards/rejected': -1.8221919536590576, 'rewards/accuracies': 0.734375, 'rewards/margins': 0.6239641904830933, 'logps/rejected': -78.6844711303711, 'logps/chosen': -71.80996704101562, 'logits/rejected': -31.775104522705078, 'logits/chosen': -31.749439239501953, 'epoch': 1.48}\n{'loss': 0.4994, 'grad_norm': 1.8958323001861572, 'learning_rate': 2e-06, 'rewards/chosen': -1.1463027000427246, 'rewards/rejected': -1.8640882968902588, 'rewards/accuracies': 0.764843761920929, 'rewards/margins': 0.7177855372428894, 'logps/rejected': -79.18475341796875, 'logps/chosen': -71.89082336425781, 'logits/rejected': -32.22596740722656, 'logits/chosen': -31.899311065673828, 'epoch': 1.49}\n{'loss': 0.5069, 'grad_norm': 2.091376781463623, 'learning_rate': 2e-06, 'rewards/chosen': -1.1295047998428345, 'rewards/rejected': -1.8319936990737915, 'rewards/accuracies': 0.758593738079071, 'rewards/margins': 0.7024887800216675, 'logps/rejected': -79.33329772949219, 'logps/chosen': -71.10560607910156, 'logits/rejected': -31.894983291625977, 'logits/chosen': -32.12749481201172, 'epoch': 1.5}\n{'loss': 0.5312, 'grad_norm': 1.9909863471984863, 'learning_rate': 2e-06, 'rewards/chosen': -1.1886342763900757, 'rewards/rejected': -1.837680459022522, 'rewards/accuracies': 0.73046875, 'rewards/margins': 0.6490461230278015, 'logps/rejected': -79.08892059326172, 'logps/chosen': -71.18687438964844, 'logits/rejected': -31.474273681640625, 'logits/chosen': -31.514623641967773, 'epoch': 1.51}\n{'loss': 0.5485, 'grad_norm': 2.0712196826934814, 'learning_rate': 2e-06, 'rewards/chosen': -1.174446702003479, 'rewards/rejected': -1.7722256183624268, 'rewards/accuracies': 0.733593761920929, 'rewards/margins': 0.5977790951728821, 'logps/rejected': -77.67532348632812, 'logps/chosen': -71.80110168457031, 'logits/rejected': -31.894357681274414, 'logits/chosen': -32.44871139526367, 'epoch': 1.51}\n{'loss': 0.5392, 'grad_norm': 2.17521595954895, 'learning_rate': 2e-06, 'rewards/chosen': -1.2096937894821167, 'rewards/rejected': -1.8217971324920654, 'rewards/accuracies': 0.717968761920929, 'rewards/margins': 0.612103283405304, 'logps/rejected': -78.55705261230469, 'logps/chosen': -72.34752655029297, 'logits/rejected': -32.215980529785156, 'logits/chosen': -32.08793258666992, 'epoch': 1.52}\n{'loss': 0.5181, 'grad_norm': 1.9864922761917114, 'learning_rate': 2e-06, 'rewards/chosen': -1.1614930629730225, 'rewards/rejected': -1.8318374156951904, 'rewards/accuracies': 0.7445312738418579, 'rewards/margins': 0.6703444719314575, 'logps/rejected': -78.36259460449219, 'logps/chosen': -71.49526977539062, 'logits/rejected': -32.53619384765625, 'logits/chosen': -32.10715866088867, 'epoch': 1.53}\n{'loss': 0.5107, 'grad_norm': 2.1700544357299805, 'learning_rate': 2e-06, 'rewards/chosen': -1.1615712642669678, 'rewards/rejected': -1.8487030267715454, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.6871317625045776, 'logps/rejected': -79.17801666259766, 'logps/chosen': -71.82069396972656, 'logits/rejected': -32.135860443115234, 'logits/chosen': -31.859094619750977, 'epoch': 1.54}\n{'loss': 0.5182, 'grad_norm': 2.083146810531616, 'learning_rate': 2e-06, 'rewards/chosen': -1.1557471752166748, 'rewards/rejected': -1.8228447437286377, 'rewards/accuracies': 0.7578125, 'rewards/margins': 0.6670976877212524, 'logps/rejected': -78.7076644897461, 'logps/chosen': -71.7503433227539, 'logits/rejected': -31.899566650390625, 'logits/chosen': -31.967426300048828, 'epoch': 1.55}\n{'loss': 0.5038, 'grad_norm': 2.017179489135742, 'learning_rate': 2e-06, 'rewards/chosen': -1.1727795600891113, 'rewards/rejected': -1.881058931350708, 'rewards/accuracies': 0.76953125, 'rewards/margins': 0.7082793712615967, 'logps/rejected': -79.31209564208984, 'logps/chosen': -72.3440933227539, 'logits/rejected': -31.485153198242188, 'logits/chosen': -31.62628746032715, 'epoch': 1.56}\n{'loss': 0.5263, 'grad_norm': 2.1359305381774902, 'learning_rate': 2e-06, 'rewards/chosen': -1.1973296403884888, 'rewards/rejected': -1.8298145532608032, 'rewards/accuracies': 0.74609375, 'rewards/margins': 0.632485032081604, 'logps/rejected': -78.89762115478516, 'logps/chosen': -71.93818664550781, 'logits/rejected': -31.45009994506836, 'logits/chosen': -31.56830406188965, 'epoch': 1.57}\n{'loss': 0.5071, 'grad_norm': 2.180647611618042, 'learning_rate': 2e-06, 'rewards/chosen': -1.1989480257034302, 'rewards/rejected': -1.9027067422866821, 'rewards/accuracies': 0.749218761920929, 'rewards/margins': 0.703758955001831, 'logps/rejected': -79.23821258544922, 'logps/chosen': -71.94036865234375, 'logits/rejected': -32.26277542114258, 'logits/chosen': -32.10224151611328, 'epoch': 1.58}\n{'loss': 0.5217, 'grad_norm': 2.4492249488830566, 'learning_rate': 2e-06, 'rewards/chosen': -1.2341718673706055, 'rewards/rejected': -1.917201042175293, 'rewards/accuracies': 0.742968738079071, 'rewards/margins': 0.6830289959907532, 'logps/rejected': -79.92031860351562, 'logps/chosen': -73.04376983642578, 'logits/rejected': -31.392894744873047, 'logits/chosen': -31.182825088500977, 'epoch': 1.59}\n{'loss': 0.5154, 'grad_norm': 2.2260076999664307, 'learning_rate': 2e-06, 'rewards/chosen': -1.221624732017517, 'rewards/rejected': -1.9202814102172852, 'rewards/accuracies': 0.7367187738418579, 'rewards/margins': 0.6986569166183472, 'logps/rejected': -80.15705871582031, 'logps/chosen': -72.37397766113281, 'logits/rejected': -31.68459701538086, 'logits/chosen': -31.78595542907715, 'epoch': 1.6}\n{'loss': 0.5159, 'grad_norm': 1.9746289253234863, 'learning_rate': 2e-06, 'rewards/chosen': -1.176999807357788, 'rewards/rejected': -1.8626762628555298, 'rewards/accuracies': 0.7484375238418579, 'rewards/margins': 0.6856763958930969, 'logps/rejected': -78.77810668945312, 'logps/chosen': -72.05958557128906, 'logits/rejected': -31.95792579650879, 'logits/chosen': -31.86653709411621, 'epoch': 1.61}\n{'loss': 0.5164, 'grad_norm': 2.1030995845794678, 'learning_rate': 2e-06, 'rewards/chosen': -1.2425779104232788, 'rewards/rejected': -1.9283874034881592, 'rewards/accuracies': 0.74609375, 'rewards/margins': 0.6858096718788147, 'logps/rejected': -79.40848541259766, 'logps/chosen': -72.82620239257812, 'logits/rejected': -32.02655792236328, 'logits/chosen': -31.805133819580078, 'epoch': 1.61}\n{'loss': 0.5424, 'grad_norm': 2.0251619815826416, 'learning_rate': 2e-06, 'rewards/chosen': -1.273086667060852, 'rewards/rejected': -1.8912858963012695, 'rewards/accuracies': 0.729687511920929, 'rewards/margins': 0.618199348449707, 'logps/rejected': -79.3201904296875, 'logps/chosen': -73.7159423828125, 'logits/rejected': -31.560115814208984, 'logits/chosen': -31.972763061523438, 'epoch': 1.62}\n{'loss': 0.5193, 'grad_norm': 1.874213695526123, 'learning_rate': 2e-06, 'rewards/chosen': -1.2334816455841064, 'rewards/rejected': -1.9359248876571655, 'rewards/accuracies': 0.745312511920929, 'rewards/margins': 0.7024434208869934, 'logps/rejected': -80.01030731201172, 'logps/chosen': -72.43565368652344, 'logits/rejected': -31.99448013305664, 'logits/chosen': -31.586002349853516, 'epoch': 1.63}\n{'loss': 0.5238, 'grad_norm': 1.9989033937454224, 'learning_rate': 2e-06, 'rewards/chosen': -1.2216590642929077, 'rewards/rejected': -1.905816674232483, 'rewards/accuracies': 0.7421875, 'rewards/margins': 0.6841573119163513, 'logps/rejected': -79.6276626586914, 'logps/chosen': -72.43974304199219, 'logits/rejected': -31.379314422607422, 'logits/chosen': -31.078113555908203, 'epoch': 1.64}\n{'loss': 0.5268, 'grad_norm': 2.192072629928589, 'learning_rate': 2e-06, 'rewards/chosen': -1.2228639125823975, 'rewards/rejected': -1.884521484375, 'rewards/accuracies': 0.74609375, 'rewards/margins': 0.661657452583313, 'logps/rejected': -80.43700408935547, 'logps/chosen': -71.56422424316406, 'logits/rejected': -31.376134872436523, 'logits/chosen': -32.029747009277344, 'epoch': 1.65}\n{'loss': 0.5173, 'grad_norm': 2.1288087368011475, 'learning_rate': 2e-06, 'rewards/chosen': -1.2179806232452393, 'rewards/rejected': -1.9027557373046875, 'rewards/accuracies': 0.7476562261581421, 'rewards/margins': 0.684775173664093, 'logps/rejected': -79.41650390625, 'logps/chosen': -72.1264877319336, 'logits/rejected': -31.299270629882812, 'logits/chosen': -31.373088836669922, 'epoch': 1.66}\n{'loss': 0.5181, 'grad_norm': 2.269564390182495, 'learning_rate': 2e-06, 'rewards/chosen': -1.2406965494155884, 'rewards/rejected': -1.9309879541397095, 'rewards/accuracies': 0.7523437738418579, 'rewards/margins': 0.6902912855148315, 'logps/rejected': -79.84545135498047, 'logps/chosen': -73.41143035888672, 'logits/rejected': -31.877981185913086, 'logits/chosen': -31.619003295898438, 'epoch': 1.67}\n{'loss': 0.5183, 'grad_norm': 2.1883363723754883, 'learning_rate': 2e-06, 'rewards/chosen': -1.2318992614746094, 'rewards/rejected': -1.9218637943267822, 'rewards/accuracies': 0.7421875, 'rewards/margins': 0.6899644136428833, 'logps/rejected': -79.98242950439453, 'logps/chosen': -72.8156509399414, 'logits/rejected': -31.735363006591797, 'logits/chosen': -31.784137725830078, 'epoch': 1.68}\n{'loss': 0.52, 'grad_norm': 2.2644717693328857, 'learning_rate': 2e-06, 'rewards/chosen': -1.2400281429290771, 'rewards/rejected': -1.9137033224105835, 'rewards/accuracies': 0.757031261920929, 'rewards/margins': 0.6736751794815063, 'logps/rejected': -79.61475372314453, 'logps/chosen': -72.3553237915039, 'logits/rejected': -31.3570613861084, 'logits/chosen': -31.44057846069336, 'epoch': 1.69}\n{'loss': 0.5294, 'grad_norm': 2.1653518676757812, 'learning_rate': 2e-06, 'rewards/chosen': -1.2749167680740356, 'rewards/rejected': -1.9329912662506104, 'rewards/accuracies': 0.7484375238418579, 'rewards/margins': 0.6580743789672852, 'logps/rejected': -79.89710998535156, 'logps/chosen': -72.86735534667969, 'logits/rejected': -32.282615661621094, 'logits/chosen': -32.429222106933594, 'epoch': 1.7}\n{'loss': 0.5217, 'grad_norm': 2.002089262008667, 'learning_rate': 2e-06, 'rewards/chosen': -1.2431254386901855, 'rewards/rejected': -1.9327633380889893, 'rewards/accuracies': 0.741406261920929, 'rewards/margins': 0.6896376609802246, 'logps/rejected': -80.49266815185547, 'logps/chosen': -72.64248657226562, 'logits/rejected': -32.16172790527344, 'logits/chosen': -32.373985290527344, 'epoch': 1.7}\n{'loss': 0.5214, 'grad_norm': 2.2291064262390137, 'learning_rate': 2e-06, 'rewards/chosen': -1.2725211381912231, 'rewards/rejected': -1.9487955570220947, 'rewards/accuracies': 0.735156238079071, 'rewards/margins': 0.6762741804122925, 'logps/rejected': -79.39476013183594, 'logps/chosen': -73.30303192138672, 'logits/rejected': -32.4875373840332, 'logits/chosen': -32.04781723022461, 'epoch': 1.71}\n{'loss': 0.5241, 'grad_norm': 2.0148487091064453, 'learning_rate': 2e-06, 'rewards/chosen': -1.256468415260315, 'rewards/rejected': -1.948786973953247, 'rewards/accuracies': 0.7359374761581421, 'rewards/margins': 0.6923184394836426, 'logps/rejected': -79.28330993652344, 'logps/chosen': -72.2749252319336, 'logits/rejected': -32.241363525390625, 'logits/chosen': -32.59447479248047, 'epoch': 1.72}\n{'loss': 0.5327, 'grad_norm': 2.229489803314209, 'learning_rate': 2e-06, 'rewards/chosen': -1.244378924369812, 'rewards/rejected': -1.887036919593811, 'rewards/accuracies': 0.741406261920929, 'rewards/margins': 0.6426580548286438, 'logps/rejected': -79.09019470214844, 'logps/chosen': -73.16703796386719, 'logits/rejected': -32.49485397338867, 'logits/chosen': -32.4644660949707, 'epoch': 1.73}\n{'loss': 0.5238, 'grad_norm': 2.0568618774414062, 'learning_rate': 2e-06, 'rewards/chosen': -1.2260560989379883, 'rewards/rejected': -1.9130446910858154, 'rewards/accuracies': 0.725781261920929, 'rewards/margins': 0.6869888305664062, 'logps/rejected': -79.875732421875, 'logps/chosen': -72.58515930175781, 'logits/rejected': -32.07577133178711, 'logits/chosen': -32.446903228759766, 'epoch': 1.74}\n{'loss': 0.5399, 'grad_norm': 1.9522267580032349, 'learning_rate': 2e-06, 'rewards/chosen': -1.2506630420684814, 'rewards/rejected': -1.888780951499939, 'rewards/accuracies': 0.741406261920929, 'rewards/margins': 0.6381180882453918, 'logps/rejected': -80.02388000488281, 'logps/chosen': -72.69075012207031, 'logits/rejected': -31.190332412719727, 'logits/chosen': -31.775089263916016, 'epoch': 1.75}\n{'loss': 0.491, 'grad_norm': 1.8648934364318848, 'learning_rate': 2e-06, 'rewards/chosen': -1.2069413661956787, 'rewards/rejected': -1.9442784786224365, 'rewards/accuracies': 0.765625, 'rewards/margins': 0.7373371720314026, 'logps/rejected': -80.05287170410156, 'logps/chosen': -72.16959381103516, 'logits/rejected': -32.17365646362305, 'logits/chosen': -32.22467803955078, 'epoch': 1.76}\n{'loss': 0.5183, 'grad_norm': 2.272251605987549, 'learning_rate': 2e-06, 'rewards/chosen': -1.2162526845932007, 'rewards/rejected': -1.9074270725250244, 'rewards/accuracies': 0.750781238079071, 'rewards/margins': 0.6911742687225342, 'logps/rejected': -80.38812255859375, 'logps/chosen': -72.48119354248047, 'logits/rejected': -32.522377014160156, 'logits/chosen': -32.63343048095703, 'epoch': 1.77}\n{'loss': 0.4977, 'grad_norm': 1.9945119619369507, 'learning_rate': 2e-06, 'rewards/chosen': -1.2083240747451782, 'rewards/rejected': -1.951312780380249, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.7429887056350708, 'logps/rejected': -80.16486358642578, 'logps/chosen': -72.03565979003906, 'logits/rejected': -32.082725524902344, 'logits/chosen': -31.818557739257812, 'epoch': 1.78}\n{'loss': 0.5226, 'grad_norm': 2.1383981704711914, 'learning_rate': 2e-06, 'rewards/chosen': -1.2604336738586426, 'rewards/rejected': -1.9244804382324219, 'rewards/accuracies': 0.74609375, 'rewards/margins': 0.6640466451644897, 'logps/rejected': -80.7152328491211, 'logps/chosen': -72.80238342285156, 'logits/rejected': -32.087066650390625, 'logits/chosen': -32.27346420288086, 'epoch': 1.79}\n{'loss': 0.5149, 'grad_norm': 2.0311224460601807, 'learning_rate': 2e-06, 'rewards/chosen': -1.2744033336639404, 'rewards/rejected': -1.9926567077636719, 'rewards/accuracies': 0.733593761920929, 'rewards/margins': 0.7182534337043762, 'logps/rejected': -80.21385192871094, 'logps/chosen': -72.89192199707031, 'logits/rejected': -32.328826904296875, 'logits/chosen': -31.75006675720215, 'epoch': 1.79}\n{'loss': 0.5354, 'grad_norm': 2.1499392986297607, 'learning_rate': 2e-06, 'rewards/chosen': -1.2669594287872314, 'rewards/rejected': -1.9143937826156616, 'rewards/accuracies': 0.741406261920929, 'rewards/margins': 0.6474343538284302, 'logps/rejected': -79.86201477050781, 'logps/chosen': -72.98514556884766, 'logits/rejected': -31.97176170349121, 'logits/chosen': -31.4659481048584, 'epoch': 1.8}\n{'loss': 0.5133, 'grad_norm': 2.244732618331909, 'learning_rate': 2e-06, 'rewards/chosen': -1.2833077907562256, 'rewards/rejected': -2.0015876293182373, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.7182798385620117, 'logps/rejected': -80.20457458496094, 'logps/chosen': -73.06229400634766, 'logits/rejected': -32.62544631958008, 'logits/chosen': -32.31911849975586, 'epoch': 1.81}\n{'loss': 0.513, 'grad_norm': 2.0399346351623535, 'learning_rate': 2e-06, 'rewards/chosen': -1.2555898427963257, 'rewards/rejected': -1.9679756164550781, 'rewards/accuracies': 0.757031261920929, 'rewards/margins': 0.7123861312866211, 'logps/rejected': -79.41835021972656, 'logps/chosen': -72.23866271972656, 'logits/rejected': -32.883663177490234, 'logits/chosen': -32.570404052734375, 'epoch': 1.82}\n{'loss': 0.5093, 'grad_norm': 2.264348030090332, 'learning_rate': 2e-06, 'rewards/chosen': -1.2642669677734375, 'rewards/rejected': -1.9944175481796265, 'rewards/accuracies': 0.750781238079071, 'rewards/margins': 0.7301506400108337, 'logps/rejected': -80.02162170410156, 'logps/chosen': -72.13356018066406, 'logits/rejected': -32.168174743652344, 'logits/chosen': -32.29535675048828, 'epoch': 1.83}\n{'loss': 0.5139, 'grad_norm': 2.2751102447509766, 'learning_rate': 2e-06, 'rewards/chosen': -1.288041353225708, 'rewards/rejected': -2.0057015419006348, 'rewards/accuracies': 0.746874988079071, 'rewards/margins': 0.7176604866981506, 'logps/rejected': -80.16960144042969, 'logps/chosen': -73.20069122314453, 'logits/rejected': -32.0692024230957, 'logits/chosen': -31.962749481201172, 'epoch': 1.84}\n{'loss': 0.521, 'grad_norm': 2.260390520095825, 'learning_rate': 2e-06, 'rewards/chosen': -1.2834651470184326, 'rewards/rejected': -1.9765546321868896, 'rewards/accuracies': 0.745312511920929, 'rewards/margins': 0.6930897235870361, 'logps/rejected': -79.58755493164062, 'logps/chosen': -73.4111328125, 'logits/rejected': -32.29948043823242, 'logits/chosen': -32.55017852783203, 'epoch': 1.85}\n{'loss': 0.5092, 'grad_norm': 2.1258273124694824, 'learning_rate': 2e-06, 'rewards/chosen': -1.2565536499023438, 'rewards/rejected': -1.9994094371795654, 'rewards/accuracies': 0.7484375238418579, 'rewards/margins': 0.742855966091156, 'logps/rejected': -80.23263549804688, 'logps/chosen': -72.71964263916016, 'logits/rejected': -32.660823822021484, 'logits/chosen': -32.804161071777344, 'epoch': 1.86}\n{'loss': 0.4791, 'grad_norm': 1.7903430461883545, 'learning_rate': 2e-06, 'rewards/chosen': -1.2348610162734985, 'rewards/rejected': -2.0261504650115967, 'rewards/accuracies': 0.789843738079071, 'rewards/margins': 0.7912896275520325, 'logps/rejected': -80.84215545654297, 'logps/chosen': -72.3481674194336, 'logits/rejected': -31.358652114868164, 'logits/chosen': -31.768590927124023, 'epoch': 1.87}\n{'loss': 0.518, 'grad_norm': 2.0492260456085205, 'learning_rate': 2e-06, 'rewards/chosen': -1.2781295776367188, 'rewards/rejected': -1.9673902988433838, 'rewards/accuracies': 0.745312511920929, 'rewards/margins': 0.6892610192298889, 'logps/rejected': -80.77693176269531, 'logps/chosen': -72.59673309326172, 'logits/rejected': -32.0350341796875, 'logits/chosen': -31.980005264282227, 'epoch': 1.88}\n{'loss': 0.5082, 'grad_norm': 2.090615749359131, 'learning_rate': 2e-06, 'rewards/chosen': -1.3104465007781982, 'rewards/rejected': -2.0417423248291016, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.7312957048416138, 'logps/rejected': -81.3422622680664, 'logps/chosen': -73.63407897949219, 'logits/rejected': -32.663169860839844, 'logits/chosen': -32.07855224609375, 'epoch': 1.88}\n{'loss': 0.5235, 'grad_norm': 2.130509853363037, 'learning_rate': 2e-06, 'rewards/chosen': -1.3141833543777466, 'rewards/rejected': -2.009295701980591, 'rewards/accuracies': 0.7367187738418579, 'rewards/margins': 0.6951121687889099, 'logps/rejected': -80.95928955078125, 'logps/chosen': -73.94428253173828, 'logits/rejected': -32.215755462646484, 'logits/chosen': -32.57520294189453, 'epoch': 1.89}\n{'loss': 0.5027, 'grad_norm': 2.1532113552093506, 'learning_rate': 2e-06, 'rewards/chosen': -1.2708501815795898, 'rewards/rejected': -2.0053839683532715, 'rewards/accuracies': 0.758593738079071, 'rewards/margins': 0.7345338463783264, 'logps/rejected': -80.95335388183594, 'logps/chosen': -73.43475341796875, 'logits/rejected': -32.37833023071289, 'logits/chosen': -31.8893985748291, 'epoch': 1.9}\n{'loss': 0.5359, 'grad_norm': 2.186810255050659, 'learning_rate': 2e-06, 'rewards/chosen': -1.3442078828811646, 'rewards/rejected': -1.991769790649414, 'rewards/accuracies': 0.741406261920929, 'rewards/margins': 0.6475622057914734, 'logps/rejected': -81.00511169433594, 'logps/chosen': -74.09627532958984, 'logits/rejected': -31.711685180664062, 'logits/chosen': -32.107818603515625, 'epoch': 1.91}\n{'loss': 0.5045, 'grad_norm': 2.2465832233428955, 'learning_rate': 2e-06, 'rewards/chosen': -1.323346495628357, 'rewards/rejected': -2.0659117698669434, 'rewards/accuracies': 0.750781238079071, 'rewards/margins': 0.7425654530525208, 'logps/rejected': -81.00205993652344, 'logps/chosen': -73.30302429199219, 'logits/rejected': -32.52919006347656, 'logits/chosen': -32.594783782958984, 'epoch': 1.92}\n{'loss': 0.5027, 'grad_norm': 2.176471471786499, 'learning_rate': 2e-06, 'rewards/chosen': -1.318509817123413, 'rewards/rejected': -2.079899549484253, 'rewards/accuracies': 0.754687488079071, 'rewards/margins': 0.7613897323608398, 'logps/rejected': -81.07426452636719, 'logps/chosen': -73.30165100097656, 'logits/rejected': -31.744735717773438, 'logits/chosen': -32.0186767578125, 'epoch': 1.93}\n{'loss': 0.517, 'grad_norm': 2.2150704860687256, 'learning_rate': 2e-06, 'rewards/chosen': -1.3292720317840576, 'rewards/rejected': -2.045042037963867, 'rewards/accuracies': 0.758593738079071, 'rewards/margins': 0.7157699465751648, 'logps/rejected': -80.71443939208984, 'logps/chosen': -73.63195037841797, 'logits/rejected': -31.795528411865234, 'logits/chosen': -31.845062255859375, 'epoch': 1.94}\n{'loss': 0.5068, 'grad_norm': 2.152101755142212, 'learning_rate': 2e-06, 'rewards/chosen': -1.329578161239624, 'rewards/rejected': -2.0517945289611816, 'rewards/accuracies': 0.765625, 'rewards/margins': 0.7222161889076233, 'logps/rejected': -80.82139587402344, 'logps/chosen': -72.91338348388672, 'logits/rejected': -32.094337463378906, 'logits/chosen': -31.97103500366211, 'epoch': 1.95}\n{'loss': 0.481, 'grad_norm': 2.047335147857666, 'learning_rate': 2e-06, 'rewards/chosen': -1.277409315109253, 'rewards/rejected': -2.1211016178131104, 'rewards/accuracies': 0.76953125, 'rewards/margins': 0.8436921238899231, 'logps/rejected': -81.95289611816406, 'logps/chosen': -72.2953872680664, 'logits/rejected': -31.8929386138916, 'logits/chosen': -32.01642608642578, 'epoch': 1.96}\n{'loss': 0.5039, 'grad_norm': 2.0374417304992676, 'learning_rate': 2e-06, 'rewards/chosen': -1.3346426486968994, 'rewards/rejected': -2.096560478210449, 'rewards/accuracies': 0.749218761920929, 'rewards/margins': 0.761917769908905, 'logps/rejected': -81.57331848144531, 'logps/chosen': -74.54503631591797, 'logits/rejected': -32.28440475463867, 'logits/chosen': -31.8885440826416, 'epoch': 1.97}\n{'loss': 0.5221, 'grad_norm': 2.084047317504883, 'learning_rate': 2e-06, 'rewards/chosen': -1.3480217456817627, 'rewards/rejected': -2.073392152786255, 'rewards/accuracies': 0.7328125238418579, 'rewards/margins': 0.7253702878952026, 'logps/rejected': -80.38023376464844, 'logps/chosen': -74.0570068359375, 'logits/rejected': -32.688072204589844, 'logits/chosen': -32.0830192565918, 'epoch': 1.97}\n{'loss': 0.5186, 'grad_norm': 2.1383039951324463, 'learning_rate': 2e-06, 'rewards/chosen': -1.350987195968628, 'rewards/rejected': -2.083225727081299, 'rewards/accuracies': 0.7445312738418579, 'rewards/margins': 0.7322381734848022, 'logps/rejected': -81.2284927368164, 'logps/chosen': -74.36888885498047, 'logits/rejected': -31.905956268310547, 'logits/chosen': -32.42322540283203, 'epoch': 1.98}\n{'loss': 0.5142, 'grad_norm': 2.3201253414154053, 'learning_rate': 2e-06, 'rewards/chosen': -1.3174644708633423, 'rewards/rejected': -2.081676721572876, 'rewards/accuracies': 0.739062488079071, 'rewards/margins': 0.7642122507095337, 'logps/rejected': -80.83638763427734, 'logps/chosen': -73.20442199707031, 'logits/rejected': -31.92291259765625, 'logits/chosen': -32.4843864440918, 'epoch': 1.99}\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 2218/3327 [46:00<19:47,  1.07s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|‚ñà‚ñç                                          | 2/59 [00:00<00:15,  3.65it/s]\u001b[A\n  5%|‚ñà‚ñà‚ñè                                         | 3/59 [00:01<00:21,  2.58it/s]\u001b[A\n  7%|‚ñà‚ñà‚ñâ                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|‚ñà‚ñà‚ñà‚ñã                                        | 5/59 [00:02<00:26,  2.04it/s]\u001b[A\n 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 6/59 [00:02<00:26,  1.97it/s]\u001b[A\n 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 7/59 [00:03<00:27,  1.92it/s]\u001b[A\n 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 8/59 [00:03<00:26,  1.89it/s]\u001b[A\n 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 9/59 [00:04<00:26,  1.86it/s]\u001b[A\n 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 11/59 [00:05<00:26,  1.84it/s]\u001b[A\n 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 12/59 [00:06<00:25,  1.84it/s]\u001b[A\n 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 13/59 [00:06<00:25,  1.83it/s]\u001b[A\n 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 14/59 [00:07<00:25,  1.80it/s]\u001b[A\n 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 16/59 [00:08<00:23,  1.81it/s]\u001b[A\n 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 17/59 [00:08<00:23,  1.81it/s]\u001b[A\n 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 18/59 [00:09<00:22,  1.82it/s]\u001b[A\n 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 19/59 [00:09<00:21,  1.82it/s]\u001b[A\n 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 21/59 [00:11<00:20,  1.82it/s]\u001b[A\n 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 23/59 [00:12<00:19,  1.82it/s]\u001b[A\n 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 24/59 [00:12<00:19,  1.82it/s]\u001b[A\n 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 25/59 [00:13<00:18,  1.82it/s]\u001b[A\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 26/59 [00:13<00:18,  1.82it/s]\u001b[A\n 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 27/59 [00:14<00:17,  1.82it/s]\u001b[A\n 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 28/59 [00:14<00:17,  1.82it/s]\u001b[A\n 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 29/59 [00:15<00:16,  1.82it/s]\u001b[A\n 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 30/59 [00:15<00:15,  1.82it/s]\u001b[A\n 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 31/59 [00:16<00:15,  1.82it/s]\u001b[A\n 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 32/59 [00:17<00:14,  1.82it/s]\u001b[A\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 33/59 [00:17<00:14,  1.79it/s]\u001b[A\n 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 34/59 [00:18<00:13,  1.79it/s]\u001b[A\n 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 35/59 [00:18<00:13,  1.80it/s]\u001b[A\n 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 36/59 [00:19<00:12,  1.81it/s]\u001b[A\n 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 37/59 [00:19<00:12,  1.81it/s]\u001b[A\n 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 39/59 [00:20<00:10,  1.82it/s]\u001b[A\n 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 41/59 [00:22<00:10,  1.80it/s]\u001b[A\n 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 42/59 [00:22<00:09,  1.81it/s]\u001b[A\n 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 44/59 [00:23<00:08,  1.82it/s]\u001b[A\n 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 45/59 [00:24<00:07,  1.79it/s]\u001b[A\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 47/59 [00:25<00:06,  1.81it/s]\u001b[A\n 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 48/59 [00:25<00:06,  1.79it/s]\u001b[A\n 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 50/59 [00:27<00:04,  1.81it/s]\u001b[A\n 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 52/59 [00:28<00:03,  1.81it/s]\u001b[A\n 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 53/59 [00:28<00:03,  1.59it/s]\u001b[A\n 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 54/59 [00:29<00:03,  1.63it/s]\u001b[A\n 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 55/59 [00:30<00:02,  1.66it/s]\u001b[A\n 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 56/59 [00:30<00:01,  1.68it/s]\u001b[A\n 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 57/59 [00:31<00:01,  1.70it/s]\u001b[A\n 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 58/59 [00:31<00:00,  1.73it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5187075138092041, 'eval_runtime': 32.6304, 'eval_samples_per_second': 228.897, 'eval_steps_per_second': 1.808, 'eval_rewards/chosen': -1.319923758506775, 'eval_rewards/rejected': -2.0269277095794678, 'eval_rewards/accuracies': 0.7441766858100891, 'eval_rewards/margins': 0.7070038318634033, 'eval_logps/rejected': -80.5361328125, 'eval_logps/chosen': -73.16887664794922, 'eval_logits/rejected': -32.25386047363281, 'eval_logits/chosen': -32.33916091918945, 'epoch': 2.0}\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 2218/3327 [46:33<19:47,  1.07s/it]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59/59 [00:32<00:00,  2.16it/s]\u001b[A\n{'loss': 0.5116, 'grad_norm': 1.9279705286026, 'learning_rate': 2e-06, 'rewards/chosen': -1.3244435787200928, 'rewards/rejected': -2.067620038986206, 'rewards/accuracies': 0.7563108801841736, 'rewards/margins': 0.7431763410568237, 'logps/rejected': -81.0284194946289, 'logps/chosen': -74.23465728759766, 'logits/rejected': -32.37209701538086, 'logits/chosen': -32.51865768432617, 'epoch': 2.0}\n{'loss': 0.4991, 'grad_norm': 1.8928784132003784, 'learning_rate': 2e-06, 'rewards/chosen': -1.2566020488739014, 'rewards/rejected': -2.0008726119995117, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.7442706823348999, 'logps/rejected': -80.82757568359375, 'logps/chosen': -71.88941955566406, 'logits/rejected': -32.32042694091797, 'logits/chosen': -32.69539260864258, 'epoch': 2.01}\n{'loss': 0.5033, 'grad_norm': 2.0901522636413574, 'learning_rate': 2e-06, 'rewards/chosen': -1.3144118785858154, 'rewards/rejected': -2.0651259422302246, 'rewards/accuracies': 0.7578125, 'rewards/margins': 0.750714123249054, 'logps/rejected': -80.6810302734375, 'logps/chosen': -74.34660339355469, 'logits/rejected': -32.23505401611328, 'logits/chosen': -32.2502326965332, 'epoch': 2.02}\n{'loss': 0.5102, 'grad_norm': 2.0530107021331787, 'learning_rate': 2e-06, 'rewards/chosen': -1.286563515663147, 'rewards/rejected': -2.0151188373565674, 'rewards/accuracies': 0.7406250238418579, 'rewards/margins': 0.7285550832748413, 'logps/rejected': -80.49851989746094, 'logps/chosen': -72.7728271484375, 'logits/rejected': -32.349666595458984, 'logits/chosen': -32.257354736328125, 'epoch': 2.03}\n{'loss': 0.5016, 'grad_norm': 2.3254923820495605, 'learning_rate': 2e-06, 'rewards/chosen': -1.3376410007476807, 'rewards/rejected': -2.112438678741455, 'rewards/accuracies': 0.7593749761581421, 'rewards/margins': 0.7747979164123535, 'logps/rejected': -80.5414810180664, 'logps/chosen': -74.00050354003906, 'logits/rejected': -33.11786651611328, 'logits/chosen': -32.715824127197266, 'epoch': 2.04}\n{'loss': 0.5002, 'grad_norm': 2.2237188816070557, 'learning_rate': 2e-06, 'rewards/chosen': -1.3210004568099976, 'rewards/rejected': -2.0911803245544434, 'rewards/accuracies': 0.750781238079071, 'rewards/margins': 0.7701799869537354, 'logps/rejected': -80.9929428100586, 'logps/chosen': -73.73735046386719, 'logits/rejected': -32.42827224731445, 'logits/chosen': -32.30338668823242, 'epoch': 2.05}\n{'loss': 0.4873, 'grad_norm': 2.033874988555908, 'learning_rate': 2e-06, 'rewards/chosen': -1.2646501064300537, 'rewards/rejected': -2.054135322570801, 'rewards/accuracies': 0.7640625238418579, 'rewards/margins': 0.7894851565361023, 'logps/rejected': -81.16127014160156, 'logps/chosen': -73.33338928222656, 'logits/rejected': -32.636749267578125, 'logits/chosen': -32.34418487548828, 'epoch': 2.06}\n{'loss': 0.4917, 'grad_norm': 1.9685416221618652, 'learning_rate': 2e-06, 'rewards/chosen': -1.3085118532180786, 'rewards/rejected': -2.0852067470550537, 'rewards/accuracies': 0.757031261920929, 'rewards/margins': 0.7766950130462646, 'logps/rejected': -81.52777099609375, 'logps/chosen': -73.77763366699219, 'logits/rejected': -32.423160552978516, 'logits/chosen': -32.379295349121094, 'epoch': 2.06}\n{'loss': 0.5081, 'grad_norm': 2.0301012992858887, 'learning_rate': 2e-06, 'rewards/chosen': -1.3184876441955566, 'rewards/rejected': -2.0553061962127686, 'rewards/accuracies': 0.7421875, 'rewards/margins': 0.7368186116218567, 'logps/rejected': -80.96176147460938, 'logps/chosen': -73.79109191894531, 'logits/rejected': -32.71388626098633, 'logits/chosen': -32.16566467285156, 'epoch': 2.07}\n{'loss': 0.4937, 'grad_norm': 2.119344472885132, 'learning_rate': 2e-06, 'rewards/chosen': -1.289544939994812, 'rewards/rejected': -2.0743324756622314, 'rewards/accuracies': 0.76171875, 'rewards/margins': 0.7847875356674194, 'logps/rejected': -81.092041015625, 'logps/chosen': -72.90789794921875, 'logits/rejected': -31.8370361328125, 'logits/chosen': -32.33205795288086, 'epoch': 2.08}\n{'loss': 0.4804, 'grad_norm': 1.9882065057754517, 'learning_rate': 2e-06, 'rewards/chosen': -1.2977370023727417, 'rewards/rejected': -2.106390953063965, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.8086535334587097, 'logps/rejected': -81.2883529663086, 'logps/chosen': -73.2941665649414, 'logits/rejected': -32.088233947753906, 'logits/chosen': -31.87762451171875, 'epoch': 2.09}\n{'loss': 0.4887, 'grad_norm': 1.9404038190841675, 'learning_rate': 2e-06, 'rewards/chosen': -1.3111158609390259, 'rewards/rejected': -2.1144309043884277, 'rewards/accuracies': 0.77734375, 'rewards/margins': 0.8033150434494019, 'logps/rejected': -81.09736633300781, 'logps/chosen': -73.53059387207031, 'logits/rejected': -32.24317169189453, 'logits/chosen': -32.53155517578125, 'epoch': 2.1}\n{'loss': 0.4969, 'grad_norm': 1.9787201881408691, 'learning_rate': 2e-06, 'rewards/chosen': -1.310240626335144, 'rewards/rejected': -2.093862295150757, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.7836215496063232, 'logps/rejected': -81.5143814086914, 'logps/chosen': -73.54761505126953, 'logits/rejected': -32.31987380981445, 'logits/chosen': -32.835262298583984, 'epoch': 2.11}\n{'loss': 0.5049, 'grad_norm': 2.1603283882141113, 'learning_rate': 2e-06, 'rewards/chosen': -1.3596731424331665, 'rewards/rejected': -2.1101598739624023, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.7504866123199463, 'logps/rejected': -81.5713882446289, 'logps/chosen': -73.61714172363281, 'logits/rejected': -32.267845153808594, 'logits/chosen': -32.499549865722656, 'epoch': 2.12}\n{'loss': 0.4933, 'grad_norm': 2.1148340702056885, 'learning_rate': 2e-06, 'rewards/chosen': -1.3159735202789307, 'rewards/rejected': -2.1275203227996826, 'rewards/accuracies': 0.7679687738418579, 'rewards/margins': 0.8115466833114624, 'logps/rejected': -82.1469955444336, 'logps/chosen': -73.49534606933594, 'logits/rejected': -32.222877502441406, 'logits/chosen': -32.582969665527344, 'epoch': 2.13}\n{'loss': 0.4977, 'grad_norm': 1.9673627614974976, 'learning_rate': 2e-06, 'rewards/chosen': -1.3731616735458374, 'rewards/rejected': -2.1368298530578613, 'rewards/accuracies': 0.7515624761581421, 'rewards/margins': 0.7636682391166687, 'logps/rejected': -82.39584350585938, 'logps/chosen': -74.48768615722656, 'logits/rejected': -32.51917266845703, 'logits/chosen': -33.11363983154297, 'epoch': 2.14}\n{'loss': 0.4921, 'grad_norm': 2.0905299186706543, 'learning_rate': 2e-06, 'rewards/chosen': -1.3225665092468262, 'rewards/rejected': -2.1025681495666504, 'rewards/accuracies': 0.7757812738418579, 'rewards/margins': 0.7800015807151794, 'logps/rejected': -81.12930297851562, 'logps/chosen': -72.90129089355469, 'logits/rejected': -32.48399353027344, 'logits/chosen': -32.375816345214844, 'epoch': 2.15}\n{'loss': 0.4748, 'grad_norm': 2.0476491451263428, 'learning_rate': 2e-06, 'rewards/chosen': -1.3315298557281494, 'rewards/rejected': -2.184134006500244, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.8526040315628052, 'logps/rejected': -82.04774475097656, 'logps/chosen': -73.40177154541016, 'logits/rejected': -31.80376625061035, 'logits/chosen': -31.945898056030273, 'epoch': 2.16}\n{'loss': 0.5147, 'grad_norm': 2.0683019161224365, 'learning_rate': 2e-06, 'rewards/chosen': -1.3833374977111816, 'rewards/rejected': -2.117374897003174, 'rewards/accuracies': 0.7421875, 'rewards/margins': 0.7340372800827026, 'logps/rejected': -81.82555389404297, 'logps/chosen': -74.1531753540039, 'logits/rejected': -31.39166259765625, 'logits/chosen': -32.323307037353516, 'epoch': 2.16}\n{'loss': 0.5124, 'grad_norm': 2.1448416709899902, 'learning_rate': 2e-06, 'rewards/chosen': -1.4177576303482056, 'rewards/rejected': -2.167224884033203, 'rewards/accuracies': 0.753125011920929, 'rewards/margins': 0.7494672536849976, 'logps/rejected': -82.67390441894531, 'logps/chosen': -73.75666809082031, 'logits/rejected': -32.54949188232422, 'logits/chosen': -32.83562469482422, 'epoch': 2.17}\n{'loss': 0.4749, 'grad_norm': 1.9702271223068237, 'learning_rate': 2e-06, 'rewards/chosen': -1.3730336427688599, 'rewards/rejected': -2.234961748123169, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 0.8619281649589539, 'logps/rejected': -82.69612884521484, 'logps/chosen': -73.80450439453125, 'logits/rejected': -32.24641799926758, 'logits/chosen': -32.821022033691406, 'epoch': 2.18}\n{'loss': 0.4911, 'grad_norm': 2.307842254638672, 'learning_rate': 2e-06, 'rewards/chosen': -1.3919236660003662, 'rewards/rejected': -2.1688826084136963, 'rewards/accuracies': 0.780468761920929, 'rewards/margins': 0.7769590616226196, 'logps/rejected': -82.57484436035156, 'logps/chosen': -74.431396484375, 'logits/rejected': -32.425872802734375, 'logits/chosen': -31.99337387084961, 'epoch': 2.19}\n{'loss': 0.484, 'grad_norm': 2.1893863677978516, 'learning_rate': 2e-06, 'rewards/chosen': -1.3858797550201416, 'rewards/rejected': -2.232016086578369, 'rewards/accuracies': 0.766406238079071, 'rewards/margins': 0.8461365699768066, 'logps/rejected': -82.88927459716797, 'logps/chosen': -73.4306869506836, 'logits/rejected': -31.504581451416016, 'logits/chosen': -32.33159255981445, 'epoch': 2.2}\n{'loss': 0.5049, 'grad_norm': 2.180994987487793, 'learning_rate': 2e-06, 'rewards/chosen': -1.4133785963058472, 'rewards/rejected': -2.178663730621338, 'rewards/accuracies': 0.764843761920929, 'rewards/margins': 0.7652849555015564, 'logps/rejected': -82.0356674194336, 'logps/chosen': -74.34599304199219, 'logits/rejected': -32.834964752197266, 'logits/chosen': -33.23125457763672, 'epoch': 2.21}\n{'loss': 0.481, 'grad_norm': 2.356499671936035, 'learning_rate': 2e-06, 'rewards/chosen': -1.3830111026763916, 'rewards/rejected': -2.198066234588623, 'rewards/accuracies': 0.774218738079071, 'rewards/margins': 0.8150553703308105, 'logps/rejected': -82.97572326660156, 'logps/chosen': -74.93824005126953, 'logits/rejected': -32.339481353759766, 'logits/chosen': -32.74407196044922, 'epoch': 2.22}\n{'loss': 0.486, 'grad_norm': 2.1357219219207764, 'learning_rate': 2e-06, 'rewards/chosen': -1.4267433881759644, 'rewards/rejected': -2.250983715057373, 'rewards/accuracies': 0.765625, 'rewards/margins': 0.8242402076721191, 'logps/rejected': -83.53826141357422, 'logps/chosen': -74.86573791503906, 'logits/rejected': -32.41212844848633, 'logits/chosen': -32.49873733520508, 'epoch': 2.23}\n{'loss': 0.4942, 'grad_norm': 2.166045665740967, 'learning_rate': 2e-06, 'rewards/chosen': -1.4491978883743286, 'rewards/rejected': -2.252991199493408, 'rewards/accuracies': 0.76171875, 'rewards/margins': 0.8037934303283691, 'logps/rejected': -82.95696258544922, 'logps/chosen': -74.69178009033203, 'logits/rejected': -32.84412384033203, 'logits/chosen': -32.8393440246582, 'epoch': 2.24}\n{'loss': 0.4831, 'grad_norm': 2.228339433670044, 'learning_rate': 2e-06, 'rewards/chosen': -1.4295040369033813, 'rewards/rejected': -2.2543513774871826, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 0.8248475193977356, 'logps/rejected': -83.94943237304688, 'logps/chosen': -74.8400650024414, 'logits/rejected': -32.59117889404297, 'logits/chosen': -32.801395416259766, 'epoch': 2.25}\n{'loss': 0.4591, 'grad_norm': 2.0587003231048584, 'learning_rate': 2e-06, 'rewards/chosen': -1.4073173999786377, 'rewards/rejected': -2.2799172401428223, 'rewards/accuracies': 0.7992187738418579, 'rewards/margins': 0.8725993037223816, 'logps/rejected': -83.39075469970703, 'logps/chosen': -73.54051208496094, 'logits/rejected': -32.67396926879883, 'logits/chosen': -32.48235321044922, 'epoch': 2.25}\n{'loss': 0.4726, 'grad_norm': 1.9959094524383545, 'learning_rate': 2e-06, 'rewards/chosen': -1.4262927770614624, 'rewards/rejected': -2.3046278953552246, 'rewards/accuracies': 0.792187511920929, 'rewards/margins': 0.878335177898407, 'logps/rejected': -83.77731323242188, 'logps/chosen': -74.63357543945312, 'logits/rejected': -32.6181526184082, 'logits/chosen': -32.56627655029297, 'epoch': 2.26}\n{'loss': 0.4705, 'grad_norm': 2.230818033218384, 'learning_rate': 2e-06, 'rewards/chosen': -1.4738458395004272, 'rewards/rejected': -2.3610312938690186, 'rewards/accuracies': 0.780468761920929, 'rewards/margins': 0.8871856927871704, 'logps/rejected': -83.81260681152344, 'logps/chosen': -75.79652404785156, 'logits/rejected': -33.043540954589844, 'logits/chosen': -32.85683822631836, 'epoch': 2.27}\n{'loss': 0.4898, 'grad_norm': 2.0685338973999023, 'learning_rate': 2e-06, 'rewards/chosen': -1.4734828472137451, 'rewards/rejected': -2.3043713569641113, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.8308886289596558, 'logps/rejected': -83.39155578613281, 'logps/chosen': -75.19541931152344, 'logits/rejected': -33.32697296142578, 'logits/chosen': -33.420379638671875, 'epoch': 2.28}\n{'loss': 0.4813, 'grad_norm': 2.2195920944213867, 'learning_rate': 2e-06, 'rewards/chosen': -1.4450225830078125, 'rewards/rejected': -2.278768539428711, 'rewards/accuracies': 0.776562511920929, 'rewards/margins': 0.8337461352348328, 'logps/rejected': -82.88697814941406, 'logps/chosen': -74.38902282714844, 'logits/rejected': -33.35456085205078, 'logits/chosen': -33.117103576660156, 'epoch': 2.29}\n{'loss': 0.4762, 'grad_norm': 2.1585655212402344, 'learning_rate': 2e-06, 'rewards/chosen': -1.4887808561325073, 'rewards/rejected': -2.3921213150024414, 'rewards/accuracies': 0.766406238079071, 'rewards/margins': 0.9033404588699341, 'logps/rejected': -84.23772430419922, 'logps/chosen': -75.38497924804688, 'logits/rejected': -33.087154388427734, 'logits/chosen': -32.95258712768555, 'epoch': 2.3}\n{'loss': 0.4819, 'grad_norm': 2.412365674972534, 'learning_rate': 2e-06, 'rewards/chosen': -1.4586951732635498, 'rewards/rejected': -2.312079429626465, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.8533843159675598, 'logps/rejected': -83.74628448486328, 'logps/chosen': -75.24467468261719, 'logits/rejected': -33.310997009277344, 'logits/chosen': -32.82494354248047, 'epoch': 2.31}\n{'loss': 0.4708, 'grad_norm': 2.2446630001068115, 'learning_rate': 2e-06, 'rewards/chosen': -1.44954514503479, 'rewards/rejected': -2.335200071334839, 'rewards/accuracies': 0.78515625, 'rewards/margins': 0.8856550455093384, 'logps/rejected': -84.20992279052734, 'logps/chosen': -74.31683349609375, 'logits/rejected': -32.556888580322266, 'logits/chosen': -33.51121520996094, 'epoch': 2.32}\n{'loss': 0.487, 'grad_norm': 2.3280575275421143, 'learning_rate': 2e-06, 'rewards/chosen': -1.4747111797332764, 'rewards/rejected': -2.329969644546509, 'rewards/accuracies': 0.7523437738418579, 'rewards/margins': 0.8552581667900085, 'logps/rejected': -84.16291809082031, 'logps/chosen': -74.55496978759766, 'logits/rejected': -32.80754852294922, 'logits/chosen': -32.99842071533203, 'epoch': 2.33}\n{'loss': 0.463, 'grad_norm': 2.0935394763946533, 'learning_rate': 2e-06, 'rewards/chosen': -1.456716775894165, 'rewards/rejected': -2.3533294200897217, 'rewards/accuracies': 0.7906249761581421, 'rewards/margins': 0.8966127634048462, 'logps/rejected': -84.29953002929688, 'logps/chosen': -74.29591369628906, 'logits/rejected': -33.45572280883789, 'logits/chosen': -33.25348663330078, 'epoch': 2.34}\n{'loss': 0.4931, 'grad_norm': 2.2964656352996826, 'learning_rate': 2e-06, 'rewards/chosen': -1.5129730701446533, 'rewards/rejected': -2.361943483352661, 'rewards/accuracies': 0.7679687738418579, 'rewards/margins': 0.8489702939987183, 'logps/rejected': -84.35078430175781, 'logps/chosen': -75.1541748046875, 'logits/rejected': -33.319068908691406, 'logits/chosen': -33.655235290527344, 'epoch': 2.34}\n{'loss': 0.4861, 'grad_norm': 2.0999436378479004, 'learning_rate': 2e-06, 'rewards/chosen': -1.5134055614471436, 'rewards/rejected': -2.3827359676361084, 'rewards/accuracies': 0.7710937261581421, 'rewards/margins': 0.8693304061889648, 'logps/rejected': -84.11454010009766, 'logps/chosen': -75.19293975830078, 'logits/rejected': -33.43016815185547, 'logits/chosen': -33.059356689453125, 'epoch': 2.35}\n{'loss': 0.4804, 'grad_norm': 2.256396532058716, 'learning_rate': 2e-06, 'rewards/chosen': -1.538452386856079, 'rewards/rejected': -2.399606227874756, 'rewards/accuracies': 0.7632812261581421, 'rewards/margins': 0.861153781414032, 'logps/rejected': -84.69319152832031, 'logps/chosen': -75.59628295898438, 'logits/rejected': -32.36614990234375, 'logits/chosen': -32.982330322265625, 'epoch': 2.36}\n{'loss': 0.4901, 'grad_norm': 2.375521183013916, 'learning_rate': 2e-06, 'rewards/chosen': -1.4812036752700806, 'rewards/rejected': -2.3321871757507324, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.8509836196899414, 'logps/rejected': -83.82810974121094, 'logps/chosen': -74.53208923339844, 'logits/rejected': -32.761817932128906, 'logits/chosen': -32.98033905029297, 'epoch': 2.37}\n{'loss': 0.4804, 'grad_norm': 2.180434226989746, 'learning_rate': 2e-06, 'rewards/chosen': -1.5272085666656494, 'rewards/rejected': -2.3982748985290527, 'rewards/accuracies': 0.782031238079071, 'rewards/margins': 0.8710663914680481, 'logps/rejected': -85.24996185302734, 'logps/chosen': -75.58738708496094, 'logits/rejected': -33.257652282714844, 'logits/chosen': -33.51953887939453, 'epoch': 2.38}\n{'loss': 0.4908, 'grad_norm': 2.148667335510254, 'learning_rate': 2e-06, 'rewards/chosen': -1.5584499835968018, 'rewards/rejected': -2.3937108516693115, 'rewards/accuracies': 0.772656261920929, 'rewards/margins': 0.835261344909668, 'logps/rejected': -84.47697448730469, 'logps/chosen': -76.21244812011719, 'logits/rejected': -32.99745559692383, 'logits/chosen': -32.849403381347656, 'epoch': 2.39}\n{'loss': 0.4478, 'grad_norm': 2.0419766902923584, 'learning_rate': 2e-06, 'rewards/chosen': -1.4846389293670654, 'rewards/rejected': -2.4314279556274414, 'rewards/accuracies': 0.80859375, 'rewards/margins': 0.9467892646789551, 'logps/rejected': -84.76460266113281, 'logps/chosen': -74.86381530761719, 'logits/rejected': -33.28468704223633, 'logits/chosen': -33.06996154785156, 'epoch': 2.4}\n{'loss': 0.4983, 'grad_norm': 2.2495150566101074, 'learning_rate': 2e-06, 'rewards/chosen': -1.5699256658554077, 'rewards/rejected': -2.3815274238586426, 'rewards/accuracies': 0.76953125, 'rewards/margins': 0.8116016387939453, 'logps/rejected': -83.2406234741211, 'logps/chosen': -75.1283950805664, 'logits/rejected': -33.07088088989258, 'logits/chosen': -33.33624267578125, 'epoch': 2.41}\n{'loss': 0.4909, 'grad_norm': 2.3801157474517822, 'learning_rate': 2e-06, 'rewards/chosen': -1.5647494792938232, 'rewards/rejected': -2.403027057647705, 'rewards/accuracies': 0.7632812261581421, 'rewards/margins': 0.8382773399353027, 'logps/rejected': -84.663330078125, 'logps/chosen': -74.87683868408203, 'logits/rejected': -32.7568473815918, 'logits/chosen': -33.397132873535156, 'epoch': 2.42}\n{'loss': 0.4801, 'grad_norm': 2.060642719268799, 'learning_rate': 2e-06, 'rewards/chosen': -1.5492340326309204, 'rewards/rejected': -2.4549059867858887, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.9056720733642578, 'logps/rejected': -84.30101776123047, 'logps/chosen': -75.89249420166016, 'logits/rejected': -33.464134216308594, 'logits/chosen': -33.3299560546875, 'epoch': 2.43}\n{'loss': 0.4788, 'grad_norm': 2.3643341064453125, 'learning_rate': 2e-06, 'rewards/chosen': -1.5415370464324951, 'rewards/rejected': -2.436541795730591, 'rewards/accuracies': 0.772656261920929, 'rewards/margins': 0.8950045704841614, 'logps/rejected': -85.43221282958984, 'logps/chosen': -75.29956817626953, 'logits/rejected': -33.30952072143555, 'logits/chosen': -33.73299026489258, 'epoch': 2.43}\n{'loss': 0.4821, 'grad_norm': 2.3983964920043945, 'learning_rate': 2e-06, 'rewards/chosen': -1.5272241830825806, 'rewards/rejected': -2.4058337211608887, 'rewards/accuracies': 0.7789062261581421, 'rewards/margins': 0.8786096572875977, 'logps/rejected': -84.84942626953125, 'logps/chosen': -75.00785827636719, 'logits/rejected': -33.73322296142578, 'logits/chosen': -34.246585845947266, 'epoch': 2.44}\n{'loss': 0.4744, 'grad_norm': 2.2675986289978027, 'learning_rate': 2e-06, 'rewards/chosen': -1.539494514465332, 'rewards/rejected': -2.4300360679626465, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.8905412554740906, 'logps/rejected': -84.94911193847656, 'logps/chosen': -75.06132507324219, 'logits/rejected': -33.89641571044922, 'logits/chosen': -33.820335388183594, 'epoch': 2.45}\n{'loss': 0.4751, 'grad_norm': 2.141263961791992, 'learning_rate': 2e-06, 'rewards/chosen': -1.5670039653778076, 'rewards/rejected': -2.4935660362243652, 'rewards/accuracies': 0.780468761920929, 'rewards/margins': 0.926561713218689, 'logps/rejected': -85.19591522216797, 'logps/chosen': -75.20494079589844, 'logits/rejected': -34.17454147338867, 'logits/chosen': -33.97099304199219, 'epoch': 2.46}\n{'loss': 0.484, 'grad_norm': 2.1728360652923584, 'learning_rate': 2e-06, 'rewards/chosen': -1.559395670890808, 'rewards/rejected': -2.4265389442443848, 'rewards/accuracies': 0.7718750238418579, 'rewards/margins': 0.867143452167511, 'logps/rejected': -84.35272979736328, 'logps/chosen': -74.9183578491211, 'logits/rejected': -33.76851272583008, 'logits/chosen': -34.234458923339844, 'epoch': 2.47}\n{'loss': 0.4938, 'grad_norm': 2.1531009674072266, 'learning_rate': 2e-06, 'rewards/chosen': -1.5400216579437256, 'rewards/rejected': -2.386967182159424, 'rewards/accuracies': 0.76171875, 'rewards/margins': 0.8469454646110535, 'logps/rejected': -84.12632751464844, 'logps/chosen': -76.03759765625, 'logits/rejected': -33.3734245300293, 'logits/chosen': -33.946014404296875, 'epoch': 2.48}\n{'loss': 0.4797, 'grad_norm': 2.1847589015960693, 'learning_rate': 2e-06, 'rewards/chosen': -1.5432636737823486, 'rewards/rejected': -2.3986430168151855, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.8553794026374817, 'logps/rejected': -84.50019073486328, 'logps/chosen': -75.09494018554688, 'logits/rejected': -34.176719665527344, 'logits/chosen': -34.16085433959961, 'epoch': 2.49}\n{'loss': 0.4839, 'grad_norm': 2.1530327796936035, 'learning_rate': 2e-06, 'rewards/chosen': -1.5680108070373535, 'rewards/rejected': -2.4281280040740967, 'rewards/accuracies': 0.7671874761581421, 'rewards/margins': 0.8601174354553223, 'logps/rejected': -84.77073669433594, 'logps/chosen': -76.36692810058594, 'logits/rejected': -33.834877014160156, 'logits/chosen': -33.51445770263672, 'epoch': 2.5}\n{'loss': 0.499, 'grad_norm': 2.362018585205078, 'learning_rate': 2e-06, 'rewards/chosen': -1.5804407596588135, 'rewards/rejected': -2.3913447856903076, 'rewards/accuracies': 0.760937511920929, 'rewards/margins': 0.8109042048454285, 'logps/rejected': -83.87235260009766, 'logps/chosen': -76.40465545654297, 'logits/rejected': -33.61252212524414, 'logits/chosen': -33.93240737915039, 'epoch': 2.51}\n{'loss': 0.4888, 'grad_norm': 2.198367118835449, 'learning_rate': 2e-06, 'rewards/chosen': -1.5666265487670898, 'rewards/rejected': -2.402162790298462, 'rewards/accuracies': 0.7796875238418579, 'rewards/margins': 0.8355363607406616, 'logps/rejected': -84.68547058105469, 'logps/chosen': -76.1436996459961, 'logits/rejected': -33.57528305053711, 'logits/chosen': -34.10875701904297, 'epoch': 2.52}\n{'loss': 0.5014, 'grad_norm': 2.2386581897735596, 'learning_rate': 2e-06, 'rewards/chosen': -1.5961401462554932, 'rewards/rejected': -2.4353935718536377, 'rewards/accuracies': 0.7632812261581421, 'rewards/margins': 0.839253306388855, 'logps/rejected': -84.50888061523438, 'logps/chosen': -76.45740509033203, 'logits/rejected': -34.06969451904297, 'logits/chosen': -34.21159744262695, 'epoch': 2.52}\n{'loss': 0.472, 'grad_norm': 2.1466522216796875, 'learning_rate': 2e-06, 'rewards/chosen': -1.4811052083969116, 'rewards/rejected': -2.386707305908203, 'rewards/accuracies': 0.7906249761581421, 'rewards/margins': 0.9056020975112915, 'logps/rejected': -84.05168914794922, 'logps/chosen': -75.0902328491211, 'logits/rejected': -33.82856369018555, 'logits/chosen': -34.372520446777344, 'epoch': 2.53}\n{'loss': 0.4768, 'grad_norm': 2.1903347969055176, 'learning_rate': 2e-06, 'rewards/chosen': -1.5561014413833618, 'rewards/rejected': -2.4240241050720215, 'rewards/accuracies': 0.7734375, 'rewards/margins': 0.8679227828979492, 'logps/rejected': -85.0816421508789, 'logps/chosen': -75.38063049316406, 'logits/rejected': -33.839088439941406, 'logits/chosen': -34.20795440673828, 'epoch': 2.54}\n{'loss': 0.5022, 'grad_norm': 2.1823863983154297, 'learning_rate': 2e-06, 'rewards/chosen': -1.5621384382247925, 'rewards/rejected': -2.375514268875122, 'rewards/accuracies': 0.7640625238418579, 'rewards/margins': 0.8133758306503296, 'logps/rejected': -84.375244140625, 'logps/chosen': -76.09746551513672, 'logits/rejected': -34.36370849609375, 'logits/chosen': -34.816219329833984, 'epoch': 2.55}\n{'loss': 0.4929, 'grad_norm': 2.234454393386841, 'learning_rate': 2e-06, 'rewards/chosen': -1.5393946170806885, 'rewards/rejected': -2.400585889816284, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.8611913919448853, 'logps/rejected': -85.23434448242188, 'logps/chosen': -75.24752044677734, 'logits/rejected': -34.23503112792969, 'logits/chosen': -34.146575927734375, 'epoch': 2.56}\n{'loss': 0.4987, 'grad_norm': 2.3050453662872314, 'learning_rate': 2e-06, 'rewards/chosen': -1.5195035934448242, 'rewards/rejected': -2.3533830642700195, 'rewards/accuracies': 0.745312511920929, 'rewards/margins': 0.8338794708251953, 'logps/rejected': -83.85383605957031, 'logps/chosen': -75.4508056640625, 'logits/rejected': -34.0778923034668, 'logits/chosen': -34.655799865722656, 'epoch': 2.57}\n{'loss': 0.4777, 'grad_norm': 2.261829376220703, 'learning_rate': 2e-06, 'rewards/chosen': -1.5493359565734863, 'rewards/rejected': -2.4407880306243896, 'rewards/accuracies': 0.782031238079071, 'rewards/margins': 0.8914523124694824, 'logps/rejected': -84.47510528564453, 'logps/chosen': -75.42212677001953, 'logits/rejected': -34.24471664428711, 'logits/chosen': -33.90126037597656, 'epoch': 2.58}\n{'loss': 0.4487, 'grad_norm': 2.176534652709961, 'learning_rate': 2e-06, 'rewards/chosen': -1.4669687747955322, 'rewards/rejected': -2.4285714626312256, 'rewards/accuracies': 0.80078125, 'rewards/margins': 0.9616028070449829, 'logps/rejected': -84.36152648925781, 'logps/chosen': -75.25733947753906, 'logits/rejected': -34.337257385253906, 'logits/chosen': -33.95348358154297, 'epoch': 2.59}\n{'loss': 0.467, 'grad_norm': 2.153836488723755, 'learning_rate': 2e-06, 'rewards/chosen': -1.5709879398345947, 'rewards/rejected': -2.4981255531311035, 'rewards/accuracies': 0.7734375, 'rewards/margins': 0.9271373748779297, 'logps/rejected': -85.42619323730469, 'logps/chosen': -75.44873809814453, 'logits/rejected': -34.30213165283203, 'logits/chosen': -34.489105224609375, 'epoch': 2.6}\n{'loss': 0.4862, 'grad_norm': 2.2281417846679688, 'learning_rate': 2e-06, 'rewards/chosen': -1.5813391208648682, 'rewards/rejected': -2.424337387084961, 'rewards/accuracies': 0.7523437738418579, 'rewards/margins': 0.8429983854293823, 'logps/rejected': -84.57235717773438, 'logps/chosen': -76.0647964477539, 'logits/rejected': -34.733421325683594, 'logits/chosen': -35.07516860961914, 'epoch': 2.61}\n{'loss': 0.4746, 'grad_norm': 2.346872329711914, 'learning_rate': 2e-06, 'rewards/chosen': -1.5596922636032104, 'rewards/rejected': -2.455331325531006, 'rewards/accuracies': 0.7679687738418579, 'rewards/margins': 0.8956391215324402, 'logps/rejected': -85.2152328491211, 'logps/chosen': -75.7356185913086, 'logits/rejected': -33.95318603515625, 'logits/chosen': -33.93927764892578, 'epoch': 2.61}\n{'loss': 0.4869, 'grad_norm': 2.2499654293060303, 'learning_rate': 2e-06, 'rewards/chosen': -1.5888879299163818, 'rewards/rejected': -2.476306915283203, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 0.8874186277389526, 'logps/rejected': -84.46127319335938, 'logps/chosen': -75.69154357910156, 'logits/rejected': -34.207420349121094, 'logits/chosen': -34.185203552246094, 'epoch': 2.62}\n{'loss': 0.4719, 'grad_norm': 2.221958637237549, 'learning_rate': 2e-06, 'rewards/chosen': -1.5923515558242798, 'rewards/rejected': -2.4991137981414795, 'rewards/accuracies': 0.792187511920929, 'rewards/margins': 0.9067622423171997, 'logps/rejected': -85.03155517578125, 'logps/chosen': -76.64127349853516, 'logits/rejected': -34.56208038330078, 'logits/chosen': -34.50050735473633, 'epoch': 2.63}\n{'loss': 0.4687, 'grad_norm': 2.0774998664855957, 'learning_rate': 2e-06, 'rewards/chosen': -1.5721722841262817, 'rewards/rejected': -2.4798471927642822, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.9076749086380005, 'logps/rejected': -85.86360168457031, 'logps/chosen': -76.01016998291016, 'logits/rejected': -34.69735336303711, 'logits/chosen': -34.718692779541016, 'epoch': 2.64}\n{'loss': 0.485, 'grad_norm': 2.2699365615844727, 'learning_rate': 2e-06, 'rewards/chosen': -1.579552412033081, 'rewards/rejected': -2.469299554824829, 'rewards/accuracies': 0.772656261920929, 'rewards/margins': 0.8897472620010376, 'logps/rejected': -85.3936538696289, 'logps/chosen': -75.73731994628906, 'logits/rejected': -34.08719253540039, 'logits/chosen': -34.47509765625, 'epoch': 2.65}\n{'loss': 0.4737, 'grad_norm': 2.401564359664917, 'learning_rate': 2e-06, 'rewards/chosen': -1.6005195379257202, 'rewards/rejected': -2.4922332763671875, 'rewards/accuracies': 0.776562511920929, 'rewards/margins': 0.8917137980461121, 'logps/rejected': -86.03352355957031, 'logps/chosen': -76.04195404052734, 'logits/rejected': -34.53033447265625, 'logits/chosen': -34.28330612182617, 'epoch': 2.66}\n{'loss': 0.4731, 'grad_norm': 2.297849416732788, 'learning_rate': 2e-06, 'rewards/chosen': -1.6031328439712524, 'rewards/rejected': -2.5120837688446045, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.9089511632919312, 'logps/rejected': -85.70861053466797, 'logps/chosen': -75.3094711303711, 'logits/rejected': -34.406761169433594, 'logits/chosen': -34.888797760009766, 'epoch': 2.67}\n{'loss': 0.4692, 'grad_norm': 2.1831624507904053, 'learning_rate': 2e-06, 'rewards/chosen': -1.6221601963043213, 'rewards/rejected': -2.5664420127868652, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.9442818760871887, 'logps/rejected': -86.20597839355469, 'logps/chosen': -76.47623443603516, 'logits/rejected': -34.43773651123047, 'logits/chosen': -34.37078857421875, 'epoch': 2.68}\n{'loss': 0.4793, 'grad_norm': 2.3364663124084473, 'learning_rate': 2e-06, 'rewards/chosen': -1.645081877708435, 'rewards/rejected': -2.5335943698883057, 'rewards/accuracies': 0.774218738079071, 'rewards/margins': 0.8885123133659363, 'logps/rejected': -86.27833557128906, 'logps/chosen': -76.7046127319336, 'logits/rejected': -33.83130645751953, 'logits/chosen': -34.7921028137207, 'epoch': 2.69}\n{'loss': 0.4688, 'grad_norm': 2.2768807411193848, 'learning_rate': 2e-06, 'rewards/chosen': -1.644404649734497, 'rewards/rejected': -2.5548527240753174, 'rewards/accuracies': 0.772656261920929, 'rewards/margins': 0.9104480743408203, 'logps/rejected': -86.07416534423828, 'logps/chosen': -76.80784606933594, 'logits/rejected': -34.703125, 'logits/chosen': -34.55256652832031, 'epoch': 2.7}\n{'loss': 0.4625, 'grad_norm': 2.2447280883789062, 'learning_rate': 2e-06, 'rewards/chosen': -1.6549341678619385, 'rewards/rejected': -2.5699329376220703, 'rewards/accuracies': 0.7828124761581421, 'rewards/margins': 0.9149988889694214, 'logps/rejected': -86.40589904785156, 'logps/chosen': -76.90800476074219, 'logits/rejected': -34.70998001098633, 'logits/chosen': -34.7923469543457, 'epoch': 2.71}\n{'loss': 0.4879, 'grad_norm': 2.124154806137085, 'learning_rate': 2e-06, 'rewards/chosen': -1.6391798257827759, 'rewards/rejected': -2.504031181335449, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.8648515939712524, 'logps/rejected': -84.30122375488281, 'logps/chosen': -75.6274185180664, 'logits/rejected': -34.870635986328125, 'logits/chosen': -34.508094787597656, 'epoch': 2.71}\n{'loss': 0.4723, 'grad_norm': 2.246901512145996, 'learning_rate': 2e-06, 'rewards/chosen': -1.6378408670425415, 'rewards/rejected': -2.5632855892181396, 'rewards/accuracies': 0.772656261920929, 'rewards/margins': 0.9254447221755981, 'logps/rejected': -86.5871353149414, 'logps/chosen': -76.29241180419922, 'logits/rejected': -34.867462158203125, 'logits/chosen': -35.24797821044922, 'epoch': 2.72}\n{'loss': 0.4802, 'grad_norm': 2.4243903160095215, 'learning_rate': 2e-06, 'rewards/chosen': -1.6191604137420654, 'rewards/rejected': -2.5438618659973145, 'rewards/accuracies': 0.7890625, 'rewards/margins': 0.9247013926506042, 'logps/rejected': -86.22075653076172, 'logps/chosen': -76.23106384277344, 'logits/rejected': -34.44443130493164, 'logits/chosen': -35.1553840637207, 'epoch': 2.73}\n{'loss': 0.4845, 'grad_norm': 2.286956548690796, 'learning_rate': 2e-06, 'rewards/chosen': -1.6131246089935303, 'rewards/rejected': -2.4875025749206543, 'rewards/accuracies': 0.7757812738418579, 'rewards/margins': 0.8743780851364136, 'logps/rejected': -85.73481750488281, 'logps/chosen': -76.68046569824219, 'logits/rejected': -34.021358489990234, 'logits/chosen': -34.702110290527344, 'epoch': 2.74}\n{'loss': 0.4864, 'grad_norm': 2.3058598041534424, 'learning_rate': 2e-06, 'rewards/chosen': -1.628011703491211, 'rewards/rejected': -2.5103490352630615, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.8823376893997192, 'logps/rejected': -85.32498168945312, 'logps/chosen': -76.1936264038086, 'logits/rejected': -34.890724182128906, 'logits/chosen': -35.04353713989258, 'epoch': 2.75}\n{'loss': 0.468, 'grad_norm': 2.1014490127563477, 'learning_rate': 2e-06, 'rewards/chosen': -1.6067644357681274, 'rewards/rejected': -2.5432116985321045, 'rewards/accuracies': 0.7906249761581421, 'rewards/margins': 0.936447262763977, 'logps/rejected': -85.88384246826172, 'logps/chosen': -76.69004821777344, 'logits/rejected': -34.60832595825195, 'logits/chosen': -34.480892181396484, 'epoch': 2.76}\n{'loss': 0.4828, 'grad_norm': 2.447197437286377, 'learning_rate': 2e-06, 'rewards/chosen': -1.6165252923965454, 'rewards/rejected': -2.4931693077087402, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.8766441345214844, 'logps/rejected': -85.28936767578125, 'logps/chosen': -76.73146057128906, 'logits/rejected': -34.32958221435547, 'logits/chosen': -34.083824157714844, 'epoch': 2.77}\n{'loss': 0.481, 'grad_norm': 2.385462522506714, 'learning_rate': 2e-06, 'rewards/chosen': -1.5988702774047852, 'rewards/rejected': -2.49242901802063, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.8935588002204895, 'logps/rejected': -85.29377746582031, 'logps/chosen': -76.24809265136719, 'logits/rejected': -34.129066467285156, 'logits/chosen': -34.1950569152832, 'epoch': 2.78}\n{'loss': 0.4605, 'grad_norm': 2.222669839859009, 'learning_rate': 2e-06, 'rewards/chosen': -1.5944926738739014, 'rewards/rejected': -2.516660213470459, 'rewards/accuracies': 0.79296875, 'rewards/margins': 0.9221677780151367, 'logps/rejected': -85.40486907958984, 'logps/chosen': -76.29825592041016, 'logits/rejected': -33.534156799316406, 'logits/chosen': -34.109336853027344, 'epoch': 2.79}\n{'loss': 0.4659, 'grad_norm': 2.3784658908843994, 'learning_rate': 2e-06, 'rewards/chosen': -1.6130958795547485, 'rewards/rejected': -2.5763163566589355, 'rewards/accuracies': 0.7757812738418579, 'rewards/margins': 0.9632202386856079, 'logps/rejected': -86.29792785644531, 'logps/chosen': -75.7385482788086, 'logits/rejected': -34.23505401611328, 'logits/chosen': -34.326107025146484, 'epoch': 2.8}\n{'loss': 0.4757, 'grad_norm': 2.1626553535461426, 'learning_rate': 2e-06, 'rewards/chosen': -1.6821515560150146, 'rewards/rejected': -2.589536666870117, 'rewards/accuracies': 0.7757812738418579, 'rewards/margins': 0.9073850512504578, 'logps/rejected': -86.03538513183594, 'logps/chosen': -77.5739974975586, 'logits/rejected': -34.79491424560547, 'logits/chosen': -34.64620590209961, 'epoch': 2.8}\n{'loss': 0.4622, 'grad_norm': 2.241563081741333, 'learning_rate': 2e-06, 'rewards/chosen': -1.6090145111083984, 'rewards/rejected': -2.561253070831299, 'rewards/accuracies': 0.7789062261581421, 'rewards/margins': 0.9522387385368347, 'logps/rejected': -86.396240234375, 'logps/chosen': -76.42132568359375, 'logits/rejected': -34.276344299316406, 'logits/chosen': -34.41856002807617, 'epoch': 2.81}\n{'loss': 0.4786, 'grad_norm': 2.310229539871216, 'learning_rate': 2e-06, 'rewards/chosen': -1.6443755626678467, 'rewards/rejected': -2.5909018516540527, 'rewards/accuracies': 0.7734375, 'rewards/margins': 0.9465262293815613, 'logps/rejected': -86.29258728027344, 'logps/chosen': -77.1384506225586, 'logits/rejected': -35.10721969604492, 'logits/chosen': -34.99580001831055, 'epoch': 2.82}\n{'loss': 0.4959, 'grad_norm': 2.4250621795654297, 'learning_rate': 2e-06, 'rewards/chosen': -1.6716314554214478, 'rewards/rejected': -2.5363030433654785, 'rewards/accuracies': 0.764843761920929, 'rewards/margins': 0.8646717071533203, 'logps/rejected': -85.87417602539062, 'logps/chosen': -76.59722900390625, 'logits/rejected': -34.87969207763672, 'logits/chosen': -35.164981842041016, 'epoch': 2.83}\n{'loss': 0.4739, 'grad_norm': 2.224170684814453, 'learning_rate': 2e-06, 'rewards/chosen': -1.6363534927368164, 'rewards/rejected': -2.5417981147766113, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 0.9054442644119263, 'logps/rejected': -86.57347106933594, 'logps/chosen': -76.63793182373047, 'logits/rejected': -34.310420989990234, 'logits/chosen': -34.60014724731445, 'epoch': 2.84}\n{'loss': 0.4723, 'grad_norm': 2.2810330390930176, 'learning_rate': 2e-06, 'rewards/chosen': -1.659009575843811, 'rewards/rejected': -2.616964340209961, 'rewards/accuracies': 0.7757812738418579, 'rewards/margins': 0.9579547047615051, 'logps/rejected': -86.6371078491211, 'logps/chosen': -77.40330505371094, 'logits/rejected': -34.66803741455078, 'logits/chosen': -34.44010925292969, 'epoch': 2.85}\n{'loss': 0.4774, 'grad_norm': 2.347895622253418, 'learning_rate': 2e-06, 'rewards/chosen': -1.6885120868682861, 'rewards/rejected': -2.617366313934326, 'rewards/accuracies': 0.7601562738418579, 'rewards/margins': 0.9288545846939087, 'logps/rejected': -86.56195068359375, 'logps/chosen': -77.40740966796875, 'logits/rejected': -34.2471809387207, 'logits/chosen': -34.5126953125, 'epoch': 2.86}\n{'loss': 0.4731, 'grad_norm': 2.3054659366607666, 'learning_rate': 2e-06, 'rewards/chosen': -1.622182846069336, 'rewards/rejected': -2.5695412158966064, 'rewards/accuracies': 0.77734375, 'rewards/margins': 0.9473584890365601, 'logps/rejected': -85.4999771118164, 'logps/chosen': -76.71439361572266, 'logits/rejected': -34.16664123535156, 'logits/chosen': -34.17023468017578, 'epoch': 2.87}\n{'loss': 0.4827, 'grad_norm': 2.084845781326294, 'learning_rate': 2e-06, 'rewards/chosen': -1.6359643936157227, 'rewards/rejected': -2.5162439346313477, 'rewards/accuracies': 0.7632812261581421, 'rewards/margins': 0.880279541015625, 'logps/rejected': -85.05223083496094, 'logps/chosen': -76.52909851074219, 'logits/rejected': -34.22026443481445, 'logits/chosen': -33.957305908203125, 'epoch': 2.88}\n{'loss': 0.4689, 'grad_norm': 2.199367046356201, 'learning_rate': 2e-06, 'rewards/chosen': -1.6418431997299194, 'rewards/rejected': -2.547001361846924, 'rewards/accuracies': 0.78515625, 'rewards/margins': 0.9051581621170044, 'logps/rejected': -86.20536041259766, 'logps/chosen': -76.51152038574219, 'logits/rejected': -34.12919235229492, 'logits/chosen': -34.522682189941406, 'epoch': 2.89}\n{'loss': 0.4595, 'grad_norm': 2.3008499145507812, 'learning_rate': 2e-06, 'rewards/chosen': -1.612847089767456, 'rewards/rejected': -2.5772814750671387, 'rewards/accuracies': 0.7992187738418579, 'rewards/margins': 0.9644343256950378, 'logps/rejected': -85.86172485351562, 'logps/chosen': -75.77596282958984, 'logits/rejected': -34.291114807128906, 'logits/chosen': -34.85049819946289, 'epoch': 2.89}\n{'loss': 0.4919, 'grad_norm': 2.5834617614746094, 'learning_rate': 2e-06, 'rewards/chosen': -1.6790978908538818, 'rewards/rejected': -2.5745644569396973, 'rewards/accuracies': 0.764843761920929, 'rewards/margins': 0.8954662084579468, 'logps/rejected': -85.27406311035156, 'logps/chosen': -77.37569427490234, 'logits/rejected': -34.58040237426758, 'logits/chosen': -34.58739471435547, 'epoch': 2.9}\n{'loss': 0.4768, 'grad_norm': 2.1931726932525635, 'learning_rate': 2e-06, 'rewards/chosen': -1.6459242105484009, 'rewards/rejected': -2.5658745765686035, 'rewards/accuracies': 0.76953125, 'rewards/margins': 0.9199506044387817, 'logps/rejected': -85.45014190673828, 'logps/chosen': -76.61170959472656, 'logits/rejected': -34.00334548950195, 'logits/chosen': -34.3556022644043, 'epoch': 2.91}\n{'loss': 0.4906, 'grad_norm': 2.28365159034729, 'learning_rate': 2e-06, 'rewards/chosen': -1.6492912769317627, 'rewards/rejected': -2.5522818565368652, 'rewards/accuracies': 0.754687488079071, 'rewards/margins': 0.902990460395813, 'logps/rejected': -85.77505493164062, 'logps/chosen': -76.60490417480469, 'logits/rejected': -34.54551315307617, 'logits/chosen': -34.73116683959961, 'epoch': 2.92}\n{'loss': 0.4842, 'grad_norm': 2.3970508575439453, 'learning_rate': 2e-06, 'rewards/chosen': -1.6965516805648804, 'rewards/rejected': -2.6049838066101074, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.9084320068359375, 'logps/rejected': -86.32412719726562, 'logps/chosen': -77.47659301757812, 'logits/rejected': -34.98735427856445, 'logits/chosen': -34.840065002441406, 'epoch': 2.93}\n{'loss': 0.4855, 'grad_norm': 2.250391721725464, 'learning_rate': 2e-06, 'rewards/chosen': -1.6504799127578735, 'rewards/rejected': -2.5256621837615967, 'rewards/accuracies': 0.76171875, 'rewards/margins': 0.8751822710037231, 'logps/rejected': -85.40370178222656, 'logps/chosen': -76.15210723876953, 'logits/rejected': -35.08333206176758, 'logits/chosen': -35.20752716064453, 'epoch': 2.94}\n{'loss': 0.4745, 'grad_norm': 2.310424566268921, 'learning_rate': 2e-06, 'rewards/chosen': -1.6493768692016602, 'rewards/rejected': -2.5843605995178223, 'rewards/accuracies': 0.7710937261581421, 'rewards/margins': 0.9349836111068726, 'logps/rejected': -85.9833984375, 'logps/chosen': -76.25590515136719, 'logits/rejected': -35.050838470458984, 'logits/chosen': -35.370140075683594, 'epoch': 2.95}\n{'loss': 0.441, 'grad_norm': 1.967949390411377, 'learning_rate': 2e-06, 'rewards/chosen': -1.595951795578003, 'rewards/rejected': -2.6305625438690186, 'rewards/accuracies': 0.8109375238418579, 'rewards/margins': 1.0346111059188843, 'logps/rejected': -87.74272918701172, 'logps/chosen': -75.90364837646484, 'logits/rejected': -34.772666931152344, 'logits/chosen': -35.69731903076172, 'epoch': 2.96}\n{'loss': 0.4749, 'grad_norm': 2.2515506744384766, 'learning_rate': 2e-06, 'rewards/chosen': -1.6721683740615845, 'rewards/rejected': -2.6136202812194824, 'rewards/accuracies': 0.76953125, 'rewards/margins': 0.941452145576477, 'logps/rejected': -86.5400390625, 'logps/chosen': -76.69901275634766, 'logits/rejected': -35.39894104003906, 'logits/chosen': -35.770538330078125, 'epoch': 2.97}\n{'loss': 0.4879, 'grad_norm': 2.112091302871704, 'learning_rate': 2e-06, 'rewards/chosen': -1.666837453842163, 'rewards/rejected': -2.5470235347747803, 'rewards/accuracies': 0.760937511920929, 'rewards/margins': 0.8801859617233276, 'logps/rejected': -85.84468841552734, 'logps/chosen': -77.43090057373047, 'logits/rejected': -35.446388244628906, 'logits/chosen': -35.114200592041016, 'epoch': 2.98}\n{'loss': 0.468, 'grad_norm': 2.187385320663452, 'learning_rate': 2e-06, 'rewards/chosen': -1.6649372577667236, 'rewards/rejected': -2.6101560592651367, 'rewards/accuracies': 0.7789062261581421, 'rewards/margins': 0.9452190399169922, 'logps/rejected': -86.66072082519531, 'logps/chosen': -76.81820678710938, 'logits/rejected': -35.2972526550293, 'logits/chosen': -35.96449661254883, 'epoch': 2.98}\n{'loss': 0.4908, 'grad_norm': 2.234334707260132, 'learning_rate': 2e-06, 'rewards/chosen': -1.7112455368041992, 'rewards/rejected': -2.5807995796203613, 'rewards/accuracies': 0.7640625238418579, 'rewards/margins': 0.8695537447929382, 'logps/rejected': -86.02970123291016, 'logps/chosen': -76.54765319824219, 'logits/rejected': -35.827491760253906, 'logits/chosen': -35.528648376464844, 'epoch': 2.99}\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3327/3327 [1:09:16<00:00,  1.08s/it]evaluation_loop\n\n  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\n  3%|‚ñà‚ñç                                          | 2/59 [00:00<00:15,  3.66it/s]\u001b[A\n  5%|‚ñà‚ñà‚ñè                                         | 3/59 [00:01<00:21,  2.58it/s]\u001b[A\n  7%|‚ñà‚ñà‚ñâ                                         | 4/59 [00:01<00:25,  2.18it/s]\u001b[A\n  8%|‚ñà‚ñà‚ñà‚ñã                                        | 5/59 [00:02<00:26,  2.05it/s]\u001b[A\n 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 6/59 [00:02<00:26,  1.97it/s]\u001b[A\n 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 7/59 [00:03<00:27,  1.92it/s]\u001b[A\n 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                      | 8/59 [00:03<00:26,  1.89it/s]\u001b[A\n 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 9/59 [00:04<00:26,  1.87it/s]\u001b[A\n 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                   | 10/59 [00:04<00:26,  1.85it/s]\u001b[A\n 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 11/59 [00:05<00:26,  1.85it/s]\u001b[A\n 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 12/59 [00:06<00:25,  1.84it/s]\u001b[A\n 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 13/59 [00:06<00:25,  1.84it/s]\u001b[A\n 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 14/59 [00:07<00:24,  1.81it/s]\u001b[A\n 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                | 15/59 [00:07<00:24,  1.81it/s]\u001b[A\n 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 16/59 [00:08<00:23,  1.82it/s]\u001b[A\n 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 17/59 [00:08<00:23,  1.82it/s]\u001b[A\n 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 18/59 [00:09<00:22,  1.82it/s]\u001b[A\n 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 19/59 [00:09<00:21,  1.82it/s]\u001b[A\n 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 20/59 [00:10<00:21,  1.82it/s]\u001b[A\n 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 21/59 [00:11<00:20,  1.83it/s]\u001b[A\n 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 22/59 [00:11<00:20,  1.82it/s]\u001b[A\n 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 23/59 [00:12<00:19,  1.83it/s]\u001b[A\n 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 24/59 [00:12<00:19,  1.83it/s]\u001b[A\n 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 25/59 [00:13<00:18,  1.83it/s]\u001b[A\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 26/59 [00:13<00:18,  1.83it/s]\u001b[A\n 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 27/59 [00:14<00:17,  1.83it/s]\u001b[A\n 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 28/59 [00:14<00:16,  1.83it/s]\u001b[A\n 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 29/59 [00:15<00:16,  1.83it/s]\u001b[A\n 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 30/59 [00:15<00:15,  1.83it/s]\u001b[A\n 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 31/59 [00:16<00:15,  1.83it/s]\u001b[A\n 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 32/59 [00:17<00:14,  1.83it/s]\u001b[A\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 33/59 [00:17<00:14,  1.80it/s]\u001b[A\n 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                  | 34/59 [00:18<00:13,  1.81it/s]\u001b[A\n 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 35/59 [00:18<00:13,  1.81it/s]\u001b[A\n 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 36/59 [00:19<00:12,  1.82it/s]\u001b[A\n 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 37/59 [00:19<00:12,  1.82it/s]\u001b[A\n 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 38/59 [00:20<00:11,  1.82it/s]\u001b[A\n 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 39/59 [00:20<00:10,  1.82it/s]\u001b[A\n 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 40/59 [00:21<00:10,  1.79it/s]\u001b[A\n 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 41/59 [00:22<00:09,  1.80it/s]\u001b[A\n 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 42/59 [00:22<00:09,  1.80it/s]\u001b[A\n 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 43/59 [00:23<00:08,  1.81it/s]\u001b[A\n 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 44/59 [00:23<00:08,  1.81it/s]\u001b[A\n 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 45/59 [00:24<00:07,  1.78it/s]\u001b[A\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 46/59 [00:24<00:07,  1.80it/s]\u001b[A\n 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 47/59 [00:25<00:06,  1.81it/s]\u001b[A\n 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 48/59 [00:25<00:06,  1.79it/s]\u001b[A\n 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 49/59 [00:26<00:05,  1.80it/s]\u001b[A\n 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 50/59 [00:27<00:04,  1.81it/s]\u001b[A\n 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 51/59 [00:27<00:04,  1.81it/s]\u001b[A\n 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 52/59 [00:28<00:03,  1.82it/s]\u001b[A\n 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 53/59 [00:28<00:03,  1.82it/s]\u001b[A\n 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 54/59 [00:29<00:02,  1.79it/s]\u001b[A\n 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 55/59 [00:29<00:02,  1.77it/s]\u001b[A\n 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 56/59 [00:30<00:01,  1.76it/s]\u001b[A\n 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 57/59 [00:30<00:01,  1.76it/s]\u001b[A\n 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 58/59 [00:31<00:00,  1.77it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.4990471601486206, 'eval_runtime': 32.3236, 'eval_samples_per_second': 231.07, 'eval_steps_per_second': 1.825, 'eval_rewards/chosen': -1.7100967168807983, 'eval_rewards/rejected': -2.580080032348633, 'eval_rewards/accuracies': 0.7569797039031982, 'eval_rewards/margins': 0.8699829578399658, 'eval_logps/rejected': -86.06766510009766, 'eval_logps/chosen': -77.07060241699219, 'eval_logits/rejected': -35.37128448486328, 'eval_logits/chosen': -35.65390396118164, 'epoch': 3.0}\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3327/3327 [1:09:48<00:00,  1.08s/it]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59/59 [00:31<00:00,  2.20it/s]\u001b[A\n                                                                                \u001b[AThere were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n{'train_runtime': 4207.2234, 'train_samples_per_second': 101.184, 'train_steps_per_second': 0.791, 'train_loss': 0.5371550591385397, 'epoch': 3.0}\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3327/3327 [1:09:50<00:00,  1.26s/it]\nEvaling epochs [3, 2, 1, 0]\nLoading from test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-3327\nDownloading readme: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.81k/7.81k [00:00<00:00, 13.4MB/s]\nDownloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.0M/21.0M [00:00<00:00, 58.7MB/s]\nDownloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 49.0MB/s]\nDownloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.0M/42.0M [00:00<00:00, 142MB/s]\nGenerating train split: 100%|‚ñà‚ñà| 25000/25000 [00:00<00:00, 107641.97 examples/s]\nGenerating test split: 100%|‚ñà‚ñà‚ñà| 25000/25000 [00:00<00:00, 129906.25 examples/s]\nGenerating unsupervised split: 100%|‚ñà| 50000/50000 [00:00<00:00, 116651.73 examp\nFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:00<00:00, 24984.54 examples/s]\nMap:   0%|                                       | 0/250 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:00<00:00, 756.13 examples/s]\nload ref model lvwerra/gpt2-imdb\nload train model test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-3327\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\nconfig.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 687/687 [00:00<00:00, 2.08MB/s]\npytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:04<00:00, 347MB/s]\ntokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [00:00<00:00, 718kB/s]\nvocab.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 798k/798k [00:00<00:00, 5.54MB/s]\nmerges.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:00<00:00, 2.36MB/s]\nspecial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 371kB/s]\nLoad eval reward model sentiment-analysis:siebert/sentiment-roberta-large-english\neval batch size 256\nFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [00:00<00:00, 134936.24 examples/s]\nMap:   3%|‚ñä                           | 74/2487 [00:00<00:03, 725.95 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2487/2487 [00:03<00:00, 793.78 examples/s]\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 11%|‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1/9 [00:26<03:31, 26.41s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 2/9 [00:52<03:04, 26.39s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 3/9 [01:19<02:38, 26.48s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 4/9 [01:45<02:12, 26.53s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 5/9 [02:12<01:46, 26.54s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 6/9 [02:39<01:19, 26.56s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 7/9 [03:05<00:53, 26.56s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/9 [03:32<00:26, 26.56s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [03:59<00:00, 26.56s/it]\nmean test reward 0.9489936448758525 +/- 0.004502470663073746 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9988741278648376 from 0.00922983093187213\nmean KL -7.388255500959025 +/- 0.2177168760391841 full 16.243880899002153 +/- 0.0818872034689309\nmedian KL -7.360010147094727 full 15.77302598953247\nLoading from test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-2218\nload ref model lvwerra/gpt2-imdb\nload train model test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-2218\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\nLoad eval reward model sentiment-analysis:siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 11%|‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1/9 [00:26<03:31, 26.43s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 2/9 [00:52<03:04, 26.37s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 3/9 [01:19<02:38, 26.45s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 4/9 [01:46<02:13, 26.60s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 5/9 [02:12<01:46, 26.69s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 6/9 [02:39<01:19, 26.66s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 7/9 [03:06<00:53, 26.83s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/9 [03:33<00:26, 26.87s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [04:00<00:00, 26.75s/it]\nmean test reward 0.9365258436400458 +/- 0.004999127046826938 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9988588094711304 from 0.00922983093187213\nmean KL -2.7794271748926906 +/- 0.15100651950307561 full 13.215453798365262 +/- 0.06960192365546918\nmedian KL -2.5571680068969727 full 12.796234130859375\nLoading from test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-1109\nload ref model lvwerra/gpt2-imdb\nload train model test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-1109\ndevice cuda\ndevice 0\nLoad reward model siebert/sentiment-roberta-large-english\nLoad eval reward model sentiment-analysis:siebert/sentiment-roberta-large-english\neval batch size 256\ntest len 9\n  0%|                                                     | 0/9 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 11%|‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 1/9 [00:26<03:31, 26.46s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                   | 2/9 [00:52<03:04, 26.37s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 3/9 [01:19<02:38, 26.47s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 4/9 [01:46<02:12, 26.57s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 5/9 [02:12<01:46, 26.67s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 6/9 [02:39<01:20, 26.78s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 7/9 [03:06<00:53, 26.73s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/9 [03:33<00:26, 26.65s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [03:59<00:00, 26.64s/it]\nmean test reward 0.9161701073597518 +/- 0.0056775556836090495 from 0.4351168664733096 +/- 0.010216795621720676\nmedian test reward 0.9988383650779724 from 0.00922983093187213\nmean KL 1.9288278220208466 +/- 0.11660670438640276 full 9.810515876445505 +/- 0.058218985718811476\nmedian KL 2.439262628555298 full 9.41413402557373\nLoading from test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-0\nload ref model lvwerra/gpt2-imdb\nload train model test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-0\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n    response.raise_for_status()\n  File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-0/resolve/main/config.json\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 399, in cached_file\n    resolved_file = hf_hub_download(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1325, in _hf_hub_download_to_cache_dir\n    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1823, in _raise_on_head_call_error\n    raise head_call_error\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n    r = _request_wrapper(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n    response = _request_wrapper(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 396, in _request_wrapper\n    hf_raise_for_status(response)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n    raise RepositoryNotFoundError(message, response) from e\nhuggingface_hub.utils._errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-66666bfe-5c28b04f175da8b11b77e2f4;f4464e86-e52c-4cc2-a780-915c8b3f206c)\n\nRepository Not Found for url: https://huggingface.co/test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-0/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/cs234-project/dpo.py\", line 207, in <module>\n    stat = ppo.eval(checkpoint, f\"epoch {epoch}\")\n  File \"/kaggle/working/cs234-project/ppo.py\", line 291, in eval\n    return run(PPOConfig(exp_name=\"eval\", eval_model=model), args=ScriptArguments(), full_name=f'{model}_{notes}')\n  File \"/kaggle/working/cs234-project/ppo.py\", line 128, in run\n    model = trl_model_class.from_pretrained(\n  File \"/opt/conda/lib/python3.10/site-packages/trl/models/modeling_base.py\", line 219, in from_pretrained\n    pretrained_model = cls.transformers_parent_class.from_pretrained(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 484, in from_pretrained\n    resolved_config_file = cached_file(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 422, in cached_file\n    raise EnvironmentError(\nOSError: test_dpo_0_1_lr2e_6-2024.06.10.01.36/checkpoint-0 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n","output_type":"stream"}]}]}